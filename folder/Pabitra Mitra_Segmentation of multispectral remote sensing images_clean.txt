Segmentation of multispectral remote sensing images using active support vector machines Pabitra Mitra *, B. Uma Shankar, Sankar K. Pal Machine Intelligence Unit, Indian Statistical Institute, Kolkata 700108, India Received 21 October 2003; received in revised form 26 January 2004 Available online 15 April 2004 Abstract The problem of scarcity of labeled pixels, required for segmentation of remotely sensed satellite images in supervised pixel classi cation framework, is addressed in this article. A support vector machine (SVM) is considered for classifying the pixels into di erent landcover types. It is initially designed using a small set of labeled points, and subsequently re ned by actively querying for the labels of pixels from a pool of unlabeled data. The label of the most interesting/ ambiguous unlabeled point is queried at each step. Here, active learning is exploited to minimize the number of labeled data used by the SVM classi er by several orders. These features are demonstrated on an IRS-1A four band multi- spectral image. Comparison with related methods is made in terms of number of data points used, computational time and a cluster quality measure.  2004 Elsevier B.V. All rights reserved. Keywords: Image segmentation; Semi-supervised learning; Transductive learning; Query support vector machine 1. Introduction Segmentation is a process of partitioning an image space into some nonoverlapping meaningful homogeneous regions. The success of an image analysis system depends on the quality of seg- mentation. Two broad approaches to segmenta- tion of remotely sensed images are gray level thresholding and pixel classi cation (Richards, 1993). In thresholding (Pal et al., 2000) one tries to get a set of thresholds fT1; T2; . . . ; Tkg such that all pixels with grey values in the range Ti; Ti 1 con- stitute the ith region type. On the other hand in pixel classi cation, homogeneous regions are determined by clustering the feature space of multiple image bands. Multispectral nature of most remote sensing images make pixel classi ca- tion the natural choice for segmentation. In the unsupervised pixel classi cation frame- work, several clustering algorithms like split-and- merge (Laprade, 1988), fuzzy k-means (Pal et al., 2000; Cannon et al., 1986), neural networks based methods (Baraldi and Parmiggiani, 1995), scale space techniques (Wong and Posner, 1993) and statistical methods have been used for the purpose * Corresponding author. Address: Department of Computer Science, Indian Institute of Technology and Engineering, Kanpur 208016, India. Tel.: +91-0512-259-7584. E-mail addresses: pmitra@iitk.ac.in, pabitra_r@isical.ac.in (P. Mitra), uma@isical.ac.in (B. Uma Shankar), sankar@isi- cal.ac.in (S.K. Pal). 0167-8655/$ - see front matter  2004 Elsevier B.V. All rights reserved. doi:10.1016/j.patrec.2004.03.004 Pattern Recognition Letters 25 (2004) 1067 1074 www.elsevier.com/locate/patrec of segmentation. Statistical methods are widely used in unsupervised pixel classi cation framework because of their capability of handling uncertain- ties arising from both measurement error and the presence of mixed pixels which have certain degree of membership to more than one class. A general method of statistical clustering is by means of the expectation maximization (EM) algorithm (Dempster et al., 1977) and its variants (Pal and Mitra, 2002). However, the unsupervised pixel classi cation methods have many limitations. The number of clusters are often unknown, which re- sults in region merging/splitting and also hinders the interpretation of the segmented images. Also, unsupervised methods mostly generate convex clusters, which leads to degradation in segmenta- tion quality. The aforesaid di culties do not arise in super- vised pixel classi cation, and several methods based on neural networks, genetic algorithms (Bandyopadhyay and Pal, 2001) has been devel- oped in this framework. Recently, support vector machines are becoming popular for classi cation of multispectral remote sensing images (Brown et al., 2000; Huang et al., 2002). The primary problem in supervised pixel clas- si cation is the pure availability of labeled data, which can be obtained only from ground truths and by costly manual labeling. Recently, active learning has become a popular paradigm for reducing the data requirement of large scale learning tasks (Angluin, 1988; Cohn et al., 1994). Here, instead of learning from random samples , the learner has the ability to select its own training data. This is done iteratively, and the output of a step is used to select the examples for the next step. Several active learning strategies exist in practice, e.g., error driven techniques, uncertainty sampling, version space reduction and adaptive resampling. Support vector machines (SVM) are particu- larly suited for active learning since a SVM clas- si er is characterized by a small set of support vectors (SVs) which can be easily updated over successive learning steps. One of the most e cient active SVM learning strategy is to iteratively re- quests the label of the data point closest to the current separating hyperplane or which violates the margin constraint maximally (Mitra et al., 2000; Campbell et al., 2000). This accelerates the learning drastically compared to random data selection. The above technique is often referred to as active/query SVM. Besides active SVM, another active learning strategy based on version space splitting is presented in (Tong and Koller, 2001). The points which split the current version space into two halves having equal volumes are selected at each step, as they are likely to be the actual support vectors. Three heuristics for approximat- ing the above criterion are described, the simplest among them selects the point closest to the current hyperplane as in (Campbell et al., 2000). A greedy optimal strategy for active SV learning is also de- scribed in (Schohn and Cohn, 2000). Here, logistic regression is used to compute the class probabili- ties, which is further used to estimate the expected error after adding an example. The example that minimizes this error is selected as a candidate SV. The present article describes a pixel classi ca- tion algorithm based on the query SVM algorithm. A conventional SVM is initially designed using a small set of points labeled manually. The SVM is subsequently re ned by actively querying for the labels of pixels from a pool of unlabeled data. The most interesting/ambiguous unlabeled point is queried at each step and is labeled by an human expert. It is seen that the above active learning strategy reduces the number of labeled data used by the SVM classi er by several orders compared to conventional SVM, while providing comparable segmentation quality. These features are demon- strated on an IRS-1A four band image. Compar- ison with related methods is made in terms of the number of data points used, computational time and a cluster quality measure. The article is organized as follows: the funda- mentals of support vector machines are brie y mentioned in Section 2. The active SVM learning algorithm for pixel classi cation is described in Section 3. Experimental results are provided in Section 4, followed by conclusions in Section 5. 2. Support vector machines Support vector machines are a general class of learning architecture inspired from statistical 1068 P. Mitra et al. / Pattern Recognition Letters 25 (2004) 1067 1074 learning theory that performs structural risk mini- mization on a nested set structure of separating hyperplanes (Vapnik, 1998). Given a training data, the SVM training algorithm obtains the optimal separating hyperplane in terms of generalization error. We describe below the SVM design algorithm for a two class problem. Multiclass extensions can be done by designing a number of one-against-all on one-against-one two class SVMs. Algorithm 1: Suppose we are given a set of examples x1; y1 ; . . . ; xl; yl , x 2 RN, yi 2 f1; 1g. We consider functions of the form sgn w x b , in addition we impose the condition inf i 1;...;l j w xi bj 1: 1 We would like to nd a decision function fw;b with the properties fw;b xi yi; i 1; . . . ; l. If this function exists, condition (1) implies yi w xi b P 1; i 1; . . . ; l: 2 In many practical situations, a separating hyper- plane does not exist. To allow for possibilities of violating Eq. (2), slack variables are introduced like ni P 0; i 1; . . . ; l; 3 to get yi w xi b P 1  ni; i 1; . . . ; l: 4 The support vector approach for minimizing the generalization error consists of the following: Minimize: U w; n w w C X l i 1 ni; 5 subject to the constraints (3) and (4). It can be shown that minimizing the rst term in Eq. (5), amounts to minimizing the VC-dimension, and minimizing the second term corresponds to minimizing the misclassi cation error (Burges, 1998). The above minimization problem can be posed as a constrained quadratic programming (QP) problem. The solution gives rise to a decision function of the form: f x sgn X l i 1 yiai x xi " b # : Only a small fraction of the ai coe cients are nonzero. The corresponding pairs of xi entries are known as support vectors and they fully de ne the decision function. The support vectors are geo- metrically the points lying near the class bound- aries. The linear SVM was described above. However, nonlinear kernels like polynomial, sigmoidal and radial basis functions (RBF) may also be used. Here, the decision function is of the form: f x sgn X l i 1 yiaij x; xi " b # : where j x; xi is the corresponding nonlinear ker- nel function. In remote sensing images, classes are usually spherical shaped and the use of spherical RBF kernel is most appropriate. RBF kernels are of the form j x1; x2 ewjx1x2j2. Again, the aforesaid two class SVM can easily be extended for multiclass classi cation by designing a number of one-against-all two class SVMs, e.g., a k-class problem is handled with k two class SVMs. 3. Active support vector learning for pixel classi - cation A limitation of the SVM design algorithm, de- scribed above, is the need to solve a quadratic programming (QP) problem involving a dense l l matrix, where l is the number of points in the data set. Since most QP routines have quadratic complexity, SVM design requires huge memory and computational time for large data applica- tions. Several approaches exist for circumventing the above shortcomings as well as to minimize the number of labeled points required to design the classi er. Many of them exploit the fact that the solution of the SVM problem remains the same if one removes the points that correspond to zero Lagrange multipliers of the QP problem (the nonSV points). The large QP problem can thus be broken down into a series of smaller QP problems, whose ultimate goal is to identify all of the P. Mitra et al. / Pattern Recognition Letters 25 (2004) 1067 1074 1069 nonzero Lagrange multipliers (SVs) while dis- carding the zero Lagrange multipliers (nonSVs). At every step, one solves a QP problem that con- sists of the nonzero Lagrange multiplier points from the previous step, and a number of other points queried. At the nal step, the entire set of nonzero Lagrange multipliers has been identi ed; thereby solving the large QP problem. The active SVM design algorithm used here for pixel classi- cation is based on the aforesaid principle. At each step the most informative point not belonging to the current SV set is queried along with its label; the goal is to minimize the total number of labeled points used by the learning algorithm. The method is described below and illustrated in Fig. 1. The steps need to be repeated k times for a k class problem with data from respective classes. Algorithm 2: Let x x1; x2; . . . ; xd represent a pixel of a d- band multispectral image. Here, xi is the grey value of the ith band for pixel x. Let A fx1; x2; . . . ; xl1g denote the set of pixels for which class labels are known, and B fx1; x2; . . . ; xl2g the set of pixels for which class labels are unknown. Usually, l2  l1. SV C denotes the set of support vectors of the set C obtained using the methodology de- scribed in Section 2. St fs1; s2; . . . ; smg is the support vector set obtained after tth iteration, and hwt; bti is the corresponding separating hypersur- face. Qt is the point actively queried for at step t. The learning steps involved are given below: Initial step: set t 0 and S0 SV A . Let the parameters of the corresponding RBF be hw0; b0i. While Stopping criterion is not satis ed: Qt fxj minx2B j wt; x g b. Request label of Qt. St SV St [ Qt . B B  Qt. t t 1. End while The set ST, where T is the iteration at which the algorithm terminates, contains the nal SV set representing the classi er. Stopping criterion: minx2B j wt x b > 1. In other words, training is stopped when none of the unlabeled points lie within the margin of the sep- arating hypersurface. Labeled Set A w > U < Seperating Hyperplane t SVM Design Algorithm SV( ) Stopping Criteria? NO YES SV Set Final SV Set = Actively Selected Set Sample Label of HUMAN EXPERT B Unlabeled Qt ST Qt ,bt St Fig. 1. Block diagram of the active SVM learning algorithm for pixel classi cation. 1070 P. Mitra et al. / Pattern Recognition Letters 25 (2004) 1067 1074 4. Experimental results and comparison The multispectral image data, used in our experiment, contains observations of the Indian Remote Sensing (IRS) satellite for the city of Mumbai, India. The data contains images of four spectral bands, namely blue, green, red and infra- red. The images contain 512 512 pixels and each pixel represents a 36.25 m 36.25 m region. Here the task is to segment the image into dif- ferent landcover regions, using four features (spectral bands). The image mainly consists of six classes e.g., clear water (ponds), turbid water (sea), concrete (buildings, roads, airport tarmacs), habi- tation (concrete structures but less in density), vegetation (crop, forest areas) and open spaces (barren land, playgrounds). A labeled set (A) containing 198 points is initially used. 4.1. Algorithms compared The performance of the active support vector learning algorithm (active SVM) is compared with the following multispectral image segmentation algorithms. Among them, methods SVM 1 and SVM 2 represent extreme conditions on the use of labeled samples. In SVM 1 the labeled set is very small in size but the labels are accurate, while in SVM 2 a large fraction of the entire data constitutes the labeled set, but the labels may be inaccurate. The k-means algorithm is a com- pletely unsupervised scheme requiring no class labels. (i) SVM 1: the conventional support vector ma- chine, using only the initial labeled set as the entire design set. (ii) k-means: the unsupervised k-means clustering algorithm. (iii) SVM 2: the conventional support vector ma- chine, using 10% of the entire set of pixels as the design set. The labels are supplied by the output of the k-means algorithm. 4.2. Evaluation criterion The image segmentation algorithms are com- pared on the basis of the following quantities: (i) Total number of labeled data points used in training (nlabeled). (ii) Training time (ttraining) on a Sun UltraSparc 350 MHz workstation. (iii) Quantitative cluster quality index (b), b is de- ned as (Pal et al., 2000) b Pk i 1 Pni j 1 Xij  X T Xij  X Pk i 1 Pni j 1 Xij  Xi T Xij  Xi ; 6 where ni is the number of points in the ith (i 1; . . . ; k) cluster, Xij is the feature vector of the jth pattern (j 1; . . . ; ni) in cluster i, Xi the mean of ni patterns of the ith cluster, n is the total number of patterns, and X is the mean value of the entire set of patterns. Note that the above measure is nothing but the ratio of the total variation and within-class varia- tion. This type of measure is widely used for fea- ture selection and cluster analysis (Richards, 1993; Pal et al., 2000). For a given image and k (number of clusters) value, the higher the homogeneity within the segmented regions higher would be the b-value. 4.3. Comparative results The performances of di erent multispectral image segmentation methods are presented in Table 1. Among them, the proposed active SVM learning algorithm provides the best segmentation quality as measured by the b index. The SVM 1 algorithm provides the lowest b-value, which is expected since it uses a very small number of training samples. The unsupervised k-means algo- rithm also provides much lower b-value compared to the active SVM algorithm. The SVM 2 algo- rithm uses the labels generated by the k-means Table 1 Comparative results for the IRS-1A image Method nlabeled ttraining (s) b active SVM 259 72.02 + (time for labeling 54 pixels) 6.35 SVM 1 198 28.15 3.45 k-means 0 1054.10 2.54 SVM 2 26,214 2.44 105 4.72 P. Mitra et al. / Pattern Recognition Letters 25 (2004) 1067 1074 1071 algorithm, but provides a relatively small improvement in performance compared to k- means. The visual quality of the classi ed images (Fig. 2) also reinforce these conclusion. Among the supervised classi cation algorithms, namely, active SVM, SVM 1 and SVM 2, SVM 1 uses the least number of labeled samples and has minimum training time. However, the active SVM algorithm uses only 54 additional labeled points compared to SVM 1 with a substantial improve- ment in segmentation quality. This is due to the fact that the additional points queried by active SVM were the most informative ones and con- tributed to the increase in segmentation quality. Fig. 2. IRS-1A: (a) original band four image; classi ed image using (b) active SVM, (c) SVM 1, (d) k-means, and (e) SVM 2. 1072 P. Mitra et al. / Pattern Recognition Letters 25 (2004) 1067 1074 On the other hand, SVM 2 uses a large sized la- beled set, consisting of randomly chosen points, for training. Since, accurate labels for the large training set used were not available, slightly inac- curate labels were used. The overall e ect being: the performance of the SVM 2 algorithm is poorer compared to active SVM inspite of it requiring a much higher computation time. The variation in segmentation quality (as mea- sured by b index) with the number of labeled samples queried by the active SVM algorithm is shown in Fig. 3. It is seen that the initial SVM designed using the training set of SVM 1 provides a b-value of 3.45 which subsequently increases as more point are queried to a nal value of 6.35. 5. Conclusions and discussion We have presented an active support vector learning algorithm for supervised pixel classi ca- tion in remote sensing images. The goal is to minimize the number of labeled points required to design the classi er. The algorithm uses an initial set of small number of labeled pixels to design a crude classi er, which is subsequently re ned by using more number of points obtained by querying from a pool of unlabeled pixels. The class labels of the queried points are supplied by a human expert. It is seen that the number of labeled points re- quired by the active learning algorithm is far less compared to the conventional support vector machine. It also provides better accuracy com- pared to completely unsupervised segmentation algorithms or a supervised algorithm having access to only inaccurate class labels of a large number of pixels. The active learning strategy adopted in this article queries for the most interesting/ambiguous unlabeled point as measured by its distance from the current separating hypersurface. Other query strategies based on version space splitting, logistic regression may be used. Also, besides active learning, other semi-supervised learning tech- niques like transductive learning, co-training may also help in circumventing the problem arising from scarcity of labeled data in remote sensing image analysis. The main goal of the active learning algorithm is to reduce the requirement of labeled pixels. Hence, an aggressive query strategy is adopted. However, the aggressive strategy is sensitive to wrong labeling by a human expert, resulting in performance degradation. If in some application, a higher number labeled pixels, with possibly few wrong labels, are available, a more conservative query strategy will provide better performance. References Angluin, D., 1988. Queries and concept learning. Machine Learning 2, 319 342. Bandyopadhyay, S., Pal, S.K., 2001. Pixel classi cation using variable string genetic algorithms with chromosome di er- entiation. IEEE Transactions on Geoscience and Remote Sensing 39 (2), 303 308. Baraldi, A., Parmiggiani, F., 1995. A neural network for unsupervised categorization of multivalued input pattern: An application to satellite image clustering. IEEE Transac- tions on Geoscience and remote Sensing 33, 305 316. Brown, M., Lewis, H.G., Gunn, S.R., 2000. Linear spectral mixture models and support vector machines for remote sensing. IEEE Transactions on Geoscience and Remote Sensing 38 (5), 2346 2360. Burges, C.J.C., 1998. A tutorial on support vector machines for pattern recognition. Data Mining and Knowledge Discov- ery 2 (2), 1 47. Campbell, C., Cristianini, N., Smola, A., 2000. Query learning with large margin classi ers. In: Proc. 17th Internat. Conf. 200 210 220 230 240 250 1 1.5 2 2.5 3 3.5 4 4.5 5 5.5 6 No. of labeled points used Fig. 3. Variation of b-value with the number of labeled data points used by the active SVM algorithm. P. Mitra et al. / Pattern Recognition Letters 25 (2004) 1067 1074 1073 on Machine Learning. Morgan Kaufman, Stanford, CA, pp. 111 118. Cannon, R.L., Dave, R., Bezdek, J.C., Trivedi, M., 1986. Segmentation of a thematic mapper image using fuzzy c- means clustering algorithm. IEEE Transactions on Geosci- ence and remote Sensing 24, 400 408. Cohn, D., Atlas, L., Ladner, R., 1994. Improving general- ization with active learning. Machine Learning 15, 201 221. Dempster, A.P., Laird, N.M., Rubin, D.B., 1977. Maximum likelihood from incomplete data via the EM algorithm. Journal of the Royal Statistical Society, Series B 39, 1 38. Huang, C., Davis, L.S., Townshend, J.R.G., 2002. An assess- ment of support vector machines for land cover classi ca- tion. International Journal of Remote Sensing 23, 725 749. Laprade, R.H., 1988. Split-and-merge segmentation of aerial photographs. Computer Vision Graphics and Image Pro- cessing 48, 77 86. Mitra, P., Murthy, C.A., Pal, S.K., 2000. Data condensation in large databases by incremental learning with support vector machines. In: Proc. Internat. Conf. Pattern Recognition (ICPR2000), Barcelona, Spain. pp. 712 715. Pal, S.K., Ghosh, A., Uma Shankar, B., 2000. Segmentation of remotely sensed images with fuzzy thresholding, and quan- titative evaluation. International Journal of Remote Sensing 21 (11), 2269 2300. Pal, S.K., Mitra, P., 2002. Multispectral image segmentation using the rough set initialized EM algorithm. IEEE Trans- actions on Geoscience and Remote Sensing 40 (11), 2495 2501. Richards, J.A., 1993. Remote Sensing Digital Image Analysis: An Introduction. Springer Verlag, New York. Schohn, G., Cohn, D., 2000. Less is more: Active learning with support vector machines. In: Proc. 17th Internat. Conf. Machine Learning, Morgan Kaufman, Stanford, CA, pp. 839 846. Tong, S., Koller, D., 2001. Support vector machine active learning with application to text classi cation. Journal of Machine Learning Research 2, 45 66. Vapnik, V., 1998. Statistical Learning Theory. Wiley, New York. Wong, Y.-F., Posner, E.C., 1993. A new clustering algorithm applicable to polarimetric and SAR images. IEEE Trans- actions on Geoscience and Remote Sensing 31 (3), 634 644. 1074 P. Mitra et al. / Pattern Recognition Letters 25 (2004) 1067 1074