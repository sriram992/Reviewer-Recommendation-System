PAMMELA: Policy Administration Methodology using Machine Learning Varun Gumma1, Barsha Mitra2, Soumyadeep Dey3, Pratik Shashikantbhai Patel2, Sourabh Suman2, Saptarshi Das4 1Department of Computer Science and Engineering, IIT Madras, Chennai, India 2Department of CSIS, BITS Pilani, Hyderabad Campus, Hyderabad, India 3 Microsoft IDC, India 4 JIS Institute of Advanced Studies and Research, JIS University, Kolkata, India Abstract In recent years, Attribute-Based Access Con- trol (ABAC) has become quite popular and effective for enforcing access control in dynamic and collaborative envi- ronments. Implementation of ABAC requires the creation of a set of attribute-based rules which cumulatively form a policy. Designing an ABAC policy ab initio demands a substantial amount of effort from the system administra- tor. Moreover, organizational changes may necessitate the inclusion of new rules in an already deployed policy. In such a case, re-mining the entire ABAC policy will require a considerable amount of time and administrative effort. Instead, it is better to incrementally augment the policy. Keeping these aspects of reducing administrative overhead in mind, in this paper, we propose PAMMELA, a Policy Administration Methodology using Machine Learning to help system administrators in creating new ABAC policies as well as augmenting existing ones. PAMMELA can gener- ate a new policy for an organization by learning the rules of a policy currently enforced in a similar organization. For policy augmentation, PAMMELA can infer new rules based on the knowledge gathered from the existing rules. Experimental results show that our proposed approach provides a reasonably good performance in terms of the various machine learning evaluation metrics as well as execution time. Keywords ABAC, Policy Administration, Policy Augmen- tation, Policy Adaptation, Supervised Learning I. INTRODUCTION In any organization, it is of utmost importance to ensure that all accesses to resources take place in an authorized manner. This can be facilitated through an access control model. Over the years, several access control models have been proposed like the Discretionary Access Control (DAC) model [11], the Mandatory Access Control (MAC) model [27] and the Role-Based Access Control (RBAC) [26] model. Over the years, RBAC became quite popular as an effective means of access control. The model has been successfully deployed in various organizations and has been incorporated in a number of products and platforms. The pivotal element of RBAC is roles. In spite of its widespread popularity, the RBAC model suffers from a major drawback of being unsuitable for dynamic environments. In such environments, it is not possible to know apriori the set of all users and the different types of access requests that may occur. Moreover, in situations where two or more organizations interact in a collaborative manner, RBAC cannot be implemented to enforce access control among the different organizations. The reason behind this is that the role de nitions (in terms of the included permissions) of various organizations may not be the same. Such situations may re- quire the creation of temporary roles in order to facilitate the collaborative interaction. The Attribute-Based Access Control (ABAC) model [13] was proposed for facilitating access control in dynamic and collaborative environments. ABAC encompasses the properties as well as the bene ts of DAC, MAC and RBAC. This model allows users to access resources based on the properties of the users, resources and the environment. As per the terminologies of ABAC, the users, the resources and the properties are referred to as subjects, objects and attributes respectively. Each attribute is assigned a value or multiple values from a pre- de ned set of values for every subject, object and environmental condition. In order to determine whether to allow or deny an access request, the attributes of the requesting subject, requested object as well as those of the environment in which the access request is made are taken into account. If each attribute has been assigned a speci c value, then the access request is allowed, otherwise, it is denied. In order to deploy ABAC, a set of rules is required. A rule de nes the required attributes and the corresponding permissible values for each attribute for a speci c type of access. The set of all rules collectively comprise a policy. The process of creating a policy for implementing ABAC is known as policy engineering. Policy engineering can be carried out in two ways - top-down [22] and bottom-up [9], [18], [20], [30]. Bottom-up policy engineering is also termed as policy mining. In the current literature, the policy mining problem has been formulated as a minimization problem. Combining top-down and bottom-up approaches gives hybrid policy engineering [7]. An organization intending to migrate to ABAC requires designing an ABAC policy. Also, when an organization having an already deployed ABAC model, undergoes some changes (like the opening of a new department or the introduction of a new academic course), additional ABAC rules re ecting the changes need to be generated. Creating ABAC rules ab initio or completely re-mining an ABAC policy requires a considerable amount of administrative effort and time. These overheads can be substantially reduced if an existing policy is used as a reference for the creation of a new ABAC policy for migration. Also, instead of re-mining the complete policy in order to account for the organizational changes, it is more prudent to only create the additional rules. In both the scenarios, the existing ABAC policy can aid the process of creation of new ABAC rules, thereby reducing the effort and overhead of policy administration. arXiv:2111.07060v1 [cs.CR] 13 Nov 2021 In this paper, we propose a methodology that will aid ABAC system administrators in ef ciently augmenting an existing policy by including additional rules in order to accommodate various organizational alterations as well as generating a new ABAC policy for an organization by referring to the existing policy of a similar organization. Our proposed approach focuses on policy creation through a technique which is based on the information contained in an existing policy. The strategy makes use of machine learning techniques that are trained using the currently deployed policy. After training, our methodology generates new access rules from a set of access requests that they are not covered by the existing rules. The main contributions of the paper are summarized below. We propose the ABAC Policy Inference Problem (ABAC- PIP) which takes as inputs an existing ABAC policy and a set of access requests and creates a new set of ABAC rules that either augments the existing policy or creates a new policy. It is to be noted here that the rules that are created are considered as new since they are different from the existing ones in terms of certain attribute values. We propose a machine learning based methodology for solving ABAC-PIP that makes use of supervised learning. We train a machine learning classi er using the existing ABAC policy. The training includes both positive (rules that grant accesses) as well as negative (rules that deny accesses) rules. After training, the classi er is supplied with a set of access requests (ones that should be allowed and ones that should be disallowed). Based on these, the machine learning algorithm generates a new set of access rules. We name our approach as Policy Administration Methodology using Machine Learning (PAMMELA). We propose two techniques in order to enhance the performance of PAMMELA based the intrinsic relations that exist among the different attributes and the grouping of similar attribute values. We test our proposed policy inferring methodology on three manually crafted datasets. These datasets have been carefully created by keeping in mind real-world scenarios. Our experiments show that PAMMELA shows promising results and provides a high degree of performance. We have experimented with a number of machine learning classi ers and show a comparative result for all them. The rest of the paper is organized as follows. Section II explores the different policy mining approaches present in the existing literature. In Section III, we review the preliminary concepts related to the ABAC model and supervised learning. We formulate the problem de nition of ABAC-PIP in Section IV and present the corresponding solution strategy PAMMELA along with a discussion of the application scenarios and the learning enhancement techniques in Section V. Dataset de- scription, evaluation metrics and the experimental results are presented in Section VI. Finally, Section VII concludes the paper with some insights into future research directions. II. RELATED WORK A considerable number of work has focused on developing techniques for creation of ABAC policies. Xu and Stoller proposed one of the earliest ABAC policy mining algorithms from access logs [29]. Another work by Xu and Stoller aims at generation of ABAC policies from access control lists and attribute data given as inputs [30]. They have formulated the ABAC policy mining problem as an optimization problem and have proposed weighted structural complexity as the policy quality metric. Talukdar et al. [28] have proposed ABAC- SRM, a bottom-up policy mining method capable of creating generalized ABAC rules. Cotrini et al., in [5], have proposed Rhapsody, a policy mining technique that can handle sparse inputs and have de ned a rule quality metric called reliability. An attribute-based rule mining algorithm has been proposed in [25] from the audit logs of an organization that can minimize the under and over privileges for enforcing the principle of least privilege. The authors also propose a scoring method for determining the quality of a policy from a least privilege point of view. [1] proposes a methodology that can extract ABAC constraints in an automated manner from policies expressed in natural language. A constrained policy mining technique has been proposed in [9]. In [18], the authors have proposed a pol- icy engineering approach that considers the risk associated with the improper use and possible abuse of a permitted access to a user. Lawal and Krishnan have proposed an approach for policy administration in ABAC via policy review [19]. Heutelbeck et al. [12] have designed a data structure for ef ciently indexing policy documents and have proposed a method for nding the relevant policy documents for a particular access request. Several incremental and adaptive policy generation tech- niques are present in the current literature. Das et al. [6] have proposed a policy adaptation strategy between similar organizations. In this context, they have formulated the Policy Adaptation Problem (PolAP) which aims at determining the value assignments of the attributes of each subject for a given ABAC policy. They have proved the problem to be NP- complete and have proposed a heuristic algorithm for solving it. It can be noted that our proposed ABAC-PIP is different from PolAP both in terms of the inputs and the output. Das et al. have further extended their work in [8] by considering hierarchical relationships among subject attribute values and also taking into account environmental attributes. Batra et al. [3] have proposed an incremental policy mining technique that is capable of creating new ABAC rules in the event of any one of the following occurrences - (i) addition of a permission, (ii) deletion of a permission, (iii) addition of an attribute value and (iv) deletion of an attribute value. In [2], the authors have presented a strategy for determining policy similarity, have proposed two methods for performing policy reconciliation and also presented a policy migration technique. The rapid growth of arti cial intelligence has ushered in a widespread application of different machine learning and deep learning algorithms in the eld of access control. In [20], the authors have presented a policy generation technique using Restricted Boltzmann Machines. Karimi et al. in [17] have proposed an automated policy learning method from access logs using unsupervised learning by considering both positive and negative rules. Their approach can handle noisy data as well as sparseness of logs. The authors have also proposed rule pruning and policy re nement techniques. [14] presents a framework known as Polisma for learning ABAC policies from access logs by using a combination of statistical, data mining and machine learning algorithms. In [16], the authors have designed a policy learning method that is adaptive in nature using a feedback loop and is applicable for home Internet of Things (IoT) environment. They have modeled the problem of ABAC policy learning as a reinforcement learning problem. Very recently, Bertino et al. have proposed an approach known as FLAP [15] for collaborative environments. FLAP enables one organization to learn policies from another organization and perform policy adaptation via a policy learning framework by using local log or local policies or local learning or hybrid learning. This work makes use of Polisma [14]. In this work, we employ machine learning algorithms for the purpose of generating ABAC rules. We have also formulated the corresponding policy creation problem variant and have named it as the ABAC Policy Inference Problem (ABAC-PIP). To the best of our knowledge, such kind of problem formulation and the design of end-to-end machine learning based solution strategy have rarely been addressed in the existing literature. III. BACKGROUND In this section, we present some preliminaries related to the ABAC model and supervised learning techniques. A. ABAC Model The ABAC model consists of the following components: A set S of subjects or users. Each subject can be a human being or a non-human entity. A set O of objects. Each object corresponds to a system resource that should be accessed in an authorized manner. A set E of environmental factors or conditions. Each condition can represent some temporal or spatial or some other kind of context in which a user requests access to a resource. Examples of environmental conditions can be location, time, temperature, etc. A set SA of subject attributes. Each subject attribute represents a property associated with a subject and can assume a single or multiple values from a set of values. These values are known as subject attribute values. If a subject attribute assumes a single value, it is known as atomic valued. If it is assigned multiple values for a subject simultaneously, it is known as multi-valued. An example of a subject attribute is Department. The attribute value set of Department can include Computer Science, Electronics, and Mechanical. Sometimes a spe- ci c subject attribute of a user may not be meaningful. Such a scenario can be represented by assigning the value Not Applicable for that attribute. A set OA of object attributes. All the concepts mentioned for subject attributes are applicable for object attributes as well. An example of an object attribute is Type of Document and its possible values can be Project Plan, Budget, Expenditure Details etc. A set EA of environmental attributes. All the concepts discussed for subject attributes also apply for environ- mental attributes. Example of an environmental attribute can be Time of Doctor s Visit and the possible values can be Day Shift and Night Shift. A function Fsub that assigns values to subject attributes of a subject. Formally, Fsub: S x SA {vs | vs is a subject attribute value}. For eg., Fsub(John, Department) = {Computer Science}. A function Fobj that assigns values to object attributes of each object. Formally, Fobj: O x OA {vo | vo is an object attribute value}. For eg., Fobj(File1.doc, Type of Documet) = {Project Plan}. A function Fenv that assigns values to environmental attributes. Formally, Fenv: E x EA {ve | ve is an environmental attribute value}. A set P of operations or permissions. Common types of operations/permissions include read, write, update, execute, etc. A set R of rules. Each rule speci es whether a particular type of access is to be granted or denied. A rule that permits an access is termed as a positive rule and a rule that disallows an access is termed as a negative rule. All the rules cumulatively constitute an ABAC policy. An example ABAC rule can be of the following form - {Department = Accounts, Designation = Accountant}, {Type = Payroll Data, Department = Any}, view . In natural language, this rule translates to - If a subject belongs to the Accounts department and has a Designation of Accountant, then she can view the payroll data of any employee belonging to any department. Here, the value Any is used to express the rule in a generalized form. B. Supervised Learning Supervised learning is a class of machine learning algorithms that are used either to classify data or to predict some type of outcomes based on labeled data. The machine learning model is trained using the labeled data. This training enables the model to learn the class type or the outcome for a given combination of parameter values. The trained model is used to assign the class labels or predict the outcomes of unlabeled data points. Supervised learning can address two types of problems - 1. Classi cation: Here the machine learning algorithm has to categorize inputs (or data points) into different classes. Eg., Support Vector Machine [21], k-Nearest Neighbour [21], Decision Tree [24], Random Forest [4], GradientBoost [23], XGBoost [23], etc. 2. Regression: Here the machine learning algorithm makes predictions for unknown data points. Examples include Linear Regression [21], Logistic Regression [21]. In this work, we have used only classi cation algorithms. IV. ABAC POLICY INFERENCE PROBLEM Designing ABAC policies is not a trivial task and requires a considerable amount of administrative effort. The overhead associated with the process of policy generation can be reduced if some existing policy serves as a reference point or guideline based on which new policies can be inferred. This observation is applicable both for the case of augmenting an existing policy database by incrementally adding new rules as well as creating a new policy for an organization that has a similar structure as that of another organization where an ABAC policy is already deployed. In order to achieve this goal of aiding the policy administration process, we propose the ABAC Policy Inference Problem (ABAC-PIP). In this section, we present the formal de nition of our proposed problem. ABAC-PIP gathers information from an existing policy and then creates new rules based on that learning. This problem variant takes a deployed ABAC policy, a set of subjects, a set of objects, a set of subject attributes and their corresponding values, a set of object attributes and their corresponding values and a set of access requests as inputs and produces as output, for each access request, the set of permissions or operations required to carry out the designated task in case the access request is to be granted or the decision to deny the request if it is an unauthorized one. The formal problem de nition is presented below. De nition 1. ABAC-PIP Given an ABAC policy P, a set S of subjects, a set O of objects, a set SA of subject attributes, a set OA of object attributes, a function Fsub de ning the value assignment of the subject attributes of each subject, a function Fobj de ning the value assignment of object attributes of each object, and a set L of access requests as inputs, determine, corresponding to each access request, the set of permissions (or operations) Pr, required to execute the access request if the access request is to be permitted or else output the decision to deny the access request if it is not to be permitted. The following underlying assumptions have been made for ABAC-PIP. The access requests present in the set L are new access requests and the corresponding decisions cannot be deter- mined by the rules present in the already deployed ABAC policy P. The access requests contained in L are derived from access logs of an organization. The access requests of L include both positive and nega- tive access requests. Positive access requests are the ones which are to be granted and negative access requests are those which are to be denied. The new access requests are generated when an or- ganization having a deployed ABAC model undergoes some changes. Such changes necessitate the creation of additional rules corresponding to the new access requests that will take place. An example of such a change can the opening of a new department or the introduction of a new job designation. The new access requests can also be generated when an organization wishes to migrate to ABAC. This organi- zation is similar in structure and work ow to another organization where ABAC has already been deployed. For the new access requests, the relevant information regarding the value assignment for the subject and object attributes are available. In the following section, we discuss the applicability of ABAC-PIP to two policy administration scenarios and present the solution strategy that assists the corresponding policy administration tasks. V. PROPOSED METHODOLOGY We propose a machine learning based methodology for solv- ing ABAC-PIP. Our approach is capable of helping system ad- ministrators in creating ABAC policies and in the process, can reduce the overhead associated with policy creation. We name our proposed framework as Policy Administration Methodology using Machine Learning (PAMMELA). In this section, we rst present a detailed overview of how PAMMELA solves ABAC- PIP and then elaborate on the scenarios where PAMMELA is applicable. We also present two techniques that we have designed to improve the overall performance of PAMMELA. A. PAMMELA ABAC-PIP has a direct correlation with the process of in- ferring new ABAC rules. We propose a methodology named as PAMMELA for solving ABAC-PIP. PAMMELA is a supervised learning based solution strategy that works in two phases. In the rst phase, a machine learning classi er is trained using a set of labeled data. This labeled data is in the form of an ABAC policy consisting of several rules. Each rule de nes the combination of the subject attribute-value pairs and the object attribute-value pairs for which a subject will be allowed to access and perform certain operations or acquire some permissions for an object. We refer to such rules as positive rules. The attributes are treated as features by the classi er. The positive rules help the classi er in learning under which conditions, an access request is to be granted and what are the corresponding permissions associated with the access. In addition to this, it is also essential for the classi er to learn when an access request is to be denied. Such scenarios are covered by the negative rules. A negative rule speci es the attribute-value pairings for which an access request is not permissible. For negative rules, all those attribute-value pairs are considered which lead to unauthorized accesses, not just the ones which explicitly deny accesses. Such negative rules can be derived from the set of positive rules. If U denotes the set of all possible attribute-value pairings (both subject and object) and PR denotes the set of positive rules, then the set of negative rules NR = {U} \ {PR}. Though it is straightforward to derive the elements of NR, the task, however, is not trivial. The reason behind this is that, generally in any organization, the set of rules disallowing accesses is much larger in size than the set of rules allowing accesses. In PAMMELA, the machine learning classi er is also trained using the negative rules. In this case, the classi er learns to output denial as a decision. For supplying the training data, it needs to be encoded in a format that is understandable to the machine learning algorithm. This is done by making use of categorical data. Each subject and object attribute value is assigned a numerical value. For eg., If we have a subject attribute value Designation having values Assistant Professor, Associate Professor and Professor, then Assistant Professor can be assigned the value 1, Associate Professor can be assigned the value 2 and Professor can be assigned the value 3. If a particular subject attribute is not applicable for a certain user, then a special value NA (for Not Applicable) is assigned as the attribute value for that subject. For each attribute value set, the categorical encoding starts in- creasing monotonically from 1. The reason for using categorical encoding is a reduced input vector size in comparison to the vector size that is obtained for one-hot encoding. After training, PAMMELA generates new rules in the second phase which is the testing phase for the machine learning classi er. Here, a set of access requests is given as input to the classi er. The combinations of the attribute values present in these access requests are different from those present in the existing policy rules. Such new combinations of values can occur when either the subject attribute value set(s) or the object attribute value set(s) or both are augmented with additional values. Both positive and negative access requests are given as input to PAMMELA in the second phase. Positive access requests are those which are to be granted. Negative access requests are those which are to be denied. The reason for including both positive and negative access requests is that when the already deployed policy cannot account for the organizational changes, then any type of access request needs to be appropriately classi ed. We assume that for each of the new access requests, the relevant attribute-value pair assignment information are available. Based on the learning achieved in the rst phase, the new access requests and the attribute- value information, PAMMELA classi es each access request by determining whether it is to be allowed or disallowed. If the access request is to be disallowed, PAMMELA outputs the decision NO. On the other hand, if the access request is to be granted, PAMMELA outputs the set of permissions or operations required to successfully execute the access request in addition to the decision of Y ES. Once the relevant decisions have been derived, the newly generated rules are added to the policy database. The work ow of PAMMELA is depicted in Figure 1. It needs to be mentioned here that since PAMMELA is trained using an existing set of rules, we do not need to worry about the lack or absence of labeled data. Hence, we can use supervised machine learning techniques in our methodology. Fig. 1. Block Diagram depicting the work ow of PAMMELA B. Policy Administration via Augmentative Policy Infer- ence Undergoing structural and functional changes is not uncom- mon for any organization. Examples of such changes include but are not limited to the following: An organization can start a new department. An organization can introduce a new job designation. An educational institute can introduce a new degree program. An educational institute can introduce a new undergrad- uate or graduate level course. A hospital can start treating patients in a new specializa- tion. These types of changes increase the breadth of the work ow of the organization and may not be too frequent. However, whenever they do occur, there arises a need to modify or update the access control policy in order to prevent any form of unauthorized access or leakage of rights. Updating the policy by re-executing the policy mining process involves a lot of overhead. Moreover, it increases the overall time required to manage the update process. Hence, it is prudent to design only the new rules and add them to the policy database. The types of changes considered here are not radical enough to completely alter the organizational structure. Hence, the new rules that need to be designed will have some similarity with the existing rules. More speci cally, the new rules will differ from the current ones in terms of one or more attribute values. Also, the permission or operation set associated with a new rule will be same as that of an equivalent existing rule. Manually augmenting the policy database is a very challenging task even for a moderate sized organization. Our proposed methodology PAMMELA can perform au- tomated augmentation of a deployed policy. We name this application of PAMMELA as Augmentative Policy Inference. PAMMELA can determine the relevant decisions for both positive and negative accesses, thereby augmenting the policy database by inferring and adding new ABAC rules. Other than providing the categorical encoding for the new attribute val- ues, our proposed approach completely eliminates any human intervention in the policy augmentation process. Of course, the underlying assumption here is that an organization needs to have an already deployed ABAC policy in order to perform policy augmentation using PAMMELA. We assume that the subject attribute value set as well as the object attribute value set are augmented with new values. This kind of attribute value introduction accounts for the different organizational changes. We elaborate the observations made above using the fol- lowing examples. Suppose an XY Z university has two de- partments - Computer Science and Electronics. The university has deployed the ABAC model for access control. We con- sider one subject attribute User-Type and one object attribute Resource-Type. Values of User-Type are Faculty, Student and Teaching-Assistant. Values of Resource-Type are Question- Paper, Answer-Script, Assignment and Mark-Sheet. The uni- versity management decides to open a new department, In- formation Technology. The rules governing the access of the different resources by the users belonging Computer Science and Electronics, will no doubt be applicable for Information Technology. The new rules will have the Department attribute value as Information Technology. Another example can be that, if the Computer Science department wishes to introduce a new evaluation component, Quiz, then the rules for Quiz will be similar to those associated with the access of the existing component Assignment. C. Policy Administration via Adaptive Policy Inference When an organization intends to migrate to ABAC, a policy needs to be designed ab initio using a policy generation approach. The input to the policy creation process can be an access log consisting of a set of access requests. A considerable amount of administrative overhead associated with this task can be reduced if some already deployed ABAC policy is available which can serve as a guideline or reference point. Henceforth, we shall refer to this existing policy as reference policy and the new policy that is to be designed as target policy. It is to be noted here that the structure of the organization where the reference policy is deployed is assumed to be similar to the structure of the organization that wishes to implement ABAC. In such a scenario, the rules present in the reference policy can be adapted to generate the target policy. The adaptation process will handle the dissimilarities present between the rules of the reference policy and the target policy in terms of the subject and object attribute values. We explain the adaptive policy inference task using an example. We take the example of XY Z university mentioned in Sub-section V-B having two departments, Computer Science and Electronics. The subject as well as object attributes and their corresponding values are the same as those mentioned in the previous sub-section. Suppose, another educational institute, PQR wishes to adopt the ABAC model. PQR has two departments, Mechanical Engineering and Civil Engineering. PQR has the same subject and object attributes as those of XY Z. The subject attribute values of PQR are also same as those of XY Z. For the object attribute values, PQR has an additional value Presentation apart from those present for XY Z. The evaluation component Presentation requires the same type of accesses as that of Assignment. The rules that need to be implemented for PQR have the same structure as those of XY Z and hence, can be inferred by taking the rules of XY Z as reference. In this way, the reference policy of XY Z can be appropriately adapted to create the target policy for PQR. The above mentioned scenario relates to ABAC-PIP and therefore, can be solved using our proposed methodology. The reference policy will serve as an input to the machine learning classi er in the training phase. In order to generate the target policy, the access requests present in the access logs of the organization that wishes to implement ABAC will be supplied to the classi er in the testing phase. Here, we again assume that both positive and negative requests are given to the classi er. Also, the attribute-value assignment information is available in the access logs or in some other data repository. Based on the learning accomplished during training, the classi er will output a NO or a YES . For a grant decision, the set of permissions associated with the access will also be generated. Finally, the output of the second phase combined with the attribute-value assignment information will create the target ABAC policy. One assumption associated with the adaptive policy inference task using PAMMELA is that the set of permissions or operations associated with each rule of the target policy is the same as that of a corresponding rule of the reference policy. Several recent works like [6], [8], [14] and [15] have addressed the problem of policy adaptation. The approaches proposed in [6] and [8] do not make use of machine learning. The techniques in [14] and [15] use machine learning along with a number of heuristic methods. To the best of our knowl- edge, our proposed methodology PAMMELA is the rst end- to-end machine learning based strategy for policy adaptation. D. Discussion PAMMELA offers the advantage of completely automating the tasks of augmentative as well as adaptive policy inference. Needless to say that if these tasks are carried out manually, it requires a huge amount of effort to painstakingly scan through the policy database to determine which existing rules are most similar to the rules that are to be created and generate the new rules. If the tasks are carried out manually, the entire process becomes very time consuming quite prone to errors. The tasks can be accomplished using heuristic methods but at the cost of designing several functions covering different scenarios and running several experiments to determine the best possible strategy. If each strategy executes for a considerable amount of time, then selection of the most suitable approach will involve a lot of time overhead even before the actual augmentation or adaptation process. PAMMELA eliminates all the above mentioned issues by providing an end-to-end automated solution. This is substantiated in the experimental results presented later. E. Learning Enhancement Techniques In this sub-section, we present two techniques that we have designed to enhance the learning capability of PAMMELA for better performance. The rst technique aims at extracting a set of features depending upon the relationships existing among the subject and object attributes. We name this technique as Attribute Relation based Feature Extraction (ARFE). The second one deals with the creation of a categorical encoding that is to be fed to the machine learning classi er based on similar types of subject and object attribute values. We name the second approach as Attribute Value Clustering (AVC). Details of the two techniques are presented as follows. 1) Attribute Relation based Feature Extraction: At- tribute Relation based Feature Extraction (ARFE) tries to capture the relationships that exist among subject and object at- tributes. An example of such a relation is - A student registered to the Database Systems course can access the assignment of the same course. Here, the attribute Course is associated with both the subject Student as well as the object Assignment. This implies that if an attribute is present both as a subject and an object attribute and have the same value, then most likely, the subject is eligible to access the object. We use the term most likely because the nal access decision can be dependent upon other attribute values or similar other such attribute relations. In order to capture this type of relationship between pairs of common subject and object attributes, we introduce additional features. Suppose an attribute Attr is present in a rule or an access request as a subject as well as an object attribute. We denote Attr as a subject attribute by S Attr and Attr as an object attribute by O Attr. We introduce a new feature FAttr which assumes different values based upon the attribute values of S Attr and O Attr. The number of new features introduced is equal to the number of such common subject and object attributes. 2) Attribute Value Clustering: In Attribute Value Clus- tering (AVC), we group the different values of a particular attribute based on their similarity. Suppose we have an attribute Resource-Type which has the following values - Quiz, As- signment, Question-Paper, Answer-Script, Department-Of ce- Record and Department-Budget. It can be easily concluded that Quiz and Assignment, Question-Paper and Answer-Script and Department-Of ce-Record and Department-Budget are similar types of resources. Such similarity implies same types of accesses. Consequently, the rules governing the access to these similar types of resources will follow the same structure and format. This observation holds true for any type of attribute. AVC attempts to capture the grouping of attribute values of any attribute depending upon the functional alikeness among the values. This clustering of similar attribute values is captured in the categorical encoding used in PAMMELA. We feel that the use of AVC in conjunction with PAMMELA will improve the overall performance of deriving new rules. VI. EXPERIMENTAL RESULTS In this section, we evaluate the performance of our proposed approach. First, we present a description of the datasets that we have used for experimental evaluation. We then discuss about the metrics used for evaluating the performance of PAMMELA. Finally, we report the experimental ndings. TABLE I ATTRIBUTE-VALUE COUNT FOR UNIVERSITY DATASET 1 Attribute-Name Attribute-Type No. of Values Designation Subject 3 Department Subject 4 Degree Subject 2 Year Subject 4 Resource-Type Object 7 Department Object 4 Degree Object 2 Year Object 4 A. Dataset Description For the purpose of experimentation, we have manually created three datasets. Each dataset consists of two parts: An ABAC policy consisting of a number of rules A set of access requests along with the attribute-value assignment information The rst part of the dataset, i.e., the ABAC policy is used in the training phase of PAMMELA. This corresponds to the existing or the reference policy that we have mentioned earlier. The set of access requests and the attribute-value assignment information are used in the testing phase. We have not used any synthetic dataset generator or simu- lator for creating the datasets. The datasets have been created keeping real-world scenarios in mind. We have generated the set of subjects, objects, subject attributes, object attributes and their corresponding values in such a way that they mimic real- life organizations. The rules as well as the access requests of each dataset are similar to actual organizational accesses. For each of the datasets, we have considered only one permission corresponding to the ability of a subject to access a given resource or the denial of access. However, PAMMELA is capable of handling multi-permission scenarios. The different aspects of each dataset are described below: University Dataset 1: We have designed a dataset to mimic the work ow of an educational institute and have named it as University Dataset 1. It contains the following subject attributes - Designation, De- partment, Degree and Year. The object attributes are Resource- Type, Department, Degree and Year. Table I shows the details regarding the number of values associated with each attribute of the dataset. The training data contains 53 rules. The test data contains 1010 access requests out of which 598 are positive requests and 412 are negative requests. In the test data, the subject attributes for which new values have been added are Designation, Department, and Degree and the object attributes for which new values have been introduced are Resource-Type, Department and Degree. University Dataset 2: Another dataset has been designed keeping in mind the struc- ture of an educational institute and has been named as Uni- versity Dataset 2. However, there exists several differences between this dataset and the previous one. University Dataset 2 is much more detailed than University Dataset 1 both in terms of the attributes, their corresponding values as well as the number of rules present in the training data. The subject attributes considered in this dataset are Designation, Post, Course, Department, Degree and Year. The object attributes are Resource-Type, Course, Department, Degree and Year. Table II shows the details regarding the number of values associated with each attribute of the dataset. The training data contains 1,56,775 rules and the test data contains 483 access requests out TABLE II ATTRIBUTE-VALUE COUNT FOR UNIVERSITY DATASET 2 Attribute-Name Attribute-Type No. of Values Designation Subject 5 Post Subject 2 Department Subject 5 Course Subject 120 Degree Subject 2 Year Subject 4 Resource-Type Object 8 Department Object 5 Course Object 120 Degree Object 2 Year Object 4 TABLE III ATTRIBUTE-VALUE COUNT FOR COMPANY DATASET Attribute-Name Attribute-Type No. of Values Designation Subject 12 Project-Name Subject 2 Department Subject 5 Resource-Type Object 8 Project-Name Object 2 Department Object 4 of which 308 are positive access requests and 175 are negative access requests. In the test data, the subject attributes for which new values have been added are Designation, Post, Course and Department and the object attributes for which new values have been introduced are Resource-Type, Course and Department. Company Dataset: This dataset has been created keeping in mind the structure and work ow of a software company. The dataset may not be as comprehensive and extensive as an actual company. Nonethe- less, it incorporates features and access rules similar to a real- life organization. The dataset contains three subject attributes, Designation, Project-Name and Department and three object attributes, Resource-Type, Project-Name and Department. The details regarding the number of values associated with each attribute are shown in Table III. There are 384 rules present in the training data. 291 access requests are present in the test data out of which 93 are positive access requests and 198 are negative ones. For subject attributes Designation and Project- Name and object attributes Resource-Type and Project-Name, new values have been introduced in the test data. It is to be noted here that if a certain attribute is not applicable for a particular subject or object, then the value Not Applicable is assigned for that attribute. The number of rules and access requests present respectively in the training and test data have no correlation with the dataset type. These numbers have been chosen purely as a design choice. We have created the datasets in order to cover three scenarios - (i) the number of rules present in training data is less than the number of access requests present in test data, (ii) the number of rules present in training data is higher than the number of access requests present in the test data, and (iii) the number of rules present in training data is comparable to the number of access requests of the test data. Also, in the test data of each dataset, one new attribute value has been introduced in each access request. B. Evaluation Metrics For evaluating the performance of PAMMELA, we use the following metrics - Accuracy, Precision, Recall and F1- score. Before discussing about these metrics, we introduce few terminologies that are used in the computation of the metrics. The de nitions of the terminologies as well as the metrics exist in the domain of machine learning. However, here we present the de nitions for the sake of completeness and also making them meaningful in the context of the current work. We use Y ES and NO to respectively denote the grant decision and the deny decision given as output by PAMMELA. The terminologies and the metrics are de ned as follows: True Positive Accesses (TPA): These are the positive access requests corresponding to which PAMMELA gives the output Y ES. These are instances of correct classi - cations. True Negative Accesses (TNA): These are the negative access requests corresponding to which PAMMELA gives the output NO. These are instances of correct classi ca- tions. False Positive Accesses (FPA): These are the negative access requests corresponding to which PAMMELA gives the output Y ES. These are instances of misclassi cations resulting in security breach. False Negative Accesses (FNA): These are the positive access requests corresponding to which PAMMELA gives the output NO. These are instances of misclassi cations resulting in an over-restrictive system. Accuracy: It is the ratio of the correctly classi ed access requests to the total number of access requests. It denotes the capability of the classi er to make correct decisions. Mathematically, Accuracy = TPA + TNA TPA + FPA + TNA + FNA (1) Precision: It is the ratio of the correctly classi ed positive access requests to the total number of access requests for which the output is Y ES. Precision is inversely proportional to the degree of security breach occurring in the system. Mathematically, Precision = TPA TPA + FPA (2) Recall: It is the ratio of the correctly classi ed positive access requests to the total number of positive access requests. Recall is inversely proportional to the degree of over-restrictiveness of the system. Mathematically, Recall = TPA TPA + FNA (3) F1-score: It is calculated as the weighted average of precision and recall. F1-score balances the relative trade- off between precision and recall. It is calculated as F1 score = 2 Precision Recall Precision + Recall (4) C. Results In this section, we present the experimental results. We have used the following machine learning classi ers to evaluate the performance of PAMMELA - Arti cial Neural Network (ANN) [21], Decision Tree (DT) [24], Random Forest (RF) [4], Extra Trees (ET) [10], GradientBoosting (GB) [23] and XGBoost (XGB) [23]. We report the results of the following four approaches. PAMMELA without any enhancement referred to as PAMMELA-Naive PAMMELA with Attribute Relation based Feature Extraction referred to as PAMMELA-ARFE PAMMELA with Attribute Value Clustering referred to as PAMMELA-AVC PAMMELA with Attribute Relation based Feature Extraction and Attribute Value Clustering referred to as PAMMELA-ARFE+AVC The implementation has been done using Python 3.8 and the experiments were conducted on a MacBook Pro laptop having 2.3 GHz, 8 cores, intel core i9 processor, 16 GB RAM and macOS 11.4 as operating system. We report the performance of the four approaches in terms of the metrics Accuracy (Acc), Precision (Pr), Recall (Rec) and F1-score (F1- s). Tables IV - VI present the results of the three datasets. In each table, the rst column (Clfr) denotes the name of the machine learning classi er used, each represented using the abbreviations mentioned earlier. Also, the names of the four approaches and the metrics are denoted using the compressed forms mentioned above. The results show that, in general, the performance of PAMMELA-ARFE, PAMMELA-AVC as well as PAMMELA- ARFE+AVC is better than that of PAMMELA-Naive in terms of F1-score. This substantiates the fact that the proposed learning enhancement techniques, either used in isolation or in combination, improve the overall performance of PAMMELA. For the University Datasets , PAMMELA-ARFE outperforms PAMMELA-AVC. The reason behind this is that, in these two datasets, several common subject and object attributes are present and the corresponding relations among the attributes are ef ciently captured by the ARFE strategy. However, for the Company Dataset, the performance of PAMMELA-AVC is better than PAMMELA-ARFE for F1-score values. This hap- pens because of the nature of the dataset. The Company Dataset has only two common subject and object attributes. Moreover, several positive rules present in the Company Dataset are such that the values for the common subject and object attributes are not same. Hence, the ARFE strategy cannot much enhance the performance of the approach. However, for this dataset, the AVC technique, in general, improves the performance over the Naive strategy though the improvement is not very substantial. For all the datasets, PAMMELA-ARFE+AVC gives better re- sults than either of PAMMELA-ARFE and PAMMELA-AVC in terms of F1-score. This shows that the two enhancement strategies when used simultaneously give the best possible performance among all the competing approaches. The above mentioned observations are true for most of the machine learning classi ers. In order to highlight the performance gain provided by the enhancement techniques, we select GradientBoosting (GB). For University Dataset 1, in terms of the F1-score, PAMMELA-AVC, PAMMELA-ARFE and PAMMELA-ARFE+AVC give a performance gain respec- tively of 5.5%, 9% and 10% for GB. For the University Dataset 2 and for GB, PAMMELA-AVC, PAMMELA-ARFE and PAMMELA-ARFE+AVC improve the value of F1-score over the Naive approach respectively by 8.6%, 33.2% and 95.4%. This substantial amount of performance enhancement of PAMMELA-ARFE+AVC can be attributed to the fact that the University Dataset 2 is the largest of the three datasets both in terms of the number of attributes as well as the number of rules and these aspects of the dataset are effectively handled by the two combined learning enhancement strategies. For the Company Dataset, in terms of F1-score, PAMMELA-ARFE, PAMMELA-AVC and PAMMELA-ARFE+AVC improve the TABLE IV EXPERIMENTAL RESULTS FOR UNIVERSITY DATASET 1 Clfr PAMMELA-Naive PAMMELA-ARFE PAMMELA-AVC PAMMELA-ARFE+AVC Acc Pr Rec F1-s Acc Pr Rec F1-s Acc Pr Rec F1-s Acc Pr Rec F1-s ANN 0.786 0.934 0.687 0.792 0.905 0.925 0.913 0.919 0.853 0.975 0.773 0.862 0.998 0.997 1.000 0.998 DT 0.864 0.932 0.831 0.879 0.982 0.977 0.993 0.985 0.978 0.972 0.992 0.982 0.994 0.997 0.993 0.995 RF 0.876 0.944 0.841 0.889 0.982 0.977 0.993 0.985 0.968 0.965 0.982 0.973 0.994 0.997 0.993 0.995 ET 0.882 0.967 0.829 0.893 0.982 0.977 0.993 0.985 0.972 0.967 0.987 0.977 0.994 0.997 0.993 0.995 GB 0.881 0.935 0.860 0.895 0.982 0.977 0.993 0.985 0.943 0.972 0.930 0.950 0.994 0.997 0.993 0.995 XGB 0.864 0.932 0.831 0.879 0.982 0.977 0.993 0.985 0.976 0.967 0.993 0.980 0.994 0.997 0.993 0.995 TABLE V EXPERIMENTAL RESULTS FOR UNIVERSITY DATASET 2 Clfr PAMMELA-Naive PAMMELA-ARFE PAMMELA-AVC PAMMELA-ARFE+AVC Acc Pr Rec F1-s Acc Pr Rec F1-s Acc Pr Rec F1-s Acc Pr Rec F1-s ANN 0.590 0.958 0.373 0.537 0.907 1.000 0.854 0.921 0.642 0.993 0.442 0.611 0.954 1.000 0.929 0.963 DT 0.627 0.971 0.429 0.595 0.915 1.000 0.867 0.929 0.648 0.973 0.461 0.626 0.957 1.000 0.932 0.965 RF 0.555 0.943 0.321 0.479 0.915 1.000 0.867 0.929 0.576 0.964 0.347 0.511 0.957 1.000 0.932 0.965 ET 0.551 0.925 0.321 0.477 0.915 1.000 0.867 0.929 0.596 0.945 0.390 0.552 0.957 1.000 0.932 0.965 GB 0.331 0.174 0.013 0.024 0.393 0.551 0.263 0.356 0.362 0.500 0.062 0.110 0.973 1.000 0.958 0.978 XGB 0.555 0.979 0.308 0.469 0.913 1.000 0.864 0.927 0.491 0.970 0.208 0.342 0.965 1.000 0.945 0.972 TABLE VI EXPERIMENTAL RESULTS FOR COMPANY DATASET Clfr PAMMELA-Naive PAMMELA-ARFE PAMMELA-AVC PAMMELA-ARFE+AVC Acc Pr Rec F1-s Acc Pr Rec F1-s Acc Pr Rec F1-s Acc Pr Rec F1-s ANN 0.732 0.584 0.559 0.571 0.698 0.532 0.441 0.482 0.729 0.646 0.333 0.440 0.808 0.718 0.656 0.685 DT 0.790 0.627 0.849 0.721 0.842 0.701 0.882 0.781 0.955 0.877 1.000 0.935 1.000 1.000 1.000 1.000 RF 0.856 0.726 0.882 0.796 0.835 0.689 0.882 0.774 0.955 0.877 1.000 0.935 1.000 1.000 1.000 1.000 ET 0.859 0.728 0.892 0.802 0.838 0.698 0.871 0.775 0.955 0.877 1.000 0.935 1.000 1.000 1.000 1.000 GB 0.797 0.673 0.710 0.691 0.838 0.725 0.796 0.759 0.845 0.800 0.688 0.740 1.000 1.000 1.000 1.000 XGB 0.753 0.624 0.570 0.596 0.863 0.762 0.828 0.794 0.863 0.853 0.688 0.762 1.000 1.000 1.000 1.000 performance over PAMMELA-Naive respectively by 6.8%, 4.9% and 30.9% for GB. Based on the above observations, we provide the following insights for system administrators for managing ABAC policies using PAMMELA. A system administrator can experiment with a number of classi ers for PAMMELA before selecting the best possible option. If a dataset contains several common subject and object attributes and if the administrator wants to use only one enhancement strategy, then it is better to use ARFE rather than AVC. If a dataset does not contain too many common subject and object attributes and a number of rules where the common attributes have not been assigned the same value, then it is better to use AVC rather than ARFE. If a system administrator wants to get the best possible re- sult, then ARFE+AVC should be chosen. However, some amount of effort is required for the feature extraction and the value clustering. The training and the testing time for PAMMELA is quite low. We observed that for ANN, PAMMELA-AVC took 86 seconds to complete the training on the University Dataset 2. This is the highest recorded training time for our experiments. For any other combination of strategy and classi er, PAM- MELA gave much lower training execution times on all the datasets. The maximum testing time for PAMMELA that we observed was less than 1 second. Of course, the testing time is dependent upon the number of access requests considered. Hence, experimenting with multiple classi ers will not be too time consuming. Moreover, once training has been done, PAMMELA can keep on generating new rules without any further training. However, if the policy used for training needs to be changed altogether (may happen if the organizational structure or work ow undergoes some radical modi cations), then the classi er needs to be re-trained. VII. CONCLUSION AND FUTURE SCOPE In this paper, we have proposed the ABAC Policy Inference Problem (ABAC-PIP). ABAC-PIP aims to derive a new set of attribute based rules from an existing policy. We have proposed an end-to-end supervised learning based, automated methodol- ogy, PAMMELA for solving ABAC-PIP. System administrators can use PAMMELA for augmentative as well as adaptive policy inference when an organization undergoes some changes or an organization migrates to ABAC by adapting the policy of a similar organization. We have also designed two techniques to enhance the learning capability of PAMMELA. Our experimen- tal results show that PAMMELA can be effectively used for the application scenarios mentioned above. Moreover, the learning enhancement techniques indeed improve the performance of PAMMELA. In future, we intend to apply deep learning, reinforcement learning and incremental learning for inferring ABAC policies. Another direction of future research can be attempting to adapt the ABAC policies of multiple organizations for a single target organization. This will be a challenging task since it will necessitate resolving the con icts among the rules of different organizations in order to generate the target policy. REFERENCES [1] M. Alohaly, H. Takabi, and E. Blanco. Towards an automated extraction of abac constraints from natural language policies. In Proc. of ICT Systems Security and Privacy Protection, pages 105 119, 2019. [2] G. Batra, V. Atluri, J. Vaidya, and S. Sural. In-memory policy indexing for policy retrieval points in attribute-based access control. In Proc. of Int. Conf. on Information Systems Security, pages 99 120, 2021. [3] G. Batra, V. Atluri, J. Vaidya, and S. Sural. Incremental mainte- nance of abac policies. In Proc. of the 11th ACM Conf. on Data and Application Security and Privacy, pages 185 196, 2021. [4] L. Breiman. Random forests. Machine Learning, 45(1):5 32, 2001. [5] C. Cotrini, T. Weghorn, and D. Basin. Mining abac rules from sparse logs. In Proc. of 2018 IEEE European Symposium on Security and Privacy, pages 31 46, 2018. [6] S. Das, S. Sural, J. Vaidya, and V. Atluri. Policy adaptation in attribute-based access control for inter-organizational collab- oration. In Proc. of IEEE 3rd Int. Conf. on Collaboration and Internet Computing, pages 136 145, 2017. [7] S. Das, S. Sural, J. Vaidya, and V. Atluri. Hype: A hybrid approach toward policy engineering in attribute-based access control. IEEE Letters of the Computer Society, pages 25 29, 2018. [8] S. Das, S. Sural, J. Vaidya, and V. Atluri. Policy adaptation in hierarchical attribute-based access control systems. ACM Trans. on Internet Technology, 19(3), August 2019. [9] M. Gautam, S. Jha, S. Sural, J. Vaidya, and V. Atluri. Poster: Constrained policy mining in attribute based access control. In ACM Symposium on Access Control Models and Technologies, pages 121 123, 2017. [10] P. Geurts, D. Ernst, and L. Wehenkel. Extremely randomized trees. Machine Learning, 63:3 42, 2006. [11] M. A. Harrison, W. L. Ruzzo, and J. D. Ullman. Protection in operating systems. Communications of the ACM, 19(8):461 471, 1976. [12] D. Heutelbeck, M. L. Baur, and M. Kluba. In-memory policy indexing for policy retrieval points in attribute-based access control. In Proc. of 26th ACM Symposium on Access Control Models and Technologies, pages 59 70, 2021. [13] V. C. Hu, D. Ferraiolo, D. R. Kuhn, A. Schnitzer, K. Sandlin, R. Miller, and K. Scarfone. Guide to Attribute-Based Access Control (ABAC) de nition and considerations. Technical report, NIST Special Publication, 2014. [14] A. A. Jabal, E. Bertino, J. Lobo, M. Law, A Russo, S. Calo, and D. Verma. Polisma - a framework for learning attribute- based access control policies. In Proc. of European Symposium on Research in Computer Security, volume 12308, pages 523 544, 2020. [15] A. A. Jabal, E. Bertino, J. Lobo, D. Verma, S. Calo, and A. Russo. Flap a federated learning framework for attribute-based access control policies, 2020. [16] L. Karimi, M. Abdelhakim, and J. Joshi. Adaptive abac policy learning: A reinforcement learning approach, 2021. [17] L. Karimi, M. Aldairi, J. Joshi, and M. Abdelhakim. An automatic attribute based access control policy extraction from access logs. IEEE Trans. on Dependable and Secure Computing, 2021. [18] L. Krautsevich, A. Lazouski, F. Martinelli, and A. Yautsiukhin. Towards Attribute-Based Access Control policy engineering using risk. In Proc. of 1st Int. Workshop on Risk Assessment and Risk- Driven Testing, pages 80 90, November 2013. [19] S. Lawal and R. Krishnan. Enabling exible administration in abac through policy review: A policy machine case study. In Proc. of 7th IEEE Int. Conf. on Big Data Security on Cloud, IEEE Int. Conf. on High Performance and Smart Computing, and IEEE Int. Conf. on Intelligent Data and Security, pages 69 74, 2021. [20] D. C. Mocanu, F. Turkmen, and A.Liotta. Towards abac policy mining from logs with deep learning. Intelligent Systems, pages 124 128, 2015. [21] K. P. Murphy. Machine Learning: A Probabilistic Perspective. The MIT Press, 2012. [22] M. Narouei, H. Khanpour, H. Takabi, N. Parde, and R. Nielsen. Towards a top-down policy engineering framework for attribute- based access control. ACM Symposium on Access Control Models and Technologies, pages 103 114, 2017. [23] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay. Scikit-learn: Machine learning in Python. Journal of Machine Learning Research, 12:2825 2830, 2011. [24] J.R. Quinlan. Simplifying decision trees. Int. Journal of Man- Machine Studies, 27(3):221 234, 1987. [25] M. W. Sanders and C. Yue. Mining least privilege attribute based access control policies. In Proc. of the 35th Annual Computer Security Applications Conf., pages 404 416, 2019. [26] R. S. Sandhu, E. J. Coyne, H. L. Feinstein, and C. E. Youman. Role-Based Access Control Models. IEEE Computer, 29(2):38 47, 1996. [27] R.S. Sandhu. Lattice-based access control models. Computer, 26(11):9 19, 1993. [28] T. Talukdar, G. Batra, J. Vaidya, V. Atluri, and S. Sural. Ef cient bottom-up mining of attribute based access control policies. IEEE Int. Conf. on Collaboration and Internet Computing, pages 339 348, 2017. [29] Z. Xu and S. D. Stoller. Mining attribute-based access control policies from logs. In Proc. of the 28th Annual IFIP WG 11.3 Working Conf. on Data and Applications Security and Privacy, pages 276 291, 2014. [30] Z. Xu and S.D. Stoller. Mining attribute-based access control policies. IEEE Trans. on Dependable and Secure Computing, 12(5):533 545, 2015.