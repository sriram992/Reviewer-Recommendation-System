Real-time Iris Segmentation based on Image Morphology Sambit Bakshi National Institute of Technology, Rourkela Odisha, India sambitbaksi@gmail.com Hunny Mehrotra National Institute of Technology, Rourkela Odisha, India hunny@nitrkl.ac.in Dr. Banshidhar Majhi College of Computer Science, King Khalid University, Saudi Arabia bmajhi@nitrkl.ac.in ABSTRACT This paper introduces an e cient iris segmentation approach for unconstrained images. Proposed technique is robust to occlusion, specular re ection, variation in illumination and non-centered gaze. For pupil localisation, the input iris image is binarised using an adaptive threshold deter- mined based on number of connected components. Further, pupil center and radius are obtained using spectrum image based approach. The proposed technique performs accu- rately (>97%) with low computation (<0.4 seconds/image). It has been observed that the proposed approach can be de- ployed to real-time biometric systems where time as well as accuracy cannot be compromised. Categories and Subject Descriptors I.4.6 [Image Processing and Computer Vision]: Seg- mentation Edge and feature detection, Pixel classi cation, Region growing, partitioning; I.4.10 [Image Processing and Computer Vision]: Image Representation Morpho- logical General Terms Security and Experimentation Keywords Iris Segmentation, Adaptive Threshold, Connected Compo- nents, Spectrum Image and Circular Hough Transform 1. INTRODUCTION Iris is one of the most trusted biomtric authentications due to its accuracy, reliability and speed. The highly de- tailed random patterns from the iris are acquired from some distance to have real-time high con dence recognition of an individual [1]. The acquired iris image is preprocessed for Dr. Banshidhar Majhi is presently on leave from National Institute of Technology Rourkela, Odisha, India Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for pro t or commercial advantage and that copies bear this notice and the full citation on the rst page. To copy otherwise, to republish, to post on servers or to redistribute to lists, requires prior speci c permission and/or a fee. ICCCS 2011 Rourkela, Odisha, India Copyright 20XX ACM X-XXXXX-XX-X/XX/XX ...$10.00. Figure 1: Binarization using adaptive threshold [2] localisation of inner pupil and outer iris boundary that are presumed to be concentric circular. Localised iris is used for feature extraction and matching. As localisation is the primitive operation, any failure compromises performance of the subsequent process. There are several issues to be handled for sengmenting iris. Firstly, static threshold fails to binarize iris image for varying illumination. Secondly, iris occlusion by eyelids and eyelashes degrades the performance of localisation module. Thirdly, during image acquisition the spot of light creates specular highlights on pupil which adds noise to input and hinder localisation. Lastly, the gaze of an individual may not be centered. Such images are usually acquired in non- cooperative environment. The minimum value of mean in- tensity of a grid in iris image ihas been taken as threshold for binarizing the pupil [2] as shown in Figure 1, but it fails due to specular highlights. In the proposed paper, a robust iris segmentation approach has been developed that performs well for aforementioned issues. The detailed description of steps involved are given in Section 2. For accurate pupil detection, an adaptive threshold is obtained from input iris image as given in Section 2.1. The hole lled binary image is used for nding pupil boundary using spectrum image (Sec- tion 2.2). Section 2.3 outlines the approach to nd outer iris boundary. Experimental results for the proposed approach are given in Section 3. 2. PROPOSED IRIS SEGMENTATION Iris segmentation comprises nding the inner pupil and outer iris boundary. The annular region lying between the two boundaries is considered for feature extraction. In this paper an e cient and fast iris segmentation approach is pro- posed. This approach takes an input iris image and nds an adaptive threshold for pupil detection. The pupil boundary is obtained using spectrum image based approach. Finally iris boundary is found using traditional homocentric circular summation of intensities. The detailed description of steps involved are explained below: 2.1 Adaptive Thresholding Pupil is darkest region in the eye with almost circular shape. Appropriate threshold helps to nd the region of interest containing pupil. Static value of threshold may fail for di erent images taken under varying illumination conditions [2]. In the proposed paper an e ort has been made to adaptively determine the value of threshold. It has been empirically observed that the highest intensity value contributing to pupil neither exceeds (0.5 of high- est grayscale value) nor drops beyond (0.1 of highest grayscale value). To nd adaptive threshold, binary images are obtained iteratively for range of thresholds ( ) between and with increment of (0.05 of highest grayscale value). Parameters are optimized based on trade o between computational complexity and accuracy. 0.1 0.15 0.2 0.25 0.3 0.35 0.4 0.45 0.5 0 5 10 15 20 25 30 35 Threshold ( ) Number of Connected Components ( ) : 0.20 : 1 : 0.25 : 1 Figure 2: Relationship between and The binary images obtained for varying are considered for removing specular highlights (holes). Morphological re- gion lling approach is used to ll holes in the image. To begin with hole lling operation, the binary image ( ) is complemented. The convention adopted here is that the boundary pixels are labelled as 1. If non-boundary pixels are labelled as 0 then beginning with a point inside the boundary a value of 1 is assigned. The following transfor- mation lls the region with ones = ( 1 ) (1) where 0 = ; = 1, 2, 3, . . .; is used for dilation of 1 by which is de ned as 1 = { ( ) 1 = } (2) is the symmetric structuring element de ned as 0 1 0 1 1 1 0 1 0 This algorithm terminates at iteration if = 1. The image generated from last iteration is combined with using bitwise OR that contains the boundary lled image. Each hole lled image is used to nd the no. of con- nected components ( ). changes for change in value of Algorithm 1 Adaptive Thresholding Require: : Intensity Image, : Structuring element Ensure: : Binary Image 0.10 0.50 0.05 [ ] := size( ) {Compute width and height of image} for := to step do := binary( , ) {Image Binarisation using } := {Complement of an image} 0 := zeros( , ) {Image with all zeros} 0( ) = 1 { is a point inside hole} 0 repeat + 1 ( 1 ) until = 1 {Hole lled image} := connComp( ) {Find no. of connected compo- nents} end for := min nonzero( ){Find index of minimum non-zero} threshold as shown in Figure 2. The value of threshold cor- responding to minimum non-zero is chosen as adaptive binarization threshold. However, if the minimum non-zero occurs for more than one thresholds (as shown in Fig- ure 2), then maximum threshold amongst them is chosen as adaptive threshold. The reason behind nding maximum amongst potential thresholds is that pupil boundary may contain some intensity values which may not contribute to connected component of pupil for lower thresholds. Figure 3 shows binary images obtained for change in . Algorithm 1 describes steps involved. 2.2 Pupil Detection In traditional iris recognition systems, combination of edge detection and Circular Hough Transformation (CHT) is used for nding pupil and iris boundaries [3]. The major draw- back of Hough transform is that it requires range of radius as input from the user. Further, Hough works in R3 parameter space (number of parameters needed to describe the shape of a circle) which implies high time complexity of the trans- form. Hence, an e cient spectrum based approach is used for pupil detection that performs faster compared to Hough transformation without any priori estimation of radius. In this approach, the binarised image is re-complemented to detect center of pupil. The distance of every pixel in the binary image is obtained with nearest non-zero pixel [4]. By computing the distance between pixels, spectrum showing largest lled circle can be formed within the set of foreground pixels. Since pupil is the largest lled circle in the image, the overall intensity of this spectrum is maximum at the center. The spectrum image is shown in Figure 4(a). Thus, the position of maximum value in the spectrum image is pupil center. To compute the pupil radius, an edge map of the hole lled binary image is obtained as shown in Figure 4(b). In the edge map, the distance from the detected pupil center to the nearest non-zero pixel is the pupil radius ( ). The pupil detected image is shown in Figure 4(c). The algorithm for detecting pupil center and radius is given in Algorithm 2. (a) : 0.10; : 0 (b) = 0.15; : 0 (c) = 0.20; : 1 (d) = 0.25; : 1 (e) = 0.30; : 32 (f) = 0.35; : 23 (g) = 0.40; : 18 (h) = 0.45; : 23 (i) = 0.50; : 30 Figure 3: Binary images obtained for change in threshold ( ) and number of connected components ( ) (a) (b) (c) Figure 4: Pupil Detection: (a) Spectrum image, (b) Edge detected image and (c) Pupil localised image 2.3 Iris detection For iris boundary detection, circular summation of in- tensity approach is used as proposed in [5]. The original grayscale image is blurred using median lter to remove ex- ternal noise. After ltering, the contrast of image is en- hanced to have sharp variation at image boundaries using histogram equalisation as shown in Figure 5(a). This con- trast enhanced image is used for nding the outer iris bound- ary by drawing concentric circles (Figure 5(b) shows an ex- ample) of di erent radii from the pupil center and the inten- sities lying over the perimeter of the circle are summed up. Among the candidate iris circles, the circle having maximum change in intensity with respect to the previous drawn circle is the iris outer boundary as shown in Figure 5(c). 3. EXPERIMENTAL RESULTS The proposed system has been tested on two publicly available databases BATH [6] and CASIA V3 [7]. From experimental analysis it has been observed that the system is capable of handling unconstrained scenarios as well. To mention a few, it possesses invariance to noisy instances viz. occlusion, specular highlights, person wear- ing contact lens, change in illumination and viewpoint (non- centered gaze). Performance accuracy of the detector is sup- ported with the help of few illustrations. The nomenclature Algorithm 2 Pupil Detection Require: : Binary Image Ensure: : xcenter of pupil, : ycenter of pupil, : Ra- dius of pupil {Complement the binary image} [ ] := nd( == 1) {Find location of ones in an image} := length( ) {To nd the no. of elements in an array} for := 1 to do for := 1 to do for := 1 to do ( )2 + ( )2 end for , := min( ) {Minimum value of } end for end for [ ] max( ) := edge( ) {Edge detection} {Estimation of pupil radius} 0 while , = 1 do + 1 + 1 end while (a) (b) (c) Figure 5: Iris Detection: (a) Contrast enhanced im- age, (b) Concentric circles of di erent radii and (c) Iris localised image of the images are de ned as Database/Subject ID/Eye/Image Instance (e.g. C/224/L/05). Figure 6(a) depicts robustness against occlusion and spec- ular highlights. It is evident that the proposed scheme per- forms well for higher degree of occlusion (C/010/R/04) where image is occluded by upper eyelid and the region of interest (iris) is partially outside. Further, an example showing the subject wearing contact lens is shown in Figure 6(b). The segmentation takes place accurately despite unconstrained nature of the instances. Similarly, the system is pro cient in performing against illumination variation. Change in illumination leads to di- lation and contraction of pupil. Static threshold may fail to perform due to intensity variation. Samples from BATH and CASIA databases are shown in Figure 7. The localisation accuracy of the proposed system is compared against circu- lar Hough transform [8] as shown in Table 1. The proposed system performs with an accuracy of 99.07% and 95.76% on BATH and CASIA respectively (with an average accuracy of 97.42%). Hough transform performs equally well (average accuracy of 97.35%) but localisation time for the proposed system is relatively low compared to Hough transform. Few test cases where proposed approach outperforms Hough transformation are shown in Figure 8. To determine com- putation e ciency, time taken to perform segmentation is computed using 2.81GHz AMD Athlon 64 X2 Dual Core C/139/R/03 C/010/R/04 (a) Occlusion and specular highlights C/147/R/04 (b) Subject wearing contact lens Figure 6: Localization performance of the proposed approach for (a) occlusion and specular highlights and (b) contact lens B/0017/L/10 B/0018/L/20 (a) BATH C/063/R/07 C/166/R/04 (b) CASIA Figure 7: Localization performance of the proposed system for variation in illumination processor with 2GB RAM. Time required to perform local- isation by the proposed approach is signi cantly low com- pared to Hough transform as given in Table 2. Average time taken by the proposed approach is 0.37 seconds/image whereas Hough takes 7.68 seconds/image. From the results it is evident that system is capable of performing segmenta- tion for unconstrained scenarios in signi cantly less time. 4. CONCLUSIONS In this paper, issues owing to non-cooperative images have been addressed. An adaptive threshold is computed using no. of connected components. Pupil boundary is obtained from the binary image using spectrum approach. This ap- proach has been tested on BATH and CASIA databases and compared against Hough transform. It has been observed that the proposed approach performs with an average ac- curacy of 97.42% in comparison to Hough which performs with an average accuracy of 97.35%. Though there is minor improvement in accuracy, the time required to perform seg- mentation reduces to 0.37 seconds/image in comparison to 7.68 seconds/image for Hough transform. This marks suit- Table 1: Accuracy (in %) for the proposed approach and Hough transform Databases BATH CASIA Approach Hough [8] 99.53 95.17 Proposed 99.07 95.76 Table 2: Time taken (in seconds) for the proposed approach and Hough transform Databases BATH CASIA Approach Hough [8] 02.2820 13.0676 Proposed 00.3383 00.3960 ability of proposed approach for time constrained systems. 5. REFERENCES [1] J. Daugman. The importance of being random: statistical principles of iris recognition. Pattern Recognition, 36(2):279 291, 2003. [2] G. Xu, Z.F. Zhang, and Y.D. Ma. Automatic iris segmentation based on local areas. In International Conference on Pattern Recognition, volume 4, pages 505 508. IEEE Computer Society, 2006. [3] Q. Tian, Q. Pan, Y. Cheng, and Q. Gao. Fast algorithm and application of hough transform in iris segmentation. In International Conference on Machine Learning and Cybernetics, volume 7, pages 3977 3980, 2004. [4] B. Lipinski. Iris recognition: Detecting the pupil. Connexions website, 2004. http://cnx.org/content/m12487/1.4/. [5] L. Ma, T. Tan, Y. Wang, and D. Zhang. E cient iris recognition by characterizing key local variations. IEEE Transactions on Image Processing, 13(6):739 750, 2004. [6] BATH University Database. http: //www.bath.ac.uk/elec-eng/research/sipg/irisweb. [7] CASIA Database. http: //www.cbsr.ia.ac.cn/english/IrisDatabase.asp. [8] R.P. Wildes. Iris recognition: an emerging biometric technology. Proceedings of the IEEE, 85(9):1348 1363, 1997. C/124/R/06 C/144/R/03 Figure 8: Sample instances where proposed ap- proach (right) outperforms Hough transform (left)