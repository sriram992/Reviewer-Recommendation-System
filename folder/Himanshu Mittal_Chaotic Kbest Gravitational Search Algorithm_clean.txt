See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/315472674 Chaotic Kbest gravitational search algorithm (CKGSA) Conference Paper August 2016 DOI: 10.1109/IC3.2016.7880252 CITATIONS 59 READS 766 4 authors: Some of the authors of this publication are also working on these related projects: GSA in Python View project Gravitational Search Algorithm View project Himanshu Mittal Jaypee Institute of Information Technology 48 PUBLICATIONS 681 CITATIONS SEE PROFILE Raju Pal Jaypee Institute of Information Technology 54 PUBLICATIONS 698 CITATIONS SEE PROFILE Ankur Kulhari Jaypee Institute of Information Technology 12 PUBLICATIONS 147 CITATIONS SEE PROFILE Mukesh Saraswat Jaypee Institute of Information Technology 81 PUBLICATIONS 2,114 CITATIONS SEE PROFILE All content following this page was uploaded by Himanshu Mittal on 03 January 2018. The user has requested enhancement of the downloaded file. Chaotic Kbest Gravitational Search Algorithm (CKGSA) Himanshu Mittal, Raju Pal, Ankur Kulhari, Mukesh Saraswat Jaypee Institute of Information Technology himanshu.mittal224@gmail.com, raju.pal3131@gmail.com, ankur.jii@gmail.com, saraswatmukesh@gmail.com Abstract Gravitational search algorithm is a popular adaptive search algorithm among nature-inspired algorithms and has been successfully used for optimizing many real-world problems. Gravitational search algorithm uses the law of Newton gravity for nding the optimal solution. The performance of gravitational search algorithm is controlled by exploration and exploitation capabilities and Kbest is one of its parameters that controls this trade-off. In this paper, a novel chaotic Kbest gravitational search algorithm has been proposed that uses the chaotic model in Kbest to balance the exploration and exploitation non- linearly. The proposed algorithm shows better convergence rate at later iterations with high precision and does not trap into local optima.The experimental results validate that the proposed algorithm outperforms. Keywords Gravitational search algorithm; Chaotic; Kbest; Adaptive search algorithm I. INTRODUCTION Algorithms inspired from the optimization behavior of na- ture have evolved as nature-inspired algorithms (NIA) and have been successfully used for optimizing many real-world problems. Some of the well-known NIA algorithms are genetic algorithm (GA) [1], ant-colony optimization (ACO) [2], par- ticle swarm optimization (PSO) [3], gravitational search algo- rithm (GSA) [4], and many more. GSA is a recently proposed adaptive search algorithm based on the concept of Newtonian gravity. In comparison with popular NIA algorithms, GSA has performed better in searching the solution space. Due to its simplicity and exibility, it has solved many function optimization problems [4] and real-world problems [5], [6], [7], [8] like classi cation, clustering, image processing, data mining, and so on. GSA models candidate solutions as swarm of objects and computes the performance of each object in terms of mass. At the beginning, GSA explores the search space to escape local optima problem and after that performs exploitation. The search strategy is to move objects stochastically towards Kbest objects and converge towards the heaviest object using the laws of gravity and motion. Kbest function de nes the number of objects that can attract other objects at an iteration. To avoid being trapped in local optima [9], more objects should be considered at the beginning for exploration and by lapse of iterations, Kbest reduces for exploitation. In general, the value of Kbest decreases linearly and at last only one object will be left with heaviest mass whose position represents the best solution. Although, GSA has advantages like fast convergence and low computational cost, it still has some drawbacks like slow convergence rate at later iterations, traps in local optima at times, and lack of solution precision [10]. However, the performance of GSA can be improved by controlling exploration and exploitation capabilities [11]. In view of the above, many researchers proposed different variants of GSA by modifying its parameters like; position, velocity, gravitational constant, Kbest etc. [7], [10], [11], [12]. Kbest is one of the important parameters of GSA that determines the trade off between exploration and exploitation. In general, all the variants of GSA used linearly decreasing Kbest. Pal et al. [12] solved dynamic constrained optimiza- tion problems (DCOP) by modifying the Kbest function of basic GSA which enhances the exploitation gradually over exploration after some generations. However, this decrease in Kbest has also shown linear decreasing behavior. In this paper, a novel variant of GSA (CKGSA) has been proposed in which Kbest has been de ned on chaotic behavior. The proposed algorithm shows preferable convergence precision, quick convergence rate, and better global search ability. Rest of the paper is organized as follows: Section II describes the basic GSA. The proposed algorithm CKGSA has been introduced in Section III. Section IV discusses the experimental results and conclusion is presented in Section V. II. GRAVITATIONAL SEARCH ALGORITHM (GSA) Rashedi et al. [4] introduced GSA, an adaptive search nature-inspired algorithm, to solve optimization problems. It uses the law of gravity and mass interactions for nding the optimum solution. Each candidate solution is modeled as swarm of objects. Gravity force causes a global movement of all objects towards objects with heavier masses. The number of objects exerting force in the system is represented by Kbest which controls the trade-off between exploration and exploitation. Slower movement of heavier objects guarantees the exploitation step in the algorithm. The position of the object represents the solution of the problem and object with heaviest mass represents an optimum solution. Let in GSA, the position of N objects in n dimensions search space is depicted in Eq. 1; Xi = (x1 i , ..., xd i , ...., xn i ), i = 1, 2, ..., N (1) where xid denotes the dth dimension of the ith object. The total force F d i (t) on dth dimension of ith object at tth iteration 978-1-5090-3251-8/16/$31.00 2016 IEEE is de ned as randomly weighted sum of dth components of the forces from other Kbest objects and is shown in Eq. (2). F d i (t) = Kbest  j=1,j =i randjFij d(t), (2) where randj is a random number in the interval [0, 1] and Kbest for the tth iteration is de ned as per Eq. (3). Kbest(t) = final per +  1 t max it  (100 final per), (3) here, max it is maximum number of iterations and final per is the percent of objects which apply force to others. The equation of Kbest shows that its value decreases linearly over iterations. In Eq. (2), Fij is the force of jth object on ith object as depicted in Eq. (4). Fij d(t) = G(t)Mi(t) Mj(t) Rij(t) (xd j(t) xd i (t)) (4) where G(t) is a gravitational constant computed as Eq. (5) at iteration t, is a small constant, and Rij(t) is an Euclidian distance between two objects. G = G(t0) exp  t max it  (5) where G(t0) is the initial gravitational constant value. GSA considers gravitational mass (Mgi) and inertia mass (Mii) equal for an object i and is calculate as shown in Eq. (8) for every iteration t using its tness function (fiti(t)). Mi = Mii = Mgi, i = 1, 2, ..., N (6) mi(t) = fiti(t) worst(t) best(t) worst(t), (7) Mi(t) = mi(t) N j=1 mj(t) , (8) where best(t) and worst(t) are measured by Eq. (9) and Eq. (10) respectively for minimization problem. best(t) = minj {1,...,N}fitj(t) (9) worst(t) = maxj {1,...,N}fitj(t) (10) The calculated force F d i (t) and mass Mi(t) are used to nd the acceleration of ith object in the dth dimension according to law of motion as shown in Eq. (11). ad i (t) = F d i (t) Mi(t), (11) Now, the next velocity and position of an object are calculated as Eq.(12) and Eq.(13) respectively. vd i (t + 1) = randi vd i (t) + ad i (t), (12) xd i (t + 1) = xd i (t) + vd i (t + 1). (13) As object s position corresponds to solution, heaviest object in population will be the ttest agent and its position will Fig. 1: Conceptual diagram of GSA represent the global solution of the problem at the end of stop criteria. The pictorial representation of GSA has been depicted in Fig. 1. In the gure, there are 4 objects (M1 to M4) of different masses positioned at different location in the search space. The new position achieved by object M1 due to GSA is depicted as X1. Since the heavier objects represent good solutions in GSA, objects converge towards them as shown in Fig. 1. The pseudocode of the GSA is presented in Algorithm 1 [4]. Algorithm 1 Gravitational Search Algorithm (GSA) Input: N objects having n dimensions. Assume the value of G0, final per, and . Ouput: Best solution having heaviest mass. Randomly initialize the initial population of N objects; Set Kbest = N; Evaluate the tness fit of each object; Compute the mass M of each object by Eq. (8) and G by Eq. (5) ; while stopping criteria is not satis ed do Compute the acceleration a of each object by Eq. (11); Compute the velocity v of each object by Eq. (12); Update the position of each object by Eq. (13); Evaluate the tness fit for each object; Compute the mass M of each object by Eq. (8); Update G; Update Kbest as: Kbest = final per +  1 t max it  (100 final per), end while III. PROPOSED CHAOTIC KBEST GSA (CKGSA) In the proposed chaotic Kbest GSA (CKGSA), chaotic behavior of Kbest function has been used instead of the linear decrease. This introduces a chaotic optimization mechanism in GSA that makes it escape from local optima, have good solution precision, and fast convergence speed. Due to the non-linearity, ergodicity, and divergent nature, chaotic system is competent for global optimization. It shows oscillating trajectory without repeating the same value and forms a fractal structure [13]. In optimization, chaos has often shows better searching behavior than stochastic variables [7], [14]. The proposed chaotic model uses logistic mapping to compute the values of Kbest. Logistic map is de ned by Eq. (14), z(t+1) = zt (1 zt), (14) where, zt [0, 1] is the chaotic number at tth iteration. The initial value z0 is initialized randomly in the interval [0, 1]. is a positive constant, commonly termed as biotic potential [15]. Eq. (14) behaves chaotically above a certain value of [13]. When = 4, the chaotic behavior of logistic map besprin- kles between interval of [0, 1] as shown by Poincar e plot in Figure 2 [14]. The Poincar e plot maps the value of z at (t + 1) iteration on the y-axis versus the value at t on the x- axis. The bifurcation of Fig. 2 will reveal many curves which never overlap because of their fractal geometry. The proposed Kbest chaotically decreases its values over iterations as per Eq. (15). Kbest(t) = (N final per) max it t max it  +final per zt, (15) where, max it is maximum number of iterations, N is the number of objects, and final per is the percent of objects apply force to others. The pseudocode of the CKGSA is presented in Algorithm 2. Fig. 2: Poincar e plot showing chaotic behavior of Logistic mapping at = 4 IV. EXPERIMENTAL RESULTS The performance of the proposed CKGSA has been evalu- ated on 12 standard benchmark functions [4] and compared with GSA [4] and modi ed GSA (MGSA) [12]. For fair comparison, all the algorithms have been tested on a computer with 2.80 GHz Intel R core i3 processor and 2 GB of RAM using Matlab 2011a. These benchmark functions and param- eter settings are depicted in Section IV-1. The performance of proposed CKGSA has been compared in terms of average tness value, best solution, and standard deviation which are discussed in Section IV-2. The computational time of the proposed and the existing algorithms are presented in Section IV-3. Section IV-4 shows the statistical validation of the results using wilcoxon rank sum test. Moreover, Section IV-5 depicts the comparative analysis of the convergence rate. Algorithm 2 Chaotic Kbest Gravitational Search Algorithm (CKGSA) Input: N objects having n dimensions. Assume the value of G0, final per, and . Output: Best solution having heaviest mass. Randomly initialize the initial population of N objects; Set Kbest = N and = 4; Evaluate the tness fit of each object; Compute the mass M of each object by Eq. (8) and G by Eq. (5) ; while stopping criteria is not satis ed do Compute the acceleration a of each object by Eq. (11); Compute the velocity v of each object by Eq. (12); Update the position of each object by Eq. (13); Evaluate the tness fit for each object; Compute the mass M of each object by Eq. (8); Update G; Update Kbest as: Select a random number as z, z = z (1 z), Kbest = (N final per)  max it t max it  + final per z, end while 1) Benchmark Functions: Table I depicts the 12 benchmark functions along with their de nitions, range of each function, and global minimum tness [4]. In this table, d represents the dimension of the function which is set to the value of power in the range column of each function. The considered benchmark functions belong to either unimodal or multi-modal class. In general, unimodal functions tests the convergence rate of a global optimum while the chances of trapping into local optima is evaluated by multi-modal functions. These functions have been considered for compa rative analysis of proposed algorithm CKGSA with two other optimization algorithms (GSA, MGSA). For all the algorithms, population size (N), number of iterations (itr), Gconstant (G0), and Alpha ( ) are set to 50, 1000, 100 and 20 respectively as shown in parameter setting Table II. 2) Experimental Comparison: The experimental results have been analyzed over 30 runs and the average tness value, best solution, and standard deviation of each existing and proposed algorithms are listed in Table III. From table, it is visualized that average tness value, for maximum number of the benchmark functions (F1, F2, F7, F8, F12), generated by proposed CKGSA are best among GSA and MGSA and similar for three benchmark functions (F4, F9, F11). GSA shows slightly better than CKGSA for F3, F5, and F10 benchmark functions while, MGSA performs comparatively better for F6 only. However, for these functions CKGSA outperforms in terms of best solution or standard deviation values. Therefore, these observations con rm that CKGSA shows better searching performance with high precision. 3) Computational Time: The searching time of optimiza- tion algorithms is another important criteria for applicability on the real - world problems. Table IV reveals the averaged running time (in seconds) of each existing and proposed algorithm on each benchmark function over 30 runs. It is interesting to see from Table IV that the proposed algorithm converges very fast as compared to existing algorithms for all the benchmark functions. Therefore, it con rms that CKGSA has ef cient computational time at reaching the optimal value. TABLE I: Benchmark functions Test Function Range Optimal Value F1(X) = d i=1 i j=1 xj 2 , x [ 100, 100]30 0 F2(X) = d 1 i=1  100(xi+1 x2 i )2 + (xi 1)2 , x [ 30, 30]30 0 F3(X) = d i=1 | xi | + d i=1 | xi |, x [ 10, 10]30 0 F4(X) = d i=1 ([xi + 0.5])2 , x [ 100, 100]30 0 F5(X) = 20exp  0.2 1 d d i=1 x2 i exp  1 d d i=1 cos(2 xi)  + 20 + e, x [ 32, 32]30 0 F6(X) = 0.1{sin2(3 x1) + d i=1(xi 1)2[1 + sin2(3 xi + 1)] + (xd 1)2[1 + sin2(2 xd)]} + d i=1 u(xi, 5, 100, 4), x [ 50, 50]30 0 F7(X) =  1 500 + 25 j=1 1 j+2 i=1(xi aij )6 1 , x [ 65.53, 65.53]2 1 F8(X) = 11 i=1 ai x1(b2 i +bix2) b2 i +bix3+x4 2 , x [ 5, 5]4 0.0003 F9(X) = 4x2 1 2.1x4 1 + 1 3 x6 1 + x1x2 4x2 2 + 4x4 2, x [ 5, 5]2 -1.0316 F10(X) =  x2 5.1 4 2 x2 1 + 5 x1 6 2 + 10(1 1 8 )cosx1 + 10, x [ 5, 10]X[0, 15] 0.398 F11(X) = [1 + (x1 + x2 + 1)2(19 14x1 + 3x2 1 14x2 + 6x1x2 + 3x2 2)] [30 + (2x1 3x2)2 (18 32x1 + 12x2 1 + 48x2 36x1x2 + 27x2 2)], x [ 5, 5]2 3 F12(X) = 5 i=1[(X ai)(X ai)T + ci] 1, x [0, 10]4 -10.1532 TABLE II: Parameter settings of existing and proposed algorithms Parameter GSA MGSA CKGSA Population Size (N) 50 50 50 Number of Iterations (itr) 1000 1000 1000 Gconstant (G0) 100 100 100 Alpha ( ) 20 20 20 final per 2 2 2 Biotic Potential ( ) 4 4) Wilcoxon Rank Sum Test: For statistical validation of the results, a non-parametric statistical test, wilcoxon rank sum test [16], has also been done. Table V shows the results of wilcoxon rank sum test for the NULL hypothesis which states similarity of two algorithms at 5% signi cance level for each benchmark function. In the table, p value and z value are presented for each benchmark functions, mea- sured by comparing the tness values of 30 runs for compared algorithms and proposed algorithm. If p < 0.05 then null hypothesis is rejected and symbolized by + or otherwise accepted represented by = . From the table, it is observed that the values generated by proposed algorithm are better than GSA and MGSA for three functions (F1, F2, F8) and for six functions (F1, F2, F3, F5, F6, F8) respectively. How- ever for other benchmark functions, it shows no signi cant difference. Therefore, it validates that the proposed algorithm outperforms. 5) Convergence Rate: The searching of best-so-far solution achieved by an algorithm is easily understandable by analyzing its convergence behavior on each benchmark function. Fig. 3 plots the convergence trends of the considered algorithms between number of iterations and corresponding best-so-far tness value. All the vertical axis in the gures are represented in a logarithmic scale and horizontal axis represents the iteration numbers, i.e. 200, 400, 600, 800, and 1000. From the gures, it can be analyzed that the proposed CKGSA has better convergence rate in almost all the unimodal and multi-modal functions as compared to existing algorithms. However, it is performing comparatively similar for few functions. Therefore, the observed results validate that the chaotic behavior in GSA nds not only better optimal solutions but also enhances its convergence rate. V. CONCLUSION In this paper, a novel chaotic Kbest GSA (CKGSA) has been introduced which uses chaotic Kbest. The introduced Kbest decreases chaotically while increasing the GSA performs and balances the exploration and exploitation non-linearly.The proposed algorithm has also enhanced convergence rate at later iterations and better solution precision and thus, reduced the possibility of stucking into local optima. The experimental results validate that the CKGSA outperforms the compared algorithms in terms of mean tness values, best solution, standard deviation values, and convergence behavior. The future work includes the applicability of proposed algorithm on real-world scenarios. REFERENCES [1] J. H. Holland, Adaptation in natural and arti cial systems: an intro- ductory analysis with applications to biology, control, and arti cial intelligence. U Michigan Press, 1975. [2] M. Dorigo, M. Birattari, and T. St utzle, Ant colony optimization, Computational Intelligence Magazine, IEEE, vol. 1, pp. 28 39, 2006. [3] J. Kennedy, Particle swarm optimization, in Encyclopedia of machine learning. Springer, 2011. [4] E. Rashedi, H. Nezamabadi-Pour, and S. Saryazdi, Gsa: a gravitational search algorithm, Information sciences, vol. 179, pp. 2232 2248, 2009. TABLE III: Comparison of mean tness value, best solution and standard deviation for 30 runs on benchmark functions GSA MGSA CKGSA F1 Avg. 253.7767 30.1224 15.0144 Best 99.2278 6.1996 0.8037 Std. 101.9828 17.9346 10.7364 F2 Avg. 28.7775 24.9007 24.0224 Best 25.6653 24.5247 23.6322 Std. 14.6493 0.2063 0.2148 F3 Avg. 2.38E-08 6.16E-08 2.45E-08 Best 1.69E-08 4.37E-08 1.87E-08 Std. 4.93E-09 5.78E-09 4.64E-09 F4 Avg. 0 0 0 Best 0 0 0 Std. 0 0 0 F5 Avg. 3.43E-09 1.08E-08 3.60E-09 Best 2.43E-09 9.10E-09 2.51E-09 Std. 5.38E-10 1.17E-09 4.72E-10 F6 Avg. 0.0014 0.0011 0.0015 Best 1.10E-18 1.36E-17 8.50E-19 Std. 0.0046 0.0034 0.0038 F7 Avg. 3.4283 3.5426 3.9861 Best 0.9980 0.9990 0.9980 Std. 2.8040 2.3789 2.4637 F8 Avg. 0.0022 0.0018 0.0011 Best 0.0010 0.0012 0.0007 Std. 0.0006 0.0004 0.0006 F9 Avg. -1.0316 -1.0316 -1.0316 Best -1.0316 -1.0316 -1.0316 Std. 5.38E-16 4.70E-16 6.12E-16 F10 Avg. 0.3979 0.3979 0.3979 Best 0.3979 0.3979 0.3979 Std. 0 0 0 F11 Avg. 3 3 3 Best 3 3 3 Std. 1.91E-15 5.82E-15 2.34E-15 F12 Avg. -5.8114 -7.2255 -7.9257 Best -10.1532 -10.1532 -10.1532 Std. 3.3915 3.4855 3.3251 [5] B. Zibanezhad, K. Zamanifar, N. Nematbakhsh, and F. Mardukhi, An approach for web services composition based on qos and gravitational search algorithm, in Innovations in Information Technology, 2009. IIT 09. International Conference on, 2009. [6] C. Lopez-Molina, H. Bustince, J. Fern andez, P. Couto, and B. De Baets, A gravitational approach to edge detection based on triangular norms, Pattern Recognition, vol. 43, pp. 3730 3741, 2010. [7] X. Han and X. Chang, A chaotic digital secure communication based on a modi ed gravitational search algorithm lter, Information Sciences, vol. 208, pp. 14 27, 2012. [8] M. K. Rafsanjani and M. B. Dowlatshahi, Using gravitational search algorithm for nding near-optimal base station location in two-tiered wsns, International Journal of Machine Learning and Computing, vol. 2, p. 377, 2012. [9] H.-C. Tsai, Y.-Y. Tyan, Y.-W. Wu, and Y.-H. Lin, Gravitational particle swarm, Applied Mathematics and Computation, vol. 219, pp. 9106 9117, 2013. [10] Y. Zhang, Y. Li, F. Xia, and Z. Luo, Immunity-based gravita- tional search algorithm, in Information Computing and Applications. TABLE IV: Average computational time (in seconds) of 30 runs on benchmark functions GSA MGSA CKGSA F1 18.6476 18.4054 12.8066 F2 14.2491 13.9796 8.4383 F3 13.6722 13.4465 7.9436 F4 14.1503 13.5915 8.0801 F5 14.4529 13.5512 8.0524 F6 17.0100 15.7141 10.2212 F7 17.4356 16.4042 13.0219 F8 10.1217 9.4107 5.8873 F9 9.2016 8.5902 5.2400 F10 9.3012 8.6211 5.2552 F11 9.3260 8.5847 5.2606 F12 11.1768 9.9440 6.4219 TABLE V: Results of the wilcoxon rank sum test for statistically signi cance level at = 0.05 on benchmark functions Function CKGSA-GSA CKGSA-MGSA p-value z-value SGFNT p-value z-value SGFNT F1 3.02E-11 -6.6456 + 0.0003 -3.6000 + F2 3.02E-11 -6.6456 + 3.17E-11 -6.6384 + F3 0.7117 0.3696 = 3.02E-11 -6.6457 + F4 0 915 = 0 915 = F5 0.2226 1.2197 = 3.02E-11 -6.6456 + F6 0.3182 0.9982 = 6.20E-07 -4.9848 + F7 0.1494 1.4416 = 0.4333 0.7836 = F8 7.77E-09 -5.7733 + 7.12E-09 -5.7881 + F9 0 915 = 0 915 = F10 0 915 = 0 915 = F11 0 915 = 0 915 = F12 0.0822 -1.7378 = 0.4909 -0.6889 = Springer, 2012. [11] Y. Kumar and G. Sahoo, A review on gravitational search algorithm and its applications to data clustering & classi cation, International Journal of Intelligent Systems and Applications, vol. 6, p. 79, 2014. [12] K. Pal, C. Saha, S. Das, and C. A. C. Coello, Dynamic constrained optimization with offspring repair based gravitational search algorithm, in Evolutionary Computation (CEC), 2013 IEEE Congress on, 2013. [13] Chaos theory and the logistic map - geoff boeing, http://geoffboeing. com/2015/03/chaos-theory-logistic-map/. [14] Y. Feng, G.-F. Teng, A.-X. Wang, and Y.-M. Yao, Chaotic inertia weight in particle swarm optimization, in Innovative Computing, Information and Control, 2007. ICICIC 07. Second International Conference on, 2007. [15] Logistic map from wolfram mathworld, http://mathworld.wolfram. com/LogisticMap.html. [16] J. Derrac, S. Garc a, D. Molina, and F. Herrera, A practical tutorial on the use of nonparametric statistical tests as a methodology for comparing evolutionary and swarm intelligence algorithms, Swarm and Evolutionary Computation, vol. 1, pp. 3 18, 2011. (a) F1 (b) F2 (c) F3 (d) F4 (e) F5 (f) F6 (g) F7 (h) F8 (i) F9 (j) F10 (k) F11 (l) F12 Fig. 3: The convergence graphs of benchmark functions View publication stats