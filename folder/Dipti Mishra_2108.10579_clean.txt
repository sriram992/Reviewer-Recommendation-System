Lossy Medical Image Compression using Residual Learning-based Dual Autoencoder Model Dipti Mishra , Satish Kumar Singh , and Rajat Kumar Singh Department of Electronics & Communication Engineering Department of Information Technology Department of Electronics & Communication Engineering Indian Institute of Information Technology Allahabad, Prayagraj, 211015, India Email: dipti.mishra28@gmail.com, sk.singh@iiita.ac.in, rajatsingh@iiita.ac.in Abstract In this work, we propose a two-stage autoencoder based compressor-decompressor framework for compressing malaria RBC cell image patches. We know that the medical images used for disease diagnosis are around multiple gigabytes size, which is quite huge. The proposed residual-based dual autoencoder network is trained to extract the unique features which are then used to reconstruct the original image through the decompressor module. The two latent space representations ( rst for the original image and second for the residual image) are used to rebuild the nal original image. Color-SSIM has been exclusively used to check the quality of the chrominance part of the cell images after decompression. The empirical results indicate that the proposed work outperformed other neural network related compression technique for medical images by approximately 35%, 10% and 5% in PSNR, Color SSIM and MS-SSIM respectively. The algorithm exhibits a signi cant improvement in bit savings of 76%, 78%, 75% & 74% over JPEG-LS, JP2K-LM, CALIC and recent neural network ap- proach respectively, making it a good compression-decompression technique. Index Terms lossy image compression, convolutional neural network, deep learning based, whole slide images (WSI), autoen- coder, residual, encoder-decoder, compression-decompression, RBM I. INTRODUCTION D EEP learning techniques are now mostly used for diverse applications in image classi cation, object detection, and segmentation task. Rapid development in this eld is made possible with the help of fast computing GPU resources. With the advancement in resources, image compression researchers are also diving and digging for these deep architectures available to date to accomplish the task of image compres- sion [1] [4]. Applying the principle of exploiting domain knowledge of image processing with the deep neural network architectures, proved to be better for image compression over conventional pre-deep learning era algorithms. The traditional image compression algorithms were dependent on transform and quantization analysis, and among them, mostly are lossy in nature. Mostly the researchers are con ned to lossy image compression due to various constraints of quality distortion and limitations on compression ratio. In the medical eld, pathologists used to diagnose diseases by analyzing large images using a recently developed imaging technique called Whole Slide Imaging (WSI) [5], [6]. WSI is a process to scan the glass slides to produce a digital slide. These images provide higher resolution and features in multi layers to extract very minute and ne details. The size of these images ranges from many gigabytes, which need a lot of storage and transmission bandwidth. So, there is an alarming need for highly ef cient lossless image compression algorithms to compress information-rich images like medical images. For compressing these images, lossy compression for these whole slide images can affect the diagnosis process due to the information loss. Therefore, lossless image compression is the optimal approach to preserve relevant information in the images where any type of data loss is not acceptable; for example, medical images, satellite images, or images to be sent to army war eld areas. JPEG 2000 [7], being lossless and lossy both, is a region of interest (ROI) based compression scheme involving multi-band decomposition through discrete wavelet transform (DWT). ROI implies that the different parts of the image can be encoded with variable bit rates providing variable image qualities. The uniqueness of this compression scheme is its exibility of scalable or progressive decoding in resolution and quality based on the availability of the receiver system data rate (related to different com- pression ratios based on different bit-rate suitability). Due to this property, the encoder and decoder employed in its architecture are quite complicated and costly. Speci cally, for lossless compression, the best available technique in literature is JPEG in lossless mode (JPEG-LS) [8], a prediction based effective approach based on a median edge detector (MED) with an additional entropy coding technique namely Golomb Rice Encoding (GRC) [9]. Context adaptive lossless image compression (CALIC) [10] was also heavily employed in literature based on the gradient adjusted predictor (GAP). It is based on MANIAC (Meta-Adaptive Near-zero Integer Arith- metic Coding), a context-adaptive method based on growing decision trees. Edge directed predictor (EDP) [11] was another approach which is optimized with least square techniques. In 2014, Hesabi et al. [12] exploited principle component analysis (PCA) [13] to learn the relationship between input samples and compressed representation to learn cross-image correlation. In [12], PCA was exploited to reduce the inter and intra image redundancies. The method outperformed JP2K-LM 978-0-7381-1151-3/20/$31.00 2020 IEEE arXiv:2108.10579v1 [eess.IV] 24 Aug 2021 16x16x16 O(x,y) Compressor R(x,y) Original Image f(x,y) (128x128x3) M1 LS 1 + Int. O/P Image Residual Image (128x128x3) Output Residual Image f''(x,y) (128x128x3) Decompressor (Decoder of M1) Final Image (128x128x3) LS 2 M2 M3 f'(x,y) Compressor Encoder Decoder Encoder Decoder - Concatenation 16x16x16 Fig. 1. Block diagram of the proposed compression-decompression model. (JPEG 2000 lossless mode) [7], JPEG-LS [14], CALIC, and bzip21 algorithm. However, the algorithm was only suitable for the correlated medical image dataset and not able to encounter sharp images, i.e., infected and non-infected cell images. On the other hand, the essential features extracted from the convolutional neural network (CNN) help to decide the salient regions so that context-speci c image compression can be achieved by allocating variable bits to different parts of the region. The salient region can be identi ed with the help of essential features extracted through CNN. This unique property of feature extraction forced the researchers to shift their domain to deep learning algorithms. All the compression techniques discussed so far have a compression ratio limited to 2:1 only. Then in 2016, Shen et al. [15] demonstrated a region of interest (ROI) based lossless cum lossy compression scheme for medical images. The approach exploited very less dissimilarity property between adjacent ROIs. The binary ROI feature maps are encoded by arithmetic coding [16]. Later on, Shen et al. [17] provided a lossless compression scheme followed by the Golomb Rice encoding technique (GRC) [9] on malaria-infected cells. However, the results on infected cells are not as good as in non-infected cells, showing that deep learning architectures have become less useful for infected cell image compression. Here, we focus on CNN based image compression for medical images like RBC blood cells. We have developed an algorithm based on residual error calculation for ROI based lossy compression. The architecture is simply a CNN designed for training of both correlated and uncorrelated type of cell images. In this work, we propose a de-correlation 1http://www.bzip.org/ based two-stage autoencoder network designed for lossy image compression, whose functionality is to extract features to reduce inter-image redundancies in addition to intra-image de- correlation. The proposed residual-based dual autoencoder is used to extract the signi cant features of non-infected and malaria-infected RBC cells. We have exploited the principle of deep residual autoencoding based on Restricted Boltzmann Machine (RBM) mentioned in [18], [19]. When implemented and assessed with performance metrics, the network worked well for both infected and non-infected cells, however much better for compressing infected cells with no loss in ROI. The key signi cant contributions are summarized as follows: First autoencoder is utilized to learn low-frequency com- ponents; however, the second autoencoder learns the high-frequency components of the residual image ob- tained. The second learning thereby helps to retain the high-frequency components like edges and textures etc., and hence helped to produce good quality images and calling it a lossy compression scheme. The algorithm has incorporated ROI based encoding to ensure variable bit coding dependent on the spatial content of the image. Since the medical images are of various colors and color symbolizes essential information, so we have directly incorporated color based structural similarity (C-SSIM) into account without exploiting color to gray and gray to color conversion in the pre-processing to avoid infor- mation loss. So, the use of color-SSIM ensures accurate subjective assessment. The rest of the paper details is organized as follows. Section II discusses the proposed compression-decompression framework based on dual autoencoders. Section III illustrates the dataset and other experimental set up details. Section IV throws a light on the empirical results obtained with the proposed algorithm. Section V ends with a conclusion of the work described in this paper. II. PROPOSED DUAL AUTOENCODER BASED COMPRESSION FRAMEWORK We have designed a codec network by cascading the com- pressor and decompressor module, exploiting a deep autoen- coder. The residual dual deep architecture technique is used to achieve lossy image compression on Malaria infected cell images. The network architecture for the proposed algorithm is shown in Fig. 1. The compressor module (M1) consists of an encoder-decoder architecture. Table I shows the layer- wise network details for the compression ratio of 6 : 1. Fully connected layer has not been used in the proposed encoder- decoder network making it a fully convolutional network (FCN) in nature. Initially, the deep autoencoder (M1) has been trained to get a compressed latent space representation (LS 1) of 16 16 16 size, which is then reconstructed by the decoder to obtain intermediate output image O(x, y) of 128 128 3 size. We further experimented for improving the quality of the obtained image. For that, the residual image R(x, y) is calculated by subtracting this intermediate output O(x, y) from the original image f(x, y). A factor of 128 then scales this residual image because of very little pixel intensity. The scaled residual is then substantially applied as the input to the same autoencoder architecture (M2) for residual learning only. This is to obtain a mapping of latent space representation with the residuals to get high-frequency information (edges, textures or boundary). The nal image is then reconstructed through this model with the help of compressed latent space representation (LS 1 and LS 2). These latent space representations LS 1 and LS 2 are concatenated followed by upscaling with the help of convolution and pooling layers. The decompressor module (M3) or decoder of module M1 or M2 acts by taking this concatenated and upscaled representation to decode them for the nal reconstruction of the image. The visual quality of the reconstructed image inferred that the dual autoencoder model performed well in improving the quality of images in terms of these compression performance metrics. III. DATASET AND EXPERIMENTAL SETTINGS The network has been trained on the Malaria Cell Images Dataset2, which consists of 27,558 cell images having equal samples of parasitic and non-infected cells. It is used to train the proposed network to capture the discriminative features of both type of cell images. The parasitic cell has a purple ring formation, which differentiates it from non-infected cells. In this dataset, the image size varies from 130 130 3 to 360 360 3, so we have resized the complete dataset to 128 128 3. Accordingly, 22,222 and 5334 images are used for training and testing the network respectively. To 2https://www.kaggle.com/iarunava/cell-images-for-detecting-malaria TABLE I ARCHITECTURE DETAILS OF THE PROPOSED COMPRESSOR (M1/M2) AND DECOMPRESSOR MODULE (M3) FOR 6 : 1 COMPRESSION RATIO. Encoder Decoder 3 3, 64 Conv, strides 2 2, ReLU Dense, 16, ReLU 2 2 Maxpooling 3 3, 32 Conv, ReLU 3 3, 32 Conv, strides 2 2, ReLU 2 2 Upsampling 2 2 Maxpooling 3 3, 32 Conv, ReLU 3 3, 32 Conv, strides 2 2, ReLU 2 2 Upsampling 2 2 Maxpooling 3 3, 64 Conv, ReLU Dense, 16, ReLU 2 2 Upsampling 3 3, 3 Conv, Sigmoid achieve accurate decision making, we have applied data clean- ing/whitening for getting reliable datasets. Data whitening is used to make the data less redundant so that all the features become uncorrelated with the same variance. By this way, correlation is reduced by merely projecting the dataset into eigen vectors, which is then followed by normalization. The dual-stage autoencoder network has been trained with mean square loss (MSE) function [20]. To achieve global minima, the network has been trained for 100 epochs with a batch size of 8. We have used the Adam optimizer with learning rate as 0.001. Moreover, the momentum parameters 1 = 0.9, 2 = 0.999 are selected which are reported to produce better results in [20], [21]. The proposed algorithm has been evaluated for the qual- ity of reconstructed images with the help of peak signal- to-noise ratio (PSNR) [22] and multi-structural similarity (MS-SSIM) [23]. One more thing to attract the attention of the researchers is that for these colored medical cell images, Color-SSIM (C-SSIM) [24], [25] has been exploited to assess the color quality of the images. It is because color images re ect more meaningful information than the corresponding gray-scale images. For color-SSIM, the im- age is modeled as a combination of four functions i.e., luminance comparison, contrast comparison, structural com- parison, and the color comparison. By de nition, Color SSIM = l(x, y).C(x, y).S(x, y).Cr(x, y) where, l(x, y), C(x, y), S(x, y) and Cr(x, y) are the luminance, contrast, structure and color comparison factor respectively between the original and reconstructed distorted images. Cr(x, y) is de ned as Cr = 1 1 k E(x, y), where E(x, y) is color delity value which is calculated between the S-CIELAB conversions of the two images X and Y ; k is a weighting constant, E = p (L 1 L 2)2 + (a 1 a 2)2 + (b 1 b 2)2). Here, L , a and b , represents the values from darkness to lightness (in the intensity range from 0-100), greenness to redness (in the intensity range from -128 to +127) and blueness to yellowness (in the intensity range from -128 to +127) respectively. Accordingly L 1, a 1, b 1 and L 2, a 2, b 2 are de ned for the two images X and Y respectively. We have TABLE II COMPARISON OF PROPOSED ALGORITHM WITH THE RELATED DEEP LEARNING BASED METHOD. Algorithm PSNR (dB)/C-SSIM/MS-SSIM Encoding Time Decoding Time Memory Used Shen's [17] 27.50/0.9423/0.9412 15ms 15ms 11.59 GB Proposed (with M1) (6:1) 29.33/0.9693/0.9634 5ms 5ms 9.11 GB Proposed (with M1, M2 & M3) (6:1) 35.91/0.9878/0.9704 6.67ms 10ms 11.23 GB used Python, an open-source coding platform with Keras and Tensor ow, deep learning framework for all the experiments. The network is trained on 16 GB CPU RAM, 12 GB GPU enabled system TITAN X (Pascal)/PCIe/SSE2. IV. RESULTS & DISCUSSION The proposed network containing a two-stage autoencoder network based on residual learning helped to preserve the ne details in infected cell images. Here, we found that the storage space required to store the latent space representation is 12 times less than the original image size, making the compres- sion ratio to 6 : 1. Since for training, the rst autoencoder (M1) is provided with the raw images and the second autoencoder (M2) is provided with the residual images, it can be inferred that M1 and M2 are learning the low and high-frequency components respectively. The additional implementation of the second (M3), which is a decompressor module, further improved the quality of reconstructed malaria cell images as the nal output is better than O(x, y) in terms of performance measures as shown in Table II. The empirical results indicate that the proposed work outperformed Shen's compression technique for medical images by approximately 35%, 10% and 5% in PSNR, Color SSIM and MS-SSIM respectively. Also, the output images are found to contain less number of blocking and ringing effects as can be seen from images shown in Fig 2. It is because the network is able to retain both low-frequency and high-frequency components which are learned in two-phases. We have compared the original image with intermediate output and nal output separately. As color images re ect more meaningful information than the corresponding gray-scale images, color-SSIM has been used for proper assessment. The rst example, shown in Fig. 2 being a normal cell image, shows a high value of MS-SSIM, as the algorithm need not focus on any region of interest, and each region is compressed uniformly. But for the other two images, more bits are allocated for ROI, and less on other regions, these enhanced values of the metrics for ROI claims to be another contribution. For the sake of comparison, we have reproduced the results of Shen's algorithm. The bit-rate comparison (at CR=6:1) with the state- of-the-art method reveals that the proposed algorithm is able to perform excellently at an extremely low bit-rate (1.4 bpp) for providing lossy compression as shown in Table III. The algorithm exhibits a signi cant improvement in bit savings of 76%, 78%, 75% & 74% over JPEG-LS, JP2K-LM, CALIC and recent neural network approach respectively. The algorithm design is universal for all types of images, but we develop a Original Image M1 Output Residual M3 Output 31.94/0.9839/0.9755 39.07/0.9948/0.9763 32.50/0.9828/0.9651 38.26/0.9925/0.9724 31.36/0.9729/0.956 37.67/0.9860/0.9669 Fig. 2. Visual quality comparison (PSNR (dB)/C-SSIM/MS-SSIM) of nal reconstructed images (M3 output) with the original images and intermediate output images (M1 output). TABLE III COMPRESSION GAIN (BPP) COMPARISON WITH BENCHMARK AND STATE-OF-THE-ART ALGORITHMS. Method JPEG- LS [8] JP2K- LM [7] CALIC [10] Shen's [17] Proposed Bit-rate (bpp) 5.83 6.34 5.52 5.34 1.40 lossy compression algorithm to generate distortion-less images at extremely low bit-rates (bpp) and high compression ratio (much beyond 2:1). It is found that the results obtained are far better than the mentioned approaches due to residual learning technique which is responsible for preserving ner details. The training time undertaken by M1 and M2 modules is 75s and 25s per epoch, respectively. So, the total time taken by the network to train is approximately 2 hours and 70 minutes respectively. Also, the average residual generation time is 79ms, which is very less. The testing time to decode one image is around 10ms, which is 1.5 times the encoding time. The comparison on the basis of compression parameters like encoding time, decoding time and memory resource utilization is given in Table II. The testing time also indicates that the proposed network is not too much complex and can be practically realized. Additionally, we have also applied the Huffman encoding and decoding technique on the latent space representations (to obtain bit-stream), further to reduce the le size to be stored or transmitted. However, when implemented, it did not contributed in further reducing le size. This is due to the minimal size of the training images used since Huffman coding is very ef cient in encoding large-sized images. We have also tried to incorporate context adaptive binary adap- tive coding (CABAC) as an entropy coding on the residual obtained, but it didn't provide much improvement. As far as we know, this is one of the good lossy image compression approaches for medical images giving better results than the mentioned approach as high-frequency components are learned separately through residual learning. V. CONCLUSION We have implemented the dual autoencoder based compression-decompression algorithm using deep learning technique on malaria cell images. The dual autoencoder model is utilized to exploit both low and high frequency details of the image. It is clear that, the ne details in the ROI are not af- fected after decompression, which does not affect the diagnosis by any medical expert. The proposed framework reports to be a good ROI based lossy compression scheme, producing good quality images with minimum information loss. The algorithm successfully outperformed JPEG-LS, JP2K-LM, CALIC and other deep learning based state-of-the-art approaches. From the experiments, it is also concluded that the compression of the image not only depends upon the model architecture but also on the type and size of the images on which the model is being trained. For achieving more improvement with Huffman coding, large size images should be chosen for training with comparatively deep architecture, which can be a future scope of the work. REFERENCES [1] George Toderici, Damien Vincent, Nick Johnston, Sung Jin Hwang, David Minnen, Joel Shor, and Michele Covell. Full resolution image compression with recurrent neural networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 5306 5314, 2017. [2] Aaditya Prakash, Nick Moran, Solomon Garber, Antonella DiLillo, and James Storer. Semantic perceptual image compression using deep convolution networks. In 2017 Data Compression Conference (DCC), pages 250 259. IEEE, 2017. [3] Johannes Ball e, Valero Laparra, and Eero P Simoncelli. End-to-End Optimized Image Compression. International Conference on Learning Representations, 2017. [4] Lucas Theis, Wenzhe Shi, Andrew Cunningham, and Ferenc Husz ar. Lossy Image Compression with Compressive Autoencoders. CoRR, abs/1703.00395, 2017. [5] Thomas Kalinski, Ralf Zw onitzer, Florian Grabellus, Sien-Yi Sheu, Saadettin Sel, Harald Hofmann, and Albert Roessner. Lossless com- pression of JPEG2000 whole slide images is not required for diagnostic virtual microscopy. American journal of clinical pathology, 136(6):889 895, 2011. [6] Anurag Sharma, Pinky Bautista, and Yukako Yagi. Balancing image quality and compression factor for special stains whole slide images. Analytical Cellular Pathology, 35(2):101 106, 2012. [7] Charilaos Christopoulos, Athanassios Skodras, and Touradj Ebrahimi. The JPEG2000 still image coding system: An Overview. IEEE trans- actions on consumer electronics, 46(4):1103 1127, 2000. [8] Marcelo J Weinberger, Gadiel Seroussi, and Guillermo Sapiro. The LOCO-I lossless image compression algorithm: Principles and stan- dardization into JPEG-LS. IEEE Transactions on Image processing, 9(8):1309 1324, 2000. [9] Solomon Golomb. Run-Length Encodings (Corresp.). IEEE transactions on information theory, 12(3):399 401, 1966. [10] Xiaolin Wu and Nasir Memon. Context-based lossless interband compression-extending CALIC. IEEE Transactions on Image Process- ing, 9(6):994 1001, 2000. [11] Xin Li and Michael T Orchard. Edge-directed prediction for lossless compression of natural images. IEEE Transactions on image processing, 10(6):813 817, 2001. [12] Zhinoos Razavi Hesabi, Mohsen Sardari, Ahmad Beirami, Faramarz Fekri, Mohamed Deriche, and Antonio Navarro. A memory-assisted lossless compression algorithm for medical images. In 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 2030 2034. IEEE, 2014. [13] Karl Pearson. Liii. on lines and planes of closest t to systems of points in space. The London, Edinburgh, and Dublin Philosophical Magazine and Journal of Science, 2(11):559 572, 1901. [14] Gregory K Wallace. The JPEG still picture compression standard. IEEE transactions on consumer electronics, 38(1):xviii xxxiv, 1992. [15] Yuhang Dong, Hongda Shen, and W David Pan. An interactive tool for ROI extraction and compression on whole slide images. In 2016 IEEE- EMBS International Conference on Biomedical and Health Informatics (BHI), pages 224 227. IEEE, 2016. [16] David JC MacKay and David JC Mac Kay. Information theory, Inference and Learning algorithms. Cambridge university press, 2003. [17] Hongda Shen, W David Pan, Yuhang Dong, and Mohammad Alim. Loss- less compression of curated erythrocyte images using deep autoencoders for malaria infection diagnosis. In 2016 Picture Coding Symposium (PCS), pages 1 5. IEEE, 2016. [18] Geoffrey E Hinton and Ruslan R Salakhutdinov. Reducing the dimen- sionality of data with neural networks. science, 313(5786):504 507, 2006. [19] Yoshua Bengio, Pascal Lamblin, Dan Popovici, and Hugo Larochelle. Greedy layer-wise training of deep networks. In Advances in neural information processing systems, pages 153 160, 2007. [20] James R Thompson. Some shrinkage techniques for estimating the mean. Journal of the American Statistical Association, 63(321):113 122, 1968. [21] D. Mishra, S. K. Singh, and R. K. Singh. Wavelet-based deep auto encoder-decoder (wdaed)-based image compression. IEEE Transactions on Circuits and Systems for Video Technology, 31(4):1452 1462, 2021. [22] David Salomon. Data compression: the complete reference. Springer Science & Business Media, 2004. [23] Zhou Wang, Eero P Simoncelli, and Alan C Bovik. Multiscale structural similarity for image quality assessment. In The Thrity-Seventh Asilomar Conference on Signals, Systems & Computers, 2003, volume 2, pages 1398 1402. Ieee, 2003. [24] Mohammed Hassan and Chakravarthy Bhagvati. Structural similarity measure for color images. International Journal of Computer Applica- tions, 43(14):7 12, 2012. [25] Mohammed Ahmed Hassan and Mazen Sheikh Bashraheel. Color-based structural similarity image quality assessment. In 2017 8th International Conference on Information Technology (ICIT), pages 691 696. IEEE, 2017.