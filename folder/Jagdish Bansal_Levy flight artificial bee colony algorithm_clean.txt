Full Terms & Conditions of access and use can be found at http://www.tandfonline.com/action/journalInformation?journalCode=tsys20 Download by: [South Asian University] Date: 20 September 2016, At: 03:43 International Journal of Systems Science ISSN: 0020-7721 (Print) 1464-5319 (Online) Journal homepage: http://www.tandfonline.com/loi/tsys20 L vy flight artificial bee colony algorithm Harish Sharma, Jagdish Chand Bansal, K. V. Arya & Xin-She Yang To cite this article: Harish Sharma, Jagdish Chand Bansal, K. V. Arya & Xin-She Yang (2016) L vy flight artificial bee colony algorithm, International Journal of Systems Science, 47:11, 2652-2670, DOI: 10.1080/00207721.2015.1010748 To link to this article: http://dx.doi.org/10.1080/00207721.2015.1010748 Published online: 17 Mar 2015. Submit your article to this journal Article views: 284 View related articles View Crossmark data International Journal of Systems Science, 2016 Vol. 47, No. 11, 2652 2670, http://dx.doi.org/10.1080/00207721.2015.1010748 L evy ight arti cial bee colony algorithm Harish Sharmaa, , Jagdish Chand Bansal b, K. V. Aryaa and Xin-She Yangc aDepartment of Information Communication and Technology, ABV-Indian Institute of Information Technology and Management, Gwalior, India; bDepartment of Mathematics, South Asian University, New Delhi, India; cSchool of Science and Technology, Middlesex University, London, UK (Received 23 June 2012; accepted 21 April 2013) Arti cial bee colony (ABC) optimisation algorithm is a relatively simple and recent population-based probabilistic approach for global optimisation. The solution search equation of ABC is signi cantly in uenced by a random quantity which helps in exploration at the cost of exploitation of the search space. In the ABC, there is a high chance to skip the true solution due to its large step sizes. In order to balance between diversity and convergence in the ABC, a L evy ight inspired search strategy is proposed and integrated with ABC. The proposed strategy is named as L evy Flight ABC (LFABC) has both the local and global search capability simultaneously and can be achieved by tuning the L evy ight parameters and thus automatically tuning the step sizes. In the LFABC, new solutions are generated around the best solution and it helps to enhance the exploitation capability of ABC. Furthermore, to improve the exploration capability, the numbers of scout bees are increased. The experiments on 20 test problems of different complexities and ve real-world engineering optimisation problems show that the proposed strategy outperforms the basic ABC and recent variants of ABC, namely, Gbest-guided ABC, best-so-far ABC and modi ed ABC in most of the experiments. Keywords: numerical optimisation; swarm intelligence; memetic algorithm; L evy ight local search 1. Introduction Swarm intelligence (SI) has become an emerging and in- teresting area in the eld of nature-inspired computing that has been used to solve optimisation problems during the past decade. SI is largely based on the collective behaviour of social creatures. Swarm-based optimisation algorithms nd solution by collaborative trial and error process. So- cial creatures utilise their ability of social learning to solve complex tasks. Peer to peer learning behaviour of social colonies is the main driving force behind the development of many ef cient swarm-based optimisation algorithms. Re- searchers have analysed such behaviours and designed al- gorithms that can be used to solve nonlinear, nonconvex or discrete optimisation problems. Previous research works (Dorigo & Di Caro, 1999; Kennedy & Eberhart, 1995; Price, Storn, & Lampinen, 2005; Vesterstrom & Thom- sen, 2004) have shown that algorithms based on SI have great potential to nd solutions of real-world optimisa- tion problems. The algorithms that have emerged in recent years include ant colony optimisation (ACO) (Dorigo & Di Caro, 1999), particle swarm optimisation (PSO) (Kennedy & Eberhart, 1995), bacterial foraging optimisation (BFO) (Passino, 2002), etc. Arti cial bee colony (ABC) optimisation algorithm in- troduced by Karaboga (2005) is a recent addition in this category. This algorithm is inspired by the behaviour of Corresponding author. Email: harish.sharma0107@gmail.com honey bees when seeking a quality food source. Like any other population-based optimisation algorithm, ABC con- sists of a population of potential solutions. The potential solutions are food sources of honey bees. The tness is de- termined in terms of the quality (nectar amount) of the food source. ABC is relatively a simple, fast and population- based stochastic search technique in the eld of nature- inspired algorithms. There are two fundamental processes which drive the swarm to update in ABC: the variation process, which en- ables exploring different areas of the search space, and the selection process, which ensures the exploitation of the previous experience. However, it has been shown that the ABC may occasionally stop proceeding toward the global optimum even though the population has not converged to a local optimum (Karaboga & Akay, 2009). It can be observed that the solution search equation of ABC algo- rithm is good at exploration but poor at exploitation (Zhu & Kwong, 2010). Therefore, to maintain the proper balance between exploration and exploitation behaviour of ABC, it is highly required to develop a local search (LS) approach in the basic ABC to exploit the search region. In this paper, a LS strategy inspired from L evy ight random walk is pro- posed and incorporated with ABC. The proposed strategy is used for nding the global optima of a unimodal and/or multimodal functions by iteratively reducing the step size C 2015 Taylor & Francis International Journal of Systems Science 2653 in updating process of the candidate solution in the search space within which the optima is known to exist. Further- more, to improve the diversity of the algorithm, numbers of scout bees are increased. The proposed strategy is com- pared to recent variants of ABC, named, gbest-guided ABC (GABC) algorithm (Zhu & Kwong, 2010), best-so-far ABC (BSFABC) (Banharnsakun, Achalakul, & Sirinaovakul, 2011) and modi ed ABC (MABC) (Akay & Karaboga, 2012). Rest of the paper is organised as follows. Section 2 describes a brief review on memetic approach. Basic ABC is explained in Section 3. L evy ight search strategy (LFSS) is proposed and described in Section 4. In Section 5, LFSS is incorporated with ABC. In Section 6, performance of the proposed strategy is analysed over test problems. In Section 7, ve real-world engineering optimisation problems are solved using proposed strategy. Finally, in Section 8, paper is concluded. 2. Brief review on memetic approach In the eld of optimisation, memetic computing is an in- teresting approach to solve the complex problems (Ong, Lim, & Chen, 2010). Memetic is synonymous to memes which can be described as instructions for carrying out behaviour, stored in brains (Blackmore, 1999). Memetic computing is de ned as ... a paradigm that uses the notion of memes as units of information encoded in computational representations for the purpose of problem solving (Ong et al., 2010). Memetic computing can be seen then as a sub- ject which studies complex structures composed of simple modules (memes), which interact and evolve adapting to the problem in order to solve it (Neri, 2012). A good sur- vey on memetic computing can be found in Ong et al. (2010), Neri (2012), and Chen, Ong, Lim, and Tan (2011). Memetic algorithms can be seen as an aspect of the re- alisation or condition-based subset of memetic computing (Chen et al., 2011). The term memetic algorithm (MA) was rst presented by Moscato (1989) as a population-based algorithm having local improvement strategy for search of solution. MAs are hybrid search methods that are based on the population-based search framework (Eiben & Smith, 2003; Fogel & Michalewicz, 1997) and neighbourhood- based LS framework (Hoos & St utzle, 2005). Popular ex- amples of population-based methods include genetic algo- rithms (GAs) and other evolutionary algorithms, while tabu search and simulated annealing are two prominent LS repre- sentatives. The main role of MA in evolutionary computing is to provide a LS to establish exploitation of the search space. LS algorithms can be categorised as (Neri, 2012) stochastic or deterministic behaviour, single solution or multisolution-based search, steepest descent or greedy-approach-based selection. An LS is thought of as an algorithmic structure con- verging to the closest local optimum, while the global search should have the potential of detecting the global optimum. Therefore, to maintain a proper balance between exploration and exploitation behaviour of an algorithm, it is highly required to incorporate an LS approach in the basic population-based algorithm to exploit the search region. Generally, population-based search algorithms like GA (Goldberg & Holland, 1988), evolution strategy (Beyer & Schwefel, 2002), differential evolution (DE) (Price et al., 2005), ACO (Dorigo & Di Caro, 1999), PSO (Kennedy, 2006), arti cial immune system (Dasgupta, 2006), ABC (Karaboga, 2005), etc. are stochastic in nature (Yang, 2010b). In recent years, researchers hybridised the LS procedures with the population-based algorithms to im- prove the exploitation capability of the population-based algorithms (Caponio, Neri, & Tirronen, 2009; Ishibuchi, Yoshida, & Murata, 2003; Mininno & Neri, 2010; Neri & Tirronen, 2009; Ong, Nair, & Keane, 2003; Valen- zuela & Smith, 2002; Wang, Wang, & Yang, 2009). Fur- thermore, MAs have been successfully applied to solve a wide range of complex optimisation problems like multiobjective optimisation (Goh, Ong, & Tan, 2009; Knowles, Corne, & Deb, 2008), continuous optimisation (Ong & Keane, 2004; Ong et al., 2003), combinatorial optimisation (Ishibuchi et al., 2003; Repoussis, Taran- tilis, & Ioannou, 2009; Tang, Mei, & Yao, 2009), bioin- formatics (Gallo, Carballido, & Ponzoni, 2009; Richer, Go effon, & Hao, 2009), ow shop scheduling (Ishibuchi et al., 2003), scheduling and routing (Brest, Zumer, & Maucec, 2006), machine learning (Caponio, Cascella, Neri, Salvatore, & Sumner, 2007; Ishibuchi & Yamamoto, 2004; Ruiz-Torrubiano & Su arez, 2010), etc. Ong and Keane (2004) introduced strategies for MAs control that decide at runtime which LS method is to be chosen for the local re nement of the solution. Further- more, they proposed multiple LS procedures during an MA search in the spirit of Lamarckian learning. Furthermore, Ong, Lim, Zhu, and Wong (2006) described a classi cation of memes adaptation in adaptive MAs on the basis of the mechanism used and the level of historical knowledge on the memes employed. Then, the asymptotic convergence properties of the adaptive MAs are analysed according to the classi cation. Nguyen, Ong, and Lim (2009) presented a novel probabilistic memetic framework that models MAs as a process involving the decision of embracing the sepa- rate actions of evolution or individual learning and analysed the probability of each process in locating the global opti- mum. Furthermore, the framework balances evolution and individual learning by governing the learning intensity of each individual according to the theoretical upper bound derived while the search progresses. In past, very few efforts have been done to incor- porate an LS with ABC. Kang, Li, Ma, and Li (2011) proposed a Hooke Jeeves ABC (HJABC) algorithm for 2654 H. Sharma et al. numerical optimisation. In HJABC, authors incorporated an LS technique which is based on HJ method (Hooke & Jeeves, 1961) with the basic ABC. Furthermore, Mezura- Montes and Velez-Koeppel (2010) introduced a variant of the basic ABC named Elitist ABC. In their work, the au- thors integrated two LS strategies. The rst LS strategy is used when 30%, 40%, 50%, 60%, 70%, 80%, 90%, 95% and 97% of function evaluations have been completed. The purpose of this is to improve the best solution achieved so far by generating a set of 1000 new food sources in its neighbourhood. The other LS works when 45%, 50%, 55%, 80%, 82%, 84%, 86%, 88%, 90%, 91%,92%, 93%, 94%, 95%, 96%, 97%, 98% and 99% of function evaluations have been reached. Fister, Fister, and Zumer (2012) proposed a memetic ABC for large-scale global optimisation. In their pro- posed work, ABC is hybridised with two LS heuristics: the Nelder Mead algorithm (Rao & Rao, 2009) and the ran- dom walk with direction exploitation (Rao & Rao, 2009). The former is attended more towards exploration, while the latter more towards exploitation of the search space. The stochastic adaptive rule as speci ed by Neri (Cotta & Neri, 2012) is applied for balancing the exploration and exploitation. Kang et al. (2011) presented a novel hybrid HJABC algorithm with intensi cation search based on the HJ pat- tern search and the ABC. In the HJABC, two modi cations are proposed, one is the tness ( ti) calculation function of basic ABC is changed and calculated by Equation (1) and another is that an HJ LS is incorporated with the basic ABC ti = 2 SP + 2(SP 1)(pi 1) NP 1 , (1) here pi is the position of the solution in the whole population after ranking, SP [1.0, 2.0] is the selection pressure. A medium value of SP = 1.5 can be a good choice and NP is the number of solutions. Furthermore, Kang, Li, and Ma (2011) described a Rosenbrock ABC (RABC) that combines Rosenbrock s ro- tational direction method with ABC for accurate numerical optimisation. In RABC, exploitation phase is introduced in the ABC using Rosenbrock s rotational direction method. 3. Arti cial bee colony (ABC) algorithm The ABC algorithm is relatively recent SI-based algorithm. The algorithm is inspired by the intelligent food foraging behaviour of honey bees. In ABC, each solution of the problem is called food source of honey bees. The tness is determined in terms of the quality of the food source. In ABC, honey bees are classi ed into three groups, namely employed bees, onlooker bees and scout bees. The numbers of employed bees are equal to the onlooker bees. The em- ployed bees are the bees which searches the food source and gather the information about the quality of the food source. Onlooker bees which stay in the hive search the food sources on the basis of the information gathered by the employed bees. The scout bee searches new food sources randomly in places of the abandoned food sources. Similar to the other population-based algorithms, ABC solution search process is an iterative process. After, initialisation of the ABC pa- rameters and swarm, it requires the repetitive iterations of the three phases, namely employed bee phase, onlooker bee phase and scout bee phase. Each of the phases is described as follows. 3.1. Initialisation of the swarm The parameters for the ABC are the number of food sources, the number of trials after which a food source is considered to be abandoned and the termination criteria. In the ba- sic ABC, the numbers of food sources are equal to the employed bees or onlooker bees. Initially, ABC generates a uniformly distributed population of SN solutions where each solution xi (i = 1, 2, . . . , SN) is a D-dimensional vec- tor. Here D is the number of variables in the optimisation problem and xi represent the ith food source in the swarm. Each food source is generated as follows: xij = xminj + rand[0, 1](xmaxj xminj), (2) here xminj and xmaxj are bounds of xi in jth direction and rand[0, 1] is a uniformly distributed random number in the range [0, 1]. 3.2. Employed bee phase In the employed bee phase, employed bees modify the cur- rent solution (food source) based on the information of individual experience and the tness value of the new solu- tion. If the tness value of the new solution is higher than that of the old solution, the bee updates her position with the new one and discards the old one. The position update equation for ith candidate in this phase is vij = xij + ij(xij xkj), (3) here k {1, 2, . . . , SN} and j {1, 2, . . . , D} are randomly chosen indices. k must be different from i. ij is a random number between [ 1, 1]. 3.3. Onlooker bees phase After completion of the employed bees phase, the onlooker bees phase starts. In onlooker bees phase, all the employed bees share the new tness information (nectar) of the new solutions (food sources) and their position information with the onlooker bees in the hive. Onlooker bees anal- yse the available information and select a solution with a International Journal of Systems Science 2655 probability probi related to its tness. The probability probi may be calculated using following expression (there may be some other but must be a function of tness): probi = tnessi SN i=1 tnessi , (4) here tnessi is the tness value of the solution i. As in the case of the employed bee, it produces a modi cation on the position in its memory and checks the tness of the candidate source. If the tness is higher than that of the previous one, the bee memorises the new position and forgets the old one. 3.4. Scout bees phase If the position of a food source is not updated up to predeter- mined number of cycles, then the food source is assumed to be abandoned and scout bees phase starts. In this phase, the bee associated with the abandoned food source becomes scout bee and the food source is replaced by a randomly chosen food source within the search space. In ABC, pre- determined number of cycles is a crucial control parameter which is called limit for abandonment. Assume that the abandoned source is xi. The scout bee replaces this food source by a randomly chosen food source which is generated as follows: xij = xminj + rand[0, 1](xmaxj xminj), for j {1, 2, . . . , D}, (5) where xminj and xmaxj are bounds of xi in jth direction. 3.5. Main steps of the ABC algorithm Based on the above explanation, it is clear that there are three control parameters in ABC search process: the num- ber of food sources SN (equal to number of onlooker or employed bees), the value of limit and the maximum num- ber of iterations. The pseudo-code of the ABC is shown in Algorithm 1. (Karaboga & Akay, 2009). Algorithm 1. Arti cial bee colony algorithm Initialise the parameters; while Termination criteria is not satis ed do Step 1: employed bee phase for generating new food sources. Step 2: onlooker bees phase for updating the food sources depending on their nectar amounts. Step 3: scout bee phase for discovering the new food sources in place of abandoned food sources. Step 4: memorise the best food source found so far. end while Output the best solution found so far. 4. L evy ight inspired search strategy LS algorithms can be seen as a population-based stochas- tic algorithms, where main task is to exploit the avail- able knowledge about a problem. Generally, in LS algo- rithms, some or all individuals in the population are im- proved by some LS method. LS algorithms are basically designed to incorporate a LS strategy between iterations of a population-based search algorithm. In this way, the population-based global search algorithms are hybridised with LS algorithms and the hybridised algorithms named as MAs. In MAs, the global search capability of the main al- gorithm explore the search space, trying to identify the most promising search space regions while the LS part scrutinises the surroundings of some initial solution, exploiting it in this way. In this paper, we are proposing an LS strategy inspired by L evy ight random walk and named LFSS. In past, the ight behaviour of many animals and insects has been analysed in various studies which exhibit the important properties of L evy ights (Brown, Liebovitch, & Glendon, 2007; Pavlyukevich, 2007; Reynolds & Frye, 2007; Yang & Deb, 2010). Furthermore, this ight behaviour has been applied to optimisation and search algorithms, and the re- ported results show its importance in the eld of solution search algorithms (Pavlyukevich, 2007; Reynolds & Frye, 2007; Shlesinger, 2006; Shlesinger, Zaslavsky, & Frisch, 1995). Recently, Yang proposed a new metaheuristic algo- rithm by combining L evy ights with the search strategy via the re y algorithm (Yang, 2010a). The L evy ight is a random walk in which the steps are de ned in terms of the step lengths, which have a certain probability distribution. The random step lengths are drawn from a L evy distribution which is de ned in Equation (6): L(s) |s| 1 , where (0 < 2) is an index and s is the step length. (6) In this paper, a Mantegna algorithm (Yang, 2010b) for a symmetric L evy stable distribution is used for generating random step sizes. Here, symmetric means that the step size may be positive or negative. In Mantega s algorithm, the step length s can be calcu- lated by s = u |v|1/ , (7) where u and v are drawn from normal distributions. That is u N(0, u 2), v N(0, v 2), (8) 2656 H. Sharma et al. where u =  (1 + )sin( /2) [(1 + )/2]2( 1)/2 1/ , v = 1. (9) This distribution (for s) obeys the expected L evy distribu- tion for |s| |s0|, where s0 is the smallest step length (Yang, 2010b). Here (.) is the Gamma function and calculated as follows: (1 + ) =  0 t e tdt. (10) In a special case when is an integer, then we have (1 + ) = !. In the proposed strategy, the step sizes are generated using L evy distribution to exploit the search area and cal- culated as follows: step size(t) = 0.001 s(t) SLC, (11) here t is the iteration counter for LS strategy, s(t) is calcu- lated using L evy distribution as shown in Equation (7) and SLC is the social learning component of the global search algorithm. In L evy ights, the step sizes are too aggressive, that is, they may generate new solutions often outside the domain or on boundary. Since, the LS algorithms can be seen as population-based stochastic algorithms, where main task is to exploit the available knowledge about a problem and steps sizes play an important role in exploiting the identi ed region. Therefore, 0.001 multiplier is used in Equation (11) to reduce the step size. The solution update equation of an ith individual based on the proposed LS strategy is given in Equation (12): x ij(t + 1) = xij(t) + step size(t) U(0, 1), (12) here xij is the individual which is going to modify its po- sition, U(0, 1) is a uniformly distributed random number between 0 and 1 and step_size(t) U(0, 1) is the actual random walks or ights drawn from L evy distribution. The pseudo-code of the proposed LFSS is shown in Algorithm 2. In Algorithm 2, determines the termination of LS. 5. L evy ight arti cial bee colony Exploration and exploitation are the two important char- acteristics of the population-based optimisation algorithms such as GA (Goldberg & Holland, 1988), PSO (Kennedy & Eberhart, 1995), DE (Storn & Price, 1997), BFO (Passino, 2002) and so on. In these optimisation algorithms, the ex- ploration refers to the ability to investigate the various un- known regions in the solution space to discover the global Algorithm 2 L evy ight search strategy Input optimisation function Minf (x) and ; Select an individual xi in the swarm which is going to modify its position; Initialise t = 1 and v = 1; Compute u using Equation (9); while (t < ) do Compute step size using Equation (11); Generate a new solution x i using Equation (12); Calculate f (x i); if f (x i) < f (xi) then xi = x i; end if t = t + 1; end while optimum, while the exploitation refers to the ability to apply the knowledge of the previous good solutions to nd bet- ter solutions. In practice, the exploration and exploitation contradict with each other, and in order to achieve better optimisation performance, the two abilities should be well balanced. Karaboga and Akay (2009) (Karaboga & Akay, 2009) tested different variants of ABC for global optimisa- tion and found that the ABC shows poor performance and remains inef cient in exploring the search space. In ABC, any potential solution updates itself using the information provided by a randomly selected potential solution within the current swarm. In this process, a step size which is a linear combination of a random number ij [ 1, 1], current solution and a randomly selected solution are used. Now the quality of the updated solution highly depends upon this step size. If the step size is too large, which may occur if the difference of current solution and randomly se- lected solution is large with high absolute value of ij, then updated solution can surpass the true solution and if this step size is too small, then the convergence rate of ABC may signi cantly decrease. A proper balance of this step size can balance the exploration and exploitation capability of the ABC simultaneously. But, since this step size con- sists of random component, so the balance cannot be done manually. The exploitation capability can be enhanced by incorpo- ration of an LS algorithm with the ABC algorithm. There- fore, in this paper, to balance the diversity and conver- gence ability of ABC, the following four modi cations are proposed. (1) To enhance the exploitation capability of ABC, LFSS (described in Section 4) is incorporated with the basic ABC. In this way, the situation of skip- ping true solution can be avoided while maintaining the speed of convergence. The L evy ight search International Journal of Systems Science 2657 algorithm, in case of large step sizes, can search within the area that is jumped by the basic ABC. (2) In the basic ABC, the food sources are updated, as shown in equation (3). Inspired by PSO (Kennedy & Eberhart, 1995) and GABC (Zhu & Kwong, 2010) algorithms which, in order to improve the exploita- tion, take advantage of the information of the global best solution to guide the search of candidate so- lutions, the solution search equation described by Equation (3) is modi ed as follows (Zhu & Kwong, 2010): vij = xij + ij(xij xkj) + ij(xbestj xij), here, ij is a uniform random number in [0, C], where C is a non-negative constant. For detailed description refer to Zhu and Kwong (2010). (3) In the basic ABC, food sources are randomly ini- tialised by the scout bees in the static range (solu- tion search space). Therefore, there is a chance to jump outside of the already shrunken search space and the knowledge of the current reduced space (converged swarm) would be lost. Hence, in this paper, the scout bees randomly initialise the aban- doned food sources by using current interval in the swarm which is, as the search does progress, increasingly smaller than the corresponding initial range. Now the following equation is used to update a food source xi in the scout bee phase: xij = aj + rand[0, 1](bj aj), here, [aj, bj] is the shrunken search interval in the jth direction. (4) To enhance the exploration capability, the num- bers of scout bees are increased. This modi ca- tion avoids situation of stagnation of the algorithm. Therefore, in this paper, all the bees who crosses the limit boundary are treated as the scout bees. How- ever, only if this modi cation has been done in basic ABC, then it may make ABC relatively less stable as the scout bees do not use the previous knowledge for generating new food solutions and hence pre- vious learning has been lost. But in the proposed strategy, rst modi cation give more chance to best solution to update itself. Second modi cation uses the experience of global best solution and hence improves the convergence and third modi cation retains the acquired experience of the swarm about the search area, hence helps in exploitation. There- fore, in the rst three modi cations, better solutions get more chance in search process and minimise the threat of less stability while taking advantage of fourth modi cation in exploration of the search space. 0 10 20 30 40 50 60 70 80 90 100 0.02 0.015 0.01 0.005 0 0.005 0.01 Local search iterations Step size Figure 1. Size of L evy ights in two dimension search space for f11. As described in the proposed rst modi cation, a L evy ight random walk inspired LS is incorporated with the basic ABC to improve the exploitation capability. In the proposed LS strategy, step size is calculated as shown in Equation (13) step size(t) = 0.001 s(t) (xbestj(t) xkj(t)), (13) here, symbols have their usual meanings, SLC = (xbestj xkj) is the social learning component of the ABC algorithm in which xbest is the best solution in the current swarm and xk is the randomly selected solution within swarm and xk = xbest. The solution update equation of the best indi- vidual within the current swarm, based on the proposed LS strategy, is given in Equation (14): x bestj(t + 1) = xbestj(t) + step size(t) U(0, 1). (14) The proposed strategy in ABC is hereby, named as L evy Flight ABC (LFABC). In LFSS, only the best par- ticle of the current swarm updates itself in its neighbour- hood. Figures 1, 2 and 3 show an example of the L evy ight random walk used to update an individual in two dimension search space for Goldstein Price function (f11), 3.8 3.85 3.9 3.95 0.6 0.61 0.62 0.63 0.64 0.65 0.66 0.67 x1 x2 Starting Point End Point Figure 2. Best solution movement in the swarm during LFSS in two dimension search space for f11. 2658 H. Sharma et al. 2.8 3 3.2 3.4 3.6 3.8 4 0.45 0.5 0.55 0.6 0.65 0.7 x1 x2 Local Search Figure 3. Best solution movement using LFABC, in two dimen- sion search space for f11. refer Table 1. The pseudo-code of the proposed LFSS with ABC is shown in Algorithm 3. Algorithm 3 L evy ight search strategy with ABC Input optimisation function Minf (x) and ; Select the best solution xbest in the swarm; Initialise t = 1 and v = 1; Compute u using Equation (9); while (t < ) do Compute step size using Equation (11); Generate a new solution x best using Algorithm 4; Calculate f (x best); if f (x best) < f (xbest) then xbest = x best; end if t = t + 1; end while Algorithm 4 New solution generation Input the best solution xbest and s; for j = 1 to D do if U(0, 1) > pr then x bestj = xbestj + 0.001 s (xbestj xkj) U(0, 1); else x bestj = xbestj; end if end for Return x best In Algorithms 3 and 4, is the termination criteria of the proposed LS. pr is a perturbation rate (a number between 0 and 1) which controls the amount of perturbation in the best solution, U(0, 1) is a uniform distributed random number between 0 and 1, D is the dimension of the problem and xk is a randomly selected solution within swarm. See Section 6.2 for details of these parameter settings. The proposed LFABC consists of four phases: employed bee phase, onlooker bee phase, scout bee phase and LFSS. The pseudo-code of the LFABC algorithm is shown in Al- gorithm 5. Algorithm 5 L evy Flight ABC Initialise the parameters; while Termination criteria do Step 1: employed bee phase for generating new food sources. Step 2: onlooker bees phase for updating the food sources depending on their nectar amounts. Step 3: scout bee phase for discovering the new food sources in place of abandoned food sources. Step 4: apply L evy Flight search strategy (LFSS) phase using Algorithm 3. end while Print best solution. 6. Experimental results and discussion 6.1. Test problems under consideration In order to analyse the performance of LFABC, 20 different global optimisation problems (f1 to f20) are selected (listed in Table 1). These are continuous optimisation problems and have different degrees of complexity and multimodality. Test problems f1 to f5 and f11 to f20 are taken from Ali, Khompatraporn, and Zabinsky (2005) and test problems f6 to f10 are taken from Suganthan et al. (2005) with the associated offset values. 6.2. Experimental setting To prove the ef ciency of LFABC, it is compared with ABC and recent variants of ABC named GABC (Zhu & Kwong, 2010), BSFABC (Banharnsakun et al., 2011) and MABC (Akay & Karaboga, 2012). To test LFABC, ABC, GABC, BSFABC and MABC over considered problems, following experimental setting is adopted. Colony size NP = 50 (Diwold, Aderhold, Scheidler, & Middendorf, 2011; El-Abd, 2011). ij = rand[ 1, 1] . Number of food sources SN = NP/2. limit = D SN (Akay & Karaboga, 2012; Karaboga & Basturk, 2007). The stopping criteria is either maximum number of function evaluations (which is set to be 200,000) is reached or the acceptable error (mentioned in Table 1) has been achieved. The number of simulations/run =100. C = 1.5 (Zhu & Kwong, 2010), International Journal of Systems Science 2659 Table 1. Test problems. Test problem Objective function Search range Optimum value D Acceptable error Neumaier 3 problem (NF3) f1(x) = D i=1 (xi 1)2 D i=2 xixi 1 [ D2, D2] f ( 0) = (D (D + 4)(D 1))/6.0 10 1.0E 01 Beale function f2(x) = [1.5 x1(1 x2)]2 + [2.25 x1(1 x2 2)]2 + [2.625 x1(1 x3 2)]2 [ 4.5, 4.5] f(3, 0.5) = 0 2 1.0E 05 Colville function f3(x) = 100[x2 x2 1]2 + (1 x1)2 + 90(x4 x2 3)2 + (1 x3)2 + 10.1[(x2 1)2 + (x4 1)2] + 19.8(x2 1)(x4 1) [ 10, 10] f ( 1) = 0 4 1.0E 05 Branins s function f4(x) = a(x2 bx2 1 + cx1 d)2 + e(1 f ) cos x1 + e x1 [ 5, 10], x2 [0, 15] f( , 12.275) = 0.3979 2 1.0E 05 Kowalik function f5(x) = 11 i=1  ai x1(b2 i +bix2) b2 i +bix3+x4 2 [ 5, 5] f(0.1928, 0.1908, 0.1231, 0.1357) = 3.07E 04 4 1.0E 05 Shifted Rosenbrock f6(x) = D 1 i=1 (100(z2 i zi+1)2 + (zi 1)2) + fbias, z = x o + 1, x = [x1, x2, . . . , xD], o = [o1, o2, . . . , oD] [ 100, 100] f(o) = fbias = 390 10 1.0E 01 Shifted sphere f7(x) = D i=1 z2 i + fbias, z = x o, x = [x1, x2, . . . , xD], o = [o1, o2, . . . , oD] [ 100, 100] f(o) = fbias = 450 10 1.0E 05 Shifted Rastrigin f8(x) = D i=1(z2 i 10 cos(2 zi) + 10) + fbias,z = (x o), x=(x1,x2,...,xD), o=(o1,o2,...,oD) [ 5, 5] f(o) = fbias = 330 10 1.0E 02 Shifted Griewank f9(x) = D i=1 z2 i 4000 D i=1 cos( zi i ) + 1 + fbias, z = (x o), x = [x1, x2, . . . , xD], o = [o1, o2, . . . , oD] [ 600, 600] f(o) = fbias = 180 10 1.0E 05 Shifted Ackley f10(x) = 20 exp( 0.2 1 D D i=1 z2 i ) exp( 1 D D i=1 cos(2 zi)) + 20 + e + fbias, z = (x o), x = (x1, x2, . . . , xD), o = (o1, o2, . . . , oD) [ 32, 32] f(o) = fbias = 140 10 1.0E 05 Goldstein Price f11(x) = (1 + (x1 + x2 + 1)2(19 14x1 + 3x2 1 14x2 + 6x1x2 + 3x2 2))(30 + (2x1 3x2)2(18 32x1 + 12x2 1 + 48x2 36x1x2 + 27x2 2)) [ 2, 2] f(0, 1) = 3 2 1.0E 14 Six-hump camel back f12(x) = (4 2.1x2 1 + x4 1/3)x2 1 + x1x2 + ( 4 + 4x2 2)x2 2 [ 5, 5] f( 0.0898, 0.7126) = 1.0316 2 1.0E 05 Easom s function f13(x) = cosx1cosx2e(( (x1 )2 (x2 )2)) [ 10, 10] f( , ) = 1 2 1.0E 13 Dekkers and Aarts f14(x) = 105x2 1 + x2 2 (x2 1 + x2 2)2 + 10 5(x2 1 + x2 2)4 [ 20, 20] f(0, 15) = f(0, 15) = 24777 2 5.0E 01 (continued) 2660 H. Sharma et al. Table 1. (Continued) Test problem Objective function Search range Optimum value D Acceptable error Hosaki problem f15 = (1 8x1 + 7x2 1 7/3x3 1 + 1/4x4 1)x2 2 exp( x2) x1 [0, 5], x2 [0, 6] 2.3458 2 1.0E 6 McCormick f16(x) = sin(x1 + x2) + (x1 x2)2 3 2x1 + 5 2x2 + 1 x1 [ 1.5, 4], x2 [ 3, 3] f( 0.547, 1.547)= 1.9133 30 1.0E 04 Meyer and Roth f17(x) = 5 i=1 x1x3ti 1+x1ti+x2vi yi 2 [ 10, 10] f(3.13, 15.16, 0.78) = 0.4E 04 3 1.0E 03 Shubert f18(x) = 5 i=1 i cos((i + 1)x1 + 1) 5 i=1 i cos((i + 1)x2 + 1) [ 10, 10] f(7.0835, 4.8580) = 186.7309 2 1.0E 05 Sinusoidal f19(x) = [A n i=1 sin(xi z) + n i=1 sin(B(xi z))], A = 2.5, B = 5, z = 30 [0, 180] f ( 90 + z) = (A + 1) 10 1.0E 02 Moved axis parallel hyper-ellipsoid f20(x) = D i=1 5ix2 i [ 5.12, 5.12] f(x) = 0; x(i) = 5i, i = 1: D 30 1.0E 15 5 10 15 20 25 1958 1960 1962 1964 1966 1968 1970 1972 1974 Local search termination criteria (Maximum number of iterations) Success Rate Figure 4. Effect of LFSS termination criteria ( ) on SR. The value of = 2 is to be set based on the empirical experiments. To set termination criteria of LFSS, the performance of LFABC is measured for considered test problems on different values of and results are analysed in Figure 4. It is clear from Figure 4 that = 15 gives better results. Therefore, termination criteria is set to be = 15. Parameter settings for the algorithms GABC, BS- FABC and MABC are similar to their original re- search papers. In order to investigate the effect of the parameter pr, described by Algorithm 4 on the performance of LFABC, its sensitivity with respect to different val- ues of pr in the range [0.1, 1] is examined in Figure 5. It can be observed from Figure 5 that the test prob- 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 1750 1800 1850 1900 1950 2000 pr Success Rate Figure 5. Effect of parameter pr on SR. lems are very sensitive towards pr and value 0.2 gives comparatively better results. Therefore, pr = 0.2 is selected for the experiments in this paper. 6.3. Results comparison Numerical results with experimental setting of Subsection 6.2 are given in Table 2. In Table 2, standard deviation (SD), mean error (ME), average function evaluations (AFE) and success rate (SR) are reported. Table 2 shows that most of the time LFABC outperforms in terms of relia- bility, ef ciency and accuracy as compared to the basic ABC, GABC, BSFABC and MABC. Some more intensive analyses based on acceleration rate (AR) (Rahnamayan, Tizhoosh, & Salama, 2008), performance indices (PI) and International Journal of Systems Science 2661 Table 2. Comparison of the results of test problems. Test function Algorithm SD ME AFE SR f1 ABC 8.36E 01 9.66E 01 197,813.12 4 LFABC 6.84E 02 1.07E 01 39,650.81 95 GABC 1.58E+00 1.16E+00 191,063.41 11 BSFABC 5.19E+00 4.18E+00 200,026.1 0 MABC 6.65E 03 9.91E 02 127,828.88 98 f2 ABC 1.55E 06 8.74E 06 16,402.52 100 LFABC 2.84E 06 7.52E 06 3746.11 100 GABC 3.02E 06 5.28E 06 9553.01 100 BSFABC 2.31E 05 1.26E 05 43,260.44 96 MABC 2.76E 06 5.12E 06 9974.54 100 f3 ABC 1.15E 01 1.62E 01 194,852.27 4 LFABC 1.29E 03 9.19E 03 65,107.64 100 GABC 1.39E 02 1.72E 02 161,149.56 42 BSFABC 3.47E 02 2.38E 02 156,594.82 42 MABC 1.05E 02 1.42E 02 98,919.26 82 f4 ABC 5.98E 06 5.13E 06 2020.3 100 LFABC 7.12E 06 6.34E 06 14,867.54 93 GABC 6.50E 06 5.56E 06 17,019.79 92 BSFABC 6.92E 06 6.03E 06 33,561.7 84 MABC 6.95E 06 5.87E 06 24,764.92 89 f5 ABC 7.33E 05 1.70E 04 181,870.15 21 LFABC 1.79E 04 1.37E 04 61,386.26 95 GABC 2.69E 05 8.42E 05 81,335.87 95 BSFABC 6.27E 05 1.30E 04 140,290.92 59 MABC 7.05E 05 2.08E 04 148,042.35 58 f6 ABC 1.61E+00 9.45E 01 173,849.01 23 LFABC 7.64E 01 2.53E 01 66,632.89 95 GABC 1.16E 01 9.64E 02 110,835.85 93 BSFABC 4.21E+00 2.64E+00 183,435.91 17 MABC 9.14E 01 6.63E 01 128,771.75 54 f7 ABC 2.39E 06 7.25E 06 9014.5 100 LFABC 2.36E 06 7.27E 06 6203.32 100 GABC 2.24E 06 6.86E 06 5545 100 BSFABC 2.32E 06 7.09E 06 18,064.5 100 MABC 1.66E 06 7.72E 06 8671 100 f8 ABC 9.61E+00 8.68E+01 200,011.85 0 LFABC 2.07E+01 1.30E+02 200,026.27 0 GABC 9.87E+00 8.46E+01 200,008.55 0 BSFABC 1.76E+01 1.20E+02 200,036.17 0 MABC 1.13E+01 8.26E+01 200,014.08 0 f9 ABC 2.54E 03 8.42E 04 69,495.97 90 LFABC 7.35E 04 8.01E 05 40,382.88 100 GABC 2.97E 06 5.48E 06 40,280.38 100 BSFABC 5.83E 03 4.02E 03 105,148.43 64 MABC 1.03E 03 1.54E 04 78,393.47 98 f10 ABC 1.84E 06 7.86E 06 16,615.5 100 LFABC 1.34E 06 8.66E 06 10,934.63 100 GABC 1.28E 06 8.55E 06 9376.5 100 BSFABC 1.74E 06 8.21E 06 31,209 100 MABC 1.00E 06 8.85E 06 14,268.06 100 f11 ABC 6.06E 06 1.18E 06 107,740.64 61 LFABC 4.40E 15 5.22E 15 4468.6 100 GABC 4.33E 15 4.63E 15 4017.73 100 BSFABC 4.89E 15 6.67E 15 13,388.95 100 MABC 4.31E 15 5.04E 15 12,893.26 100 (continued) 2662 H. Sharma et al. Table 2. (Continued). Test function Algorithm SD ME AFE SR f12 ABC 1.07E 05 1.24E 05 982.52 100 LFABC 1.51E 05 1.33E 05 70,344.57 65 GABC 1.44E 05 1.69E 05 100,300.68 50 BSFABC 1.39E 05 1.86E 05 118,329.65 41 MABC 1.51E 05 1.65E 05 98,785 51 f13 ABC 5.27E 05 1.98E 05 197,359.89 4 LFABC 3.28E 14 5.60E 14 14,065.55 100 GABC 3.48E 12 3.97E 13 51,043.52 99 BSFABC 3.23E 14 4.83E 14 4680.58 100 MABC 2.51E 03 1.29E 03 200,025.34 0 f14 ABC 4.95E 03 4.89E 01 1424.57 100 LFABC 5.68E 03 4.91E 01 687.8 100 GABC 5.02E 03 4.89E 01 778 100 BSFABC 5.34E 03 4.91E 01 2775.72 100 MABC 5.85E 03 4.91E 01 2326.44 100 f15 ABC 5.91E 06 5.50E 06 656.5 100 LFABC 6.16E 06 5.45E 06 12,378.82 94 GABC 6.47E 06 5.81E 06 18,342.24 91 BSFABC 6.53E 06 6.58E 06 38,545.38 81 MABC 6.35E 06 5.53E 06 16,954.62 92 f16 ABC 7.00E 06 8.89E 05 1244.56 100 LFABC 6.96E 06 9.04E 05 587.42 100 GABC 6.00E 06 8.74E 05 612.5 100 BSFABC 6.57E 06 8.79E 05 989.56 100 MABC 7.01E 06 8.86E 05 1711.38 100 f17 ABC 2.84E 06 1.95E 03 31,280.19 100 LFABC 3.10E 06 1.95E 03 3418.07 100 GABC 3.18E 06 1.95E 03 5088.67 100 BSFABC 2.99E 06 1.95E 03 19,162.9 100 MABC 2.80E 06 1.95E 03 8565.87 100 f18 ABC 5.89E 06 5.19E 06 4572.09 100 LFABC 5.83E 06 5.16E 06 1619.34 100 GABC 5.71E 06 5.02E 06 2467.47 100 BSFABC 5.17E 06 4.37E 06 9081.59 100 MABC 5.98E 06 5.21E 06 27,782.89 100 f19 ABC 1.89E 03 7.64E 03 51,845.51 100 LFABC 1.67E 03 8.35E 03 22,030.31 100 GABC 2.13E 03 7.70E 03 47,747.58 100 BSFABC 2.05E 03 7.75E 03 64,507.74 100 MABC 8.94E 02 6.21E 01 200,033.69 0 f20 ABC 1.47E 16 8.20E 16 59,699 100 LFABC 1.09E 16 8.75E 16 44,903 100 GABC 9.98E 17 8.66E 16 48,738.5 100 BSFABC 2.37E 16 7.17E 16 71,124 100 MABC hline 7.11E 17 9.03E 16 59,554 100 boxplots have been carried out for results of ABC and its variants. LFABC, ABC, GABC, BSFABC and MABC are com- pared through SR, ME and AFE in Table 2. First SR is compared for all these algorithms and if it is not possible to distinguish the algorithms based on SR, then comparison is made on the basis of AFE. ME is used for comparison if it is not possible on the basis of SR and AFE both. Outcome of this comparison is summarised in Table 3. In Table 3, + indicates that the LFABC is better than the considered algorithms and indicates that the algorithm is not bet- ter or the difference is very small. The last row of Table 3 establishes the superiority of LFABC over ABC, GABC, BSFABC and MABC. Furthermore, we compare the convergence speed of the considered algorithms by measuring the AFEs. Smaller AFEs means higher convergence speed. In order to min- imise the effect of the stochastic nature of the algorithms, International Journal of Systems Science 2663 Table 3. Summary of Table 2 outcome. LFABC vs LFABC vs LFABC vs LFABC vs Function ABC GABC BSFABC MABC f1 + + + f2 + + + + f3 + + + + f4 + + + f5 + + + + f6 + + + + f7 + + + f8 f9 + + + f10 + + + f11 + + + f12 + + + f13 + + + f14 + + + + f15 + + + f16 + + + + f17 + + + + f18 + + + + f19 + + + + f20 + + + + Total number 16 15 18 18 of + sign the reported function evaluations for each test problem are the average over 100 runs. In order to compare convergence speeds, we use the which is de ned as follows, based on the AFEs for the two algorithms ALGO and LFABC: AR = AFEALGO AFELFABC , (15) ABC LFABC GABC BSFABC MABC 0 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2 x 10 5 Average Number of Function Evaluations Figure 6. Boxplots graphs for AFE. where ALGO {ABC, GABC, BSFABC, MABC} and AR > 1 means LFABC is faster. In order to investigate the AR of the proposed algorithm compared to the basic ABC and its variants, results of Table 2 are analysed and the value of AR is calculated using Equation (15). Table 4 shows a clear comparison between LFABC and ABC, LFABC and GABC, LFABC and BSFABC, and LFABC and MABC in terms of AR. It is clear from Table 4 that convergence speed of LFABC is faster among all the considered algorithms. For the purpose of comparison in terms of consolidated performance, boxplot analyses have been carried out for all the considered algorithms. The empirical distribution of data is ef ciently represented graphically by the boxplot analysis tool (Williamson, Parker, & Kendrick, 1989). The boxplots for ABC, LFABC, GABC, BSFABC and MABC are shown in Figure 6. It is clear from this gure that LFABC Table 4. Acceleration rate (AR) of LFABC compare to the basic ABC, GABC, BSFABC and MABC. Test problems ABC GABC BSFABC MABC f1 4.988879672 4.818650867 5.044691395 3.22386554 f2 4.378547346 2.550114652 11.54809656 2.662639378 f3 2.992771202 2.475125193 2.405168119 1.519318777 f4 0.135886636 1.144761675 2.257380844 1.665703943 f5 2.962717553 1.32498494 2.285379823 2.411652868 f6 2.609057029 1.663380502 2.752933424 1.932555379 f7 1.453173462 0.893876182 2.912069666 1.397799888 f8 0.999927909 0.999911412 1.000049493 0.999939058 f9 1.720926541 0.997461796 2.603787298 1.941255057 f10 1.519530153 0.857505009 2.854143213 1.304850736 f11 24.11060287 0.899102627 2.996229244 2.885301884 f12 0.013967247 1.425848221 1.682143341 1.404301711 f13 14.0314378 3.628974338 0.332769071 14.22093981 f14 2.071198023 1.131142774 4.035649898 3.382436755 f15 0.053034134 1.481743817 3.113816987 1.369647511 f16 2.118688502 1.042695176 1.684586837 2.91338395 f17 9.151418783 1.48875535 5.606350952 2.506054586 f18 2.823428063 1.523750417 5.608204577 17.15692196 f19 2.353371786 2.167358517 2.928135827 9.079930786 f20 1.329510278 1.085417455 1.58394762 1.326281095 2664 H. Sharma et al. is better than the considered algorithms as interquartile range and median are comparatively low. Furthermore, to compare the considered algorithms, by giving weighted importance to the SR, the ME and the average number of function evaluations, PI are calculated (Bansal & Sharma, 2012). The values of PI for the ABC, LFABC, GABC, BSFABC and MABC are calculated by using following equations: PI = 1 Np Np i=1 (k1 i 1 + k2 i 2 + k3 i 3), where i 1 = Sri Tri ; i 2 =  Mfi Afi , if Sri > 0. 0, if Sri = 0.; and i 3 = Moi Aoi , i = 1, 2, . . . , Np , Sri = successful simulations/runs of ith problem. Tri = total simulations of ith problem. Mfi = minimum of average number of function eval- uations used for obtaining the required solution of ith problem. Afi = average number of function evaluations used for obtaining the required solution of ith problem. Moi = minimum of ME obtained for the ith problem. Aoi = ME obtained by an algorithm for the ith prob- lem. Np = total number of optimisation problems evalu- ated. The weights assigned to the SR, the average number of function evaluations and the ME are represented by k1, k2 and k3, respectively, where k1 + k2 + k3 = 1 and 0 k1, k2, k3 1. To calculate the PIs, equal weights are assigned to two variables while weight of the remaining variables vary from 0 to 1 as given in Bansal and Sharma (2012). Following are the resultant cases: (1) k1 = W, k2 = k3 = 1 W 2 , 0 W 1; (2) k2 = W, k1 = k3 = 1 W 2 , 0 W 1; (3) k3 = W, k1 = k2 = 1 W 2 , 0 W 1 The graphs corresponding to each of the cases (1), (2) and (3) for ABC, LFABC, GABC, BSFABC and MABC are shown in Figure 7(a) (c), respectively. In these gures, the weights k1, k2 and k3 are represented by horizontal axis, while the PI is represented by the vertical axis. In case (1), average number of function evaluations and the ME are given equal weights. PIs of the considered algorithms are superimposed in Figure 7(a) for comparison of the performance. It is observed that PI of LFABC are higher than the considered algorithms. In case (2), equal weights are assigned to the SR and ME and in case (3), equal weights are assigned to the SR and average number of function evaluations. It is clear from Figure 7(b) and 7(c) that the algorithms perform same as in case (1). 7. Applications of LFABC to engineering optimisation problems To see the robustness of the proposed strategy, ve well- known engineering optimisation problems, namely, pres- sure vessel (con nement method) (Wang, Gao, & Ovaska, 2008), Lennard-Jones (Clerc, 2012), parameter estimation for frequency-modulated (FM) sound waves (Das & Sug- anthan, 2010), compression spring (Onwubolu & Babu, 2004; Sandgren, 1990) and welded beam design optimi- sation problem (Mahdavi, Fesanghary, & Damangir, 2007; Ragsdell & Phillips, 1976) are solved. The considered en- gineering optimisation problems are described as follows. 7.1. Pressure vessel design The pressure vessel design is to minimise the total cost of the material, forming and welding of a cylindrical ves- sel (Wang et al., 2008). There are four design variables involved: x1, (Ts, shell thickness), x2 (Th, spherical head thickness), x3 ( R, radius of cylindrical shell) and x4 ( L, shell length). The mathematical formulation of this typical constrained optimisation problem is as follows: E1( X) = 0.6224x1x3x4 + 1.7781x2x2 3 + 3.1611x2 1x4 + 19.84x2 1x3, subject to g1( X) = 0.0193x3 x1, g2( X) = 0.00954x3 x2, g3( X) = 750 1728 x2 3 x4 + 4 3x3  . The search boundaries for the variables are 1.125 x1 12.5, 0.625 x2 12.5, 1.0E 8 x3 240 and 1.0E 8 x4 240. The known global optimum solution isf(1.125, 0.625, 55.8592, 57.7315) = 7197.729 (Wang et al., 2008). A algorithm is said to be successful if it nds error less than 1.0E 5. 7.2. Lennard-Jones It is a potential energy minimisation problem of a set of N atoms. The position Xi of the atom i has three coordi- nates, and therefore, the dimension of the search space is 3N. In practice, the coordinates of a point x are the con- catenation of the ones of the Xi. In short, we can write International Journal of Systems Science 2665 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Weight (k1) Performance Index ABC LFABC GABC BSFABC MABC (a) 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Weight (k2) Performance Index ABC LFABC GABC BSFABC MABC (b) 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Weight (k3) Performance Index ABC LFABC GABC BSFABC MABC (c) Figure 7. Performance index for test problems: (a) for case (1), (b) for case (2) and (c) for case (3). X = (X1, X2, . . . , XN), and we have then E2( X) = N 1 i=1 N j=i+1 1 Xi Xj 2 1 Xi Xj  . In this study, N = 5, = 6 and the search space is [ 2, 2] (Clerc, 2012). 7.3. Frequency-modulated (FM) sound wave Frequency-modulated (FM) sound wave synthesis has an important role in several modern music systems. The parameter optimisation of an FM synthesiser is a six- dimensional optimisation problem where the vector to be optimised is X = {a1, w1, a2, w2, a3, w3} of the sound wave given in Equation (16). The problem is to generate a sound (1) similar to target (2). This problem is a highly complex multimodal one having strong epistasis, with min- imum value f ( Xsol) = 0. This problem has been tackled using GAs in Refs [1,2]. The expressions for the estimated sound and the target sound waves are given as y(t) = a1sin(w1t + a2sin(w2t + a3sin(w3t ))), (16) y0(t) = (1.0)sin((5.0)t (1.5)sin((4.8)t + (2.0)sin((4.9)t ))), (17) respectively, where = 2 /100 and the parameters are de ned in the range [ 6.4, 6.35]. The tness function is the summation of square errors between the estimated wave (1) and the target wave (2) as follows: E3( X) = 100 i=0 (y(t) y0(t))2. Acceptable error for this problem is 1.0E 05, i.e. an algorithm is considered successful if it nds the error less than the acceptable error in a given number of generations. 7.4. Compression spring The considered fourth engineering optimisation application is compression spring problem (Onwubolu & Babu, 2004; 2666 H. Sharma et al. Table 5. Comparison of the results of test problems. Test function Algorithm SD ME AFE SR E1 ABC 1.21E+01 1.78E+01 200,022.32 0 LFABC 1.62E+00 1.03E+00 199,313.43 3 GABC 4.04E+00 6.04E+00 200,023.52 0 BSFABC 2.23E+01 2.73E+01 200,038.25 0 MABC 8.64E+00 1.47E+01 200,025.66 0 E2 ABC 1.32E 04 8.65E 04 73,667.4 99 LFABC 1.16E 04 9.13E 04 29,437.45 98 GABC 7.03E 04 1.15E 03 112,503.53 73 BSFABC 3.54E 04 9.74E 04 126,621.9 81 MABC 1.65E 01 4.49E 01 140,965.5 25 E3 ABC 5.23E+00 5.99E+00 200,033.41 0 LFABC 5.22E+00 3.99E+00 160,861.01 45 GABC 4.86E+00 3.69E+00 191,679.01 11 BSFABC 4.86E+00 1.02E+01 200,031.93 0 MABC 3.05E+00 2.81E+00 200,018.79 0 E4 ABC 1.17E 02 1.36E 02 187,602.32 10 LFABC 1.27E 03 1.37E 03 147,049.12 24 GABC 9.50E 03 8.64E 03 189,543.56 11 BSFABC 3.08E 03 3.02E 02 200,031.13 0 MABC 6.59E 03 5.28E 03 181,705.01 15 E5 ABC 8.75E 02 2.52E 01 200,017.84 1 LFABC 5.07E 03 9.38E 02 38,992.28 100 GABC 9.22E 03 9.91E 02 116,903.66 68 BSFABC 5.12E 03 9.46E 02 53,885.62 98 MABC 4.91E 03 9.36E 02 32,049.47 100 Sandgren, 1990). This problem minimises the weight of a compression spring, subject to constraints of minimum de- ection, shear stress, surge frequency and limits on outside diameter and on design variables. There are three design variables: the wire diameter x1, the mean coil diameter x2 and the number of active coils x3. This is a simpli ed version of a more dif cult problem. The mathematical formulation of this problem is x1 {1, . . . , 70} granularity 1, x2 [0.6, 3], x3 [0.207, 0.5] granularity 0.001, and four constraints g1 = 8Cf Fmaxx2 x3 3 S 0, g2 = lf lmax 0, g3 = p pm 0, g4 = w Fmax FpK 0, with Cf = 1 + 0.75 x3 x2 x3 + 0.615x3 x2 , Fmax = 1000, S = 189, 000, lf = Fmax K + 1.05(x1 + 2)x3, lmax = 14, p = Fp K , pm = 6, Fp = 300, K = 11.5 106 x4 3 8x1x3 2 , w = 1.25, and the function to be minimised is E4( X) = 2 x2x2 3(x1 + 2) 4 . The best known solution is f(7, 1.386599591, 0.292) = 2.6254. Acceptable error for this problem is 1.0E 04. 7.5. Welded beam design optimisation problem The problem is to design a welded beam for minimum cost, subject to some constraints (Mahdavi et al., 2007; Ragsdell & Phillips, 1976). The objective is to nd the minimum fabricating cost of the welded beam subject to constraints on shear stress , bending stress , buckling load Pc, end International Journal of Systems Science 2667 Table 6. Summary of Table 5 outcome. LFABC vs LFABC vs LFABC vs LFABC vs Function ABC GABC BSFABC MABC E1 + + + + E2 + + + E3 + + + + E4 + + + + E5 + + + de ection and side constraint. There are four design vari- ables: x1, x2, x3 and x4. The mathematical formulation of the objective function is described as follows: E5( x) = 1.10471x2 1x2 + 0.04811x3x4(14.0 + x2), subject to g1( x) = ( x) max 0, g2( x) = ( x) max 0, g3( x) = x1 x4 0, g4( x) = ( x) max 0, g5( x) = P Pc( x) 0, 0.125 x1 5, 0.1 x2, x3 10 and 0.1 x4 5, where ( x) =  2 x2 R + 2, = P 2x1x2 , = MR J , M = P L + x2 2 , 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Weight (k1) Performance Index ABC LFABC GABC BSFABC MABC (a) 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Weight (k2) Performance Index ABC LFABC GABC BSFABC MABC (b) 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Weight (k3) Performance Index ABC LFABC GABC BSFABC MABC (c) Figure 8. Performance index for engineering optimisation problems: (a) for case (1), (b) for case (2) and (c) for case (3). 2668 H. Sharma et al. R =  x22 4 + x1 + x3 2 2 , J = 2   2x1x2  x22 4 + x1 + x3 2 2 , ( x) = 6PL x4x32 , ( x) = 6PL3 Ex4x32 , Pc( x) = 4.013Ex3x43 6L2  1 x3 2L  E 4G  , P = 6000 lb, L = 14 in., max = 0.25 in., max = 30, 000 psi, max = 13600 psi, E = 30 106 psi, G = 12 106 psi. The best known solution is (0.205730, 3.470489, 9.036624, 0.205729), which gives the function value 1.724852. Ac- ceptable error for this problem is 1.0E 01. 7.6. Experimental results To solve the constraint optimisation problems (E1, E4 and E5), a penalty function approach is used in the experiments. In this approach, the search is modi ed by converting the original problem into an unconstrained optimisation prob- lem by adding a penalty term in case of constraints violation as shown below f (x) = f (x) + , where f(x) is the original function value and is the penalty term which is set to 103. Table 5 shows the experimental results of the considered algorithms on the engineering optimisation problems. It is clear from Table 5 that the LFABC strategy performs better than the considered algorithms. Furthermore, the algorithms are compared through SR, ME and AFE. On the basis of results shown in Table 5, the results of comparison are given in Table 6. It is clear from Table 6 that the performance of LFABC is better or comparable to the considered algorithms. The algorithms are also compared on the basis of PI. The PI are calculated same as described in Section 6.3 and the results for each case are shown in Figure 8. It is observed from Figure 8 that the inclusion of the LFSS approach enhances the performance of ABC compared to the basic ABC and its recent variants. 8. Conclusion ABC can be ef cient, but it has a drawback that may lead to incorrect optimal solutions. In this paper, a L evy ight random walk inspired search strategy is proposed and in- corporated with ABC. This L evy ight based strategy can carry out both local and global search simultaneously with a focus on more ef cient LS. Therefore, it can be more ef- cient than any standard Gaussian random walks. The pro- posed modi ed ABC is named as LFABC. In the proposed LS, new solutions are generated in the neighbourhood of the best solution depending upon a newly introduced pa- rameter, perturbation rate. Furthermore, the proposed al- gorithm has been extensively compared with other recent variants of ABC, namely, GABC, BSFABC and MABC and with the help of experiments over test problems and engi- neering optimisation problems. Our simulation results have shown that the LFABC can outperform other algorithms considered in our tests in terms of reliability, ef ciency and accuracy. Disclosure statement No potential con ict of interest was reported by the authors. Notes on contributors Harish Sharma is working as an associate professor at Rajasthan Technical Univer- sity. He has more than 10 year of teach- ing experience. In past, he has served as an assistant professor at Government En- gineering College Jhalawar and Vardhman Mahaveer Open University, Kota. He re- ceived his BTech, MTech degree in Com- puter Engg. from Government Engineering College, Kota and Rajasthan Technical University, Rajasthan in 2003 and 2009, respectively. Dr Sharma has obtained his PhD in information communication and technology from ABV-Indian Institute of Information Technology and Management, Gwalior, India. His area of research is nature inspired algorithms and soft computing. Jagdish Chand Bansal is an assistant pro- fessor at South Asian University New Delhi. Dr Bansal has obtained his PhD in math- ematics from IIT Roorkee. Before joining SAU New Delhi, he has worked as an as- sistant professor at ABV-Indian Institute of Information Technology and Management Gwalior and BITS Pilani. He is the editor in chief of International Journal of Swarm Intelligence (IJSI) published by Inderscience. His primary area of interest is nature inspired optimisation techniques. He has pub- lished more than 40 research papers in various international jour- nals/conferences. Karm Veer Arya is working as an asso- ciate professor at ABV-Indian Institute of Information Technology and Management, Gwalior, India. He earned PhD degree in computer science and engineering from In- dian Institute of Technology (IIT Kanpur), Kanpur, India. He has more than 20 years of experience to teach the undergraduate and postgraduate classes. He has published more than 75 journal and conference papers in the area of in- formation security, image processing, biometrics, wireless ad hoc networks and soft computing. International Journal of Systems Science 2669 Xin-She Yang obtained his DPhil in ap- plied mathematics from the University of Oxford. He then worked at Cambridge Uni- versity and National Physical Laboratory (UK) as a senior research scientist. Now he is a research professor/reader at Middlesex University London, an adjunct professor at Reykjavik University (Iceland) and a guest professor at Xi an Polytechnic University (China). He is the IEEE CIS Chair for the task force on busi- ness intelligence and knowledge management, Director of Inter- national Consortium for Optimisation and Modelling in Science and Industry (iCOMSI), and the editor-in-chief of International Journal of Mathematical Modelling and Numerical Optimisation (IJMMNO). ORCID Jagdish Chand Bansal http://orcid.org/0000-0001-9029- 5129 References Akay, B., & Karaboga, D. (2012). A modi ed arti cial bee colony algorithm for real-parameter optimization. Information Sciences, 192, 120 142. Ali, M., Khompatraporn, C., & Zabinsky, Z. (2005). A numerical evaluation of several stochastic algorithms on selected con- tinuous global optimization test problems. Journal of Global Optimization, 31(4), 635 672. Banharnsakun, A., Achalakul, T., & Sirinaovakul, B. (2011). The best-so-far selection in arti cial bee colony algorithm. Ap- plied Soft Computing, 11(2), 2888 2901. Bansal, J.C., & Sharma, H. (2012). Cognitive learning in dif- ferential evolution and its application to model order reduc- tion problem for single-input single-output systems. Memetic Computing, 4(3), 209 229. Beyer, H., & Schwefel, H. (2002). Evolution strategies a com- prehensive introduction. Natural computing, Springer, 1(1), 3 52. Blackmore, S. (1999). The meme machine. Oxford: Oxford Uni- versity Press. Brest, J., Zumer, V., & Maucec, M.S. (2006, July). Self-adaptive differential evolution algorithm in constrained real-parameter optimization. In Evolutionary Computation, 2006. CEC 2006. IEEE Congress on (pp. 215 222). IEEE. Brown, C., Liebovitch, L., & Glendon, R. (2007). L evy ights in Dobe Ju/ hoansi foraging patterns. Human Ecology, 35(1), 129 138. Caponio, A., Cascella, G., Neri, F., Salvatore, N., & Sumner, M. (2007). A fast adaptive memetic algorithm for online and of ine control design of PMSM drives. IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics, 37(1), 28 41. Caponio, A., Neri, F., & Tirronen, V. (2009). Super- t control adaptation in memetic differential evolution frameworks. Soft Computing A Fusion of Foundations, Methodologies and Applications, 13(8), 811 831. Chen, X., Ong, Y., Lim, M., & Tan, K. (2011). A multi-facet survey on memetic computation. IEEE Transactions on Evolutionary Computation, 15(5), 591 607. Clerc, M. (2012). List based PSO for real problems. Retrieved from http://clerc.maurice.free.fr/pso /ListBasedPSO /List- BasedPSO28PSOsite29.pdf Cotta, C., & Neri, F. (2012). Memetic algorithms in continuous optimization. Handbook of Memetic Algorithms, 1, 121 134. Das, S., & Suganthan, P. (2010). Problem de nitions and evalua- tion criteria for CEC 2011 competition on testing evolution- ary algorithms on real world optimization problems (Tech. Rep.). Kolkata: Jadavpur University and Singapore: Nanyang Technological University. Dasgupta, D. (2006). Advances in arti cial immune systems. IEEE Computational Intelligence Magazine, 1(4), 40 49. Diwold, K., Aderhold, A., Scheidler, A., & Middendorf, M. (2011). Performance evaluation of arti cial bee colony op- timization and new selection schemes. Memetic Computing, 3(3), 149 162. Dorigo, M., & Di Caro, G. (1999). Ant colony optimization: A new meta-heuristic. In Proceedings of the 1999 Congress on Evolutionary Computation, 1999. CEC 99 (Vol. 2, pp. 28 29). Washington, DC: IEEE. Eiben, A., & Smith, J. (2003). Introduction to evolutionary com- puting. Berlin: Springer Verlag. El-Abd, M. (2011). Performance assessment of foraging algo- rithms vs. evolutionary algorithms. Information Sciences, 182(1), 243 263. Fister, I., Fister, I., Jr., & Zumer, J.B. (2012). Memetic arti cial bee colony algorithm for large-scale global optimization. In Evolutionary Computation (CEC), 2012 IEEE Congress on (pp. 1 8). IEEE. Fogel, D., & Michalewicz, Z. (1997). Handbook of evolutionary computation. Abingdon: Taylor & Francis. Gallo, C., Carballido, J., & Ponzoni, I. (2009). Bihea: A hybrid evolutionary approach for microarray biclustering. Advances in Bioinformatics and Computational Biology, 1, 36 47. Goh, C., Ong, Y., & Tan, K. (2009). Multi-objective memetic algorithms (Vol. 171). Berlin: Springer Verlag. Goldberg, D.E., & Holland, J.H. (1988). Genetic algorithms and machine learning. Machine Learning, 3(2), 95 99. Hooke, R., & Jeeves, T. (1961). Direct search solution of nu- merical and statistical problems. Journal of the ACM (JACM), 8(2), 212 229. Hoos, H., & St utzle, T. (2005). Stochastic local search: Founda- tions and applications. Burlington, MA: Morgan Kaufmann. Ishibuchi, H., & Yamamoto, T. (2004). Fuzzy rule selection by multi-objective genetic local search algorithms and rule eval- uation measures in data mining. Fuzzy Sets and Systems, 141(1), 59 88. Ishibuchi, H., Yoshida, T., & Murata, T. (2003). Balance between genetic search and local search in memetic algorithms for multiobjective permutation owshop scheduling. IEEE Trans- actions on Evolutionary Computation, 7(2), 204 223. Kang, F., Li, J., & Ma, Z. (2011). Rosenbrock arti cial bee colony algorithm for accurate global optimization of numerical func- tions. Information Sciences, 181(16), 3508 3531. Kang, F., Li, J., Ma, Z., & Li, H. (2011). Arti cial bee colony al- gorithm with local search for numerical optimization. Journal of Software, 6(3), 490 497. Karaboga, D. (2005). An idea based on honey bee swarm for numerical optimization (Tech. Rep. TR06). Erciyes: Erciyes Univ. Press. Karaboga, D., & Akay, B. (2009). A comparative study of arti - cial bee colony algorithm. Applied Mathematics and Compu- tation, 214(1), 108 132. Karaboga, D., & Basturk, B. (2007). Arti cial bee colony (ABC) optimization algorithm for solving constrained optimization problems. Foundations of Fuzzy Logic and Soft Computing, 1, 789 798. Kennedy, J. (2006). Swarm intelligence. Handbook of Nature- Inspired and Innovative Computing, 2, 187 219. Kennedy, J., & Eberhart, R. (1995). Particle swarm optimization. In IEEE International Conference on Neural Networks, 1995: 2670 H. Sharma et al. Proceedings (Vol. 4, pp. 1942 1948). University of Western Australia, Perth, Western Australia: IEEE. Knowles, J., Corne, D., & Deb, K. (2008). Multiobjective problem solving from nature: From concepts to applications (Natural computing series). Berlin: Springer. Mahdavi, M., Fesanghary, M., & Damangir, E. (2007). An im- proved harmony search algorithm for solving optimization problems. Applied Mathematics and Computation, 188(2), 1567 1579. Mezura-Montes, E., & Velez-Koeppel, R. (2010). Elitist arti - cial bee colony for constrained real-parameter optimization. In 2010 Congress on Evolutionary Computation (CEC) (pp. 2068 2075). Barcelona: IEEE Service Center. Mininno, E., & Neri, F. (2010). A memetic differential evolution approach in noisy optimization. Memetic Computing, 2(2), 111 135. Moscato, P. (1989). On evolution, search, optimization, genetic algorithms and martial arts: Towards memetic algorithms. Caltech concurrent computation program (C3P Report No. 826). Pasadena, CA: California Institute of Technology. Neri, F., Cotta, C., & Moscato, P. (Eds.). (2012). Handbook of memetic algorithms: Studies in computational intelligence (Vol. 379). Berlin: Springer. Neri, F., & Tirronen, V. (2009). Scale factor local search in differ- ential evolution. Memetic Computing Journal, 1(2), 153 171. Nguyen, Q., Ong, Y., & Lim, M. (2009). A probabilistic memetic framework. IEEE Transactions on Evolutionary Computation, 13(3), 604 623. Ong, Y., & Keane, A. (2004). Meta-Lamarckian learning in memetic algorithms. IEEE Transactions on Evolutionary Computation, 8(2), 99 110. Ong, Y., Lim, M., & Chen, X. (2010). Research frontier: Memetic computation past, present & future. IEEE Computational Intelligence Magazine, 5(2), 24 31. Ong, Y., Lim, M., Zhu, N., & Wong, K. (2006). Classi cation of adaptive memetic algorithms: A comparative study. IEEE Transactions on Systems, Man, and Cybernetics, Part B: Cy- bernetics, 36(1), 141 152. Ong, Y., Nair, P., & Keane, A. (2003). Evolutionary optimization of computationally expensive problems via surrogate model- ing. AIAA journal, 41(4), 687 696. Onwubolu, G., & Babu, B. (2004). New optimization techniques in engineering. Berlin: Springer Verlag. Passino, K. (2002). Biomimicry of bacterial foraging for dis- tributed optimization and control. Control Systems Magazine, IEEE, 22(3), 52 67. Pavlyukevich, I. (2007). L evy ights, non-local search and sim- ulated annealing. Journal of Computational Physics, 226(2), 1830 1844. Price, K., Storn, R., & Lampinen, J. (2005). Differential evolution: a practical approach to global optimization. Berlin: Springer Verlag. Ragsdell, K., & Phillips, D. (1976). Optimal design of a class of welded structures using geometric programming. ASME Journal of Engineering for Industries, 98(3), 1021 1025. Rahnamayan, S., Tizhoosh, H., & Salama, M. (2008). Opposition- based differential evolution. IEEE Transactions on Evolution- ary Computation, 12(1), 64 79. Rao, S., & Rao, S. (2009). Engineering optimization: Theory and practice. Manhattan, NY: Wiley. Repoussis, P., Tarantilis, C., & Ioannou, G. (2009). Arc-guided evolutionary algorithm for the vehicle routing problem with time windows. IEEE Transactions on Evolutionary Compu- tation, 13(3), 624 647. Reynolds, A., & Frye, M. (2007). Free- ight odor tracking in Drosophila is consistent with an optimal intermittent scale- free search. PLoS One, 2(4), e354. Richer, J., Go effon, A., & Hao, J. (2009). A memetic algorithm for phylogenetic reconstruction with maximum parsimony. Evo- lutionary Computation, Machine Learning and Data Mining in Bioinformatics, 1, 164 175. Ruiz-Torrubiano, R., & Su arez, A. (2010). Hybrid approaches and dimensionality reduction for portfolio selection with cardinal- ity constraints. IEEE Computational Intelligence Magazine, 5(2), 92 107. Sandgren, E. (1990). Nonlinear integer and discrete programming in mechanical design optimization. Journal of Mechanical Design, 112, 223. Shlesinger, M. (2006). Mathematical physics: Search research. Nature, 443(7109), 281 282. Shlesinger, M.F., Zaslavsky, G.M., & Frisch, U. (1995). L evy ights and related topics in physics. In Proceedings of the International Workshop Held at Nice, Levy ights and related topics in Physics, France, 27 30 June 1994 (Vol. 450, pp. 87 102). Springer. Storn, R., & Price, K. (1997). Differential evolution a simple and ef cient adaptive scheme for global optimization over continuous spaces. Journal of Global Optimization, 11, 341 359. Suganthan, P., Hansen, N., Liang, J., Deb, K., Chen, Y., Auger, A., & Tiwari, S. (2005). Problem de nitions and evaluation criteria for the CEC 2005 special session on real-parameter optimization. In CEC 2005 (pp. 1 50). Kanpur: Kanpur Ge- netic Algorithms Laboratory (KanGAL), Indian Institute of Technology. Tang, K., Mei, Y., & Yao, X. (2009). Memetic algorithm with extended neighborhood search for capacitated arc routing problems. IEEE Transactions on Evolutionary Computation, 13(5), 1151 1166. Valenzuela, J., & Smith, A. (2002). A seeded memetic algorithm for large unit commitment problems. Journal of Heuristics, 8(2), 173 195. Vesterstrom, J., & Thomsen, R. (2004). A comparative study of differential evolution, particle swarm optimization, and evolutionary algorithms on numerical benchmark problems. In Congress on Evolutionary Computation, 2004. CEC2004 (Vol. 2, pp. 1980 1987). Portland: IEEE. Wang, H., Wang, D., & Yang, S. (2009). A memetic algorithm with adaptive hill climbing strategy for dynamic optimiza- tion problems. Soft Computing A Fusion of Foundations, Methodologies and Applications, 13(8), 763 780. Wang, X., Gao, X., & Ovaska, S. (2008). A simulated annealing- based immune optimization method. In Proceedings of the International and Interdisciplinary Conference on Adap- tive Knowledge Representation and Reasoning (pp. 41 47). Espoo: Porvoo. Williamson, D., Parker, R., & Kendrick, J. (1989). The box plot: A simple visual method to interpret data. Annals of internal medicine, 110(11), 916 918. Yang, X. (2010a). Fire y algorithm, Levy ights and global op- timization. Research and Development in Intelligent Systems XXVI, 1, 209 218. Yang, X. (2010b). Nature-inspired metaheuristic algorithms (2nd ed.). Luniver Press. United Kingdom, Springer-Verlag Lon- don Ltd, London, Conference held in Granada, Spain. Yang, X.S., & Deb, S. (2010). Eagle strategy using L evy walk and re y algorithms for stochastic optimization. In Na- ture Inspired Cooperative Strategies for Optimization (NICSO 2010): Studies in Computational Intelligence (Vol. 284, pp. 101 111). Berlin: Springer Verlag. Zhu, G., & Kwong, S. (2010). Gbest-guided arti cial bee colony algorithm for numerical function optimization. Applied Math- ematics and Computation, 217(7), 3166 3173.