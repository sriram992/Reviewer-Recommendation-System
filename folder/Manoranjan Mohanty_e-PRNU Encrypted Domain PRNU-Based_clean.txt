Copyright Notice All rights reserved. No part of this publication may be reproduced, distributed, or transmitted in any form or by any means, including photocopying, recording, or other electronic or mechanical methods, without the prior written permission of the publisher, except in the case of brief quotations embodied in critical reviews and certain other non-commercial uses permitted by copyright law. IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING 1 e-PRNU: Encrypted Domain PRNU-Based Camera Attribution for Preserving Privacy* Manoranjan Mohanty, Ming Zhang, Muhammad Rizwan Asghar, and Giovanni Russello Abstract Photo Response Non-Uniformity (PRNU) noise-based source camera attribution is a popular digital forensic method. In this method, a camera ngerprint computed from a set of known images of the camera is matched against the extracted noise of an anonymous questionable image to nd out if the camera had taken the anonymous image. The possibility of privacy leak, however, is one of the main concerns of the PRNU-based method. Using the camera ngerprint (or the extracted noise), an adversary can identify the owner of the camera by matching the ngerprint with the noise of an image (or with the ngerprint computed from a set of images) crawled from a social media account. In this article, we address this privacy concern by encrypting both the ngerprint and the noise using the Boneh-Goh-Nissim (BGN) encryption scheme, and performing the matching in encrypted domain. To overcome leakage of privacy from the content of an image that is used in the ngerprint calculation, we compute the ngerprint within a trusted environment, such as ARM TrustZone. We present e-PRNU that aims at minimizing privacy loss and allows authorized forensic experts to perform camera attribution. The security analysis shows that the proposed approach is semantically secure. Experimental results show that the run-time computational overhead is 10.26 seconds when a cluster of 64 computing nodes are used. Index Terms Secure computation, PRNU-based camera attribution, Camera Fingerprinting, Privacy. ! 1 INTRODUCTION Photo Response Non-Uniformity (PRNU) noise-based source camera attribution [2], [3] is an effective method to nd out the source camera of an anonymous image. This method has been instrumental both to verify whether an anonymous questionable image, such as the one containing terrorist propaganda or child pornography, has been taken by a suspected camera, and in the case of no particular suspected camera, to identify the culprit camera from a database of suspected cameras. The PRNU-based approach is based on the PRNU noise pattern that is present in a camera sensor due to the manufacturing impurities. Because of the impurities, each pixel in the sensor generates a different response to light intensity than the ideal noise-free case, resulting in the PRNU noise. The PRNU noise can act as a camera ngerprint as this noise is unique for each camera. Since obtaining the exact PRNU noise is not possible without the cooperation of the camera manufacturer, the PRNU noise is typically estimated from an image. Using the estimated PRNU noise of a set of known images of the camera, a camera ngerprint is computed. Then, this ngerprint is correlated with the estimated PRNU noise of an anonymous query image to determine if the camera has taken the anonymous image. In the rest of this article, for simplicity, we call the estimated PRNU noise as the PRNU noise. All authors are with the School of Computer Science, The University of Auckland, New Zealand. They can be contacted by email: m.mohanty@auckland.ac.nz (Manoranjan), ming.zhang@auckland.ac.nz (Ming), r.asghar@auckland.ac.nz (Rizwan), and g.russello@auckland.ac.nz (Giovanni). *This work is an extension of our initial work accepted to be appeared in the proceedings of the 17th IEEE International Conference On Trust, Security And Privacy In Computing And Communications (Trustcom) 2018 under the title PANDORA: Preserving privacy in PRNU-based source camera attribution by Manoranjan Mohanty, Ming Zhang, Muhammad Rizwan Asghar, and Giovanni Russello [1]. One of the concerns with the PRNU-based approach, however, is its potential to leak privacy [4], [5]. If someone s camera nger- print is leaked, her identity can be known (even if the ngerprint is anonymized) by linking the ngerprint with the PRNU noise of images crawled from social media [6]. For example, in a court case, the identity of a suspect (who can be proved innocent later) or the identity of a witness can be known by unauthorized persons using the camera ngerprint of the suspect/witness. Below, we elaborate this possibility. A high-pro le personality is under investigation as a sus- pect in a case of child pornography. Given the sensitivity of the case, the suspect s name is suppressed until proven guilty. Third-party experts extract a ngerprint from the suspect s phone to match it against a database of known child pornography images. However, the suspect s nger- print is mishandled and is released to the public. In order to nd out the suspect, journalists match PRNU noise of images from social media with the leaked ngerprint and nd a matching image on a Facebook account belonging to a high-pro le music personality. The suspect s name ap- pears in the headlines of major national and international news describing him/her as a child abuser. However, later, the suspect is proved innocent. Nevertheless, the suspect s career is now ruined as he/she is now defamed. In a trial of a drug case, a witness has provided a picture showing the dealings of a syndicate. The identity of the witness is kept secret to ensure her safety. However, the image is (maliciously) leaked to the public. In order to identify who has taken the image, the drug syndicate matches the image with the ngerprint of a number of investigating journalists (the ngerprint can be previously known to the syndicate or can be freshly obtained using images from social media accounts). From the matchings, the syndicate identi es the journalist who has taken the IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING 2 image. Then, the journalist starts receiving threats from the syndicate. Although the scenarios above could seem far-fetched, it is clear that camera ngerprint can be misused to identify users through their online presence. The problem is further complicated by the fact that law enforcement agencies are using cloud storage and external third-party experts for handling digital evidence. For example, the ngerprints could be stored on a third-party server (e.g., cloud datacenter), or the ngerprints could be extracted and matched by external forensic experts. Previous researches on addressing the privacy issue have mainly focused on distorting the PRNU noise such that a reliable PRNU noise cannot be extracted from an image [7]. As explained in Section 3, these anti-forensic approaches however are not effective privacy-preserving methods as the PRNU noise is robust to a number of anti-forensic operations. 1.1 Our Contributions In this article, we present e-PRNU that addresses the privacy issue in PRNU-based camera attribution by encrypting the ngerprint and the PRNU noise, and performing the matching operations in an encrypted domain. e-PRNU allows the computation of the ngerprint within the device to be identi ed. The ngerprint is computed in a trusted environment where an adversary can neither access the content of an image (so that the privacy is not leaked from the image content) nor tamper with the ngerprint. In this work, we assume that mobile devices cameras are the devices to be identi ed. As such, given its presence in most current mobile devices, we use ARM TrustZone as a secure environment to compute the ngerprint. However, without loss of generality, our work can be generalized to any computing platform with a similar secure environment (e.g., Intel SGX) or where a secure element can be deployed in the device (e.g., secure SIM cards). In e-PRNU, both the ngerprints and the PRNU noise of query images are encrypted using the Boneh-Goh-Nissim (BGN) encryption scheme [8] that is homomorphic to an arbitrary number of additions and one multiplication. The encrypted ngerprint can be matched against the PRNU noise of a query image on a third-party server without accessing neither the ngerprint nor the PRNU noise in clearttext. As such, e-PRNU enables outsourcing to third-parties the most costly operations, such as storage and matching. Unlike previous PRNU noise distortion techniques, our scheme can ensure privacy while providing utility, as the privacy leak from the PRNU-based attribution method is minimized while ensuring that an authorized forensic expert can uninterruptedly perform her job. This article is based on our initial work [1]. This article makes the following new contributions. A detailed mathematical construction of the proposed approach is provided in Section 7. Based on the construction, security of the proposed ap- proach is mathematically analyzed in Section 8. The security analysis shows that the proposed approach is semantically secure. In the proposed approach, oating point numbers are converted to integers to make PRNU-based camera at- tribution method compatible with BGN encryption. The oat to integer conversion is done by rounding the oating point numbers. In Section 6.4, an analysis of the effect of oat-to-integer rounding error on the PRNU-based camera attribution is provided. The computational overhead and storage overhead of the proposed method are mathematically analyzed and exper- imentally computed in Section 9. The analysis and ex- periments show that the storage overhead of the proposed method is increased by 32 times. The run-time compu- tation cost is 404.17 seconds when only one computing node is used and 10.26 seconds when 64 computing nodes are used. An optimization scheme (for decreasing computational overhead and storage overhead) of using a select few pixels of the ngerprint and encrypting a subset of the selected pixels have been explored in detail. Based on an experimental study (as presented in Table 1), it is found that encryption of a subset of pixels is not feasible as this scheme can leak information about the ngerprint to an adversary (hence, can lead to data con dentiality issue). The rest of this article is organized as follows. Section 2 provides an overview of PRNU-based source camera attribution method, and ARM TrustZone. Section 3 reviews related work on anti-forensic schemes to PRNU-based source attribution method. These methods can preserve privacy by denying extraction of a reliable PRNU noise from an image. Section 4 describes our system model and threat model. Section 5 presents e-PRNU. In Section 6, we describe our BGN-based encrypted domain camera attribution in detail. Construction details of e-PRNU are given in Section 7, and security analysis is analysed in Section 8. Section 9 explains results and performance analysis of e-PRNU. Finally, Section 10 concludes this article and provides directions for future work. 2 BACKGROUND In this section, rst we provide an overview of PRNU-based source camera attribution method. Then, we describe some details of the ARM TrustZone. Fig. 1: PRNU-based source camera attribution: a ngerprint is computed from a set of known images of a camera while the noise is extracted from a query image. The ngerprint is matched with the extracted noise to determine if the query image has been taken from the same camera. 2.1 PRNU-Based Source Camera Attribution PRNU-based source camera attribution is a well-studied method [2], [9] [17]. This method is based on the fact that the IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING 3 sensor output I of a camera can be modeled as I = I(0) +I(0)X + , where I(0) is the noise-free output, X is the PRNU noise repre- senting the camera ngerprint, and is random noise. Using a de- noising lter F (such as a wavelet lter) and a set of images of a camera, we can estimate the camera ngerprint by rst estimating the PRNU noise of the ith image as Fi = Ii F(Ii), and then combining the PRNU noise of all the images. For determining if a speci c camera has taken a given query image I , we can rst obtain the PRNU noise F of the query image using F, and then correlate F with F to determine if the camera has taken I (as illustrated in Fig. 1). The correlation can be computed using Pearson correlation coef cient (r) that is given as: r(F,F ) = n i=1(Fi F)(F i F ) q n i=1(Fi F)2. q n i=1 (F i F ) 2 , (1) where F = n i Fi n and F = n i F i n . If the correlation value r(F,F ) is above a threshold, it is concluded that the query image belongs to the camera. The threshold is chosen per-camera. 2.2 ARM TrustZone The ARM TrustZone is a trusted execution environment tech- nology offered by ARM for its ARMv6 processor architecture. Most of the recent ARM-powered mobile devices are shipped with the TrustZone. Non-ARM powered mobile devices are equipped with alternative solutions that still provide a trusted execution environment, e.g., by Intel s SGX technology. The TrustZone divides the processor core into two virtual isolated cores called worlds: the secure world (also referred to as the virtual core or simply TrustZone) and the normal world. Both worlds are separated by hardware extensions, and any access to the secure world is highly regulated. The TrustZone has its own secure operating system, secure set of applications, and secure data stor- age. Since unauthorized data access and processing request cannot be made to the secure world, highly sensitive applications, such as Digital Rights Management (DRM) applications that access protected multimedia content, are executed in the TrustZone. The general-purpose non-secure applications, on the other hand, are executed in the normal world. 3 RELATED WORK In this section, we review anti-forensic approaches that have been proposed to prevent privacy leaks in PRNU-based methods. Various anti-forensic methods have been proposed to prevent PRNU-based source camera attribution [7]. These methods can either weaken the PRNU noise pattern or misalign the PRNU noise so that a reliable PRNU noise cannot be extracted from an image, and hence privacy of the image owner can be preserved. PRNU noise can be weakened by strong signal processing operations. Gloe et al. [18] proposed two such PRNU noise weakening techniques by (i) applying an undetectable re-sampling operation to the image, and by (ii) forging image origin by removing PRNU of one camera and by adding PRNU of another camera. Karakucuk et al. proposed two adaptive PRNU denoising methods [19], [20] that iteratively remove PRNU noise from an image based on an estimated gain factor of the PRNU. Another approach to weakening the PRNU noise is to suppress the PRNU noise using at- elding [18], [21]. The PRNU noise can be misaligned either by applying geo- metric transformations, such as cropping and resizing, or by using more sophisticated irreversible transformation techniques, such as forced seam-carving [4], patch-based desynchronization [22], and image stitching [7]. Both the PRNU noise weakening method and the PRNU noise misaligning method, however, have been proved ineffective. The PRNU noise can withstand common signal processing operations such as scaling, cropping and compression [23], [24]. According to Rosenfeld et al. [25], even after eight rounds of de-noising, there is still a signi cant correlation between the noise pattern of a multiply-denoised image and the ngerprint of the camera. The at- elding approach is less practical, and it can be defeated for a speci c use case [26]. Recently, Taspinar et al. [27] showed that even an irreversible transformation method, such as forced seam-carving, can also be ineffective. In addition, both the PRNU noise weakening method and the PRNU noise misaligning method do not guarantee utility as an authorized forensic expert cannot extract camera ngerprint for lawful use. Recently, Valsesia et al. [28] showed that random projection can be used to preserve privacy in PRNU-based approaches. Their approach is inspired by Bianchi et al. s work [29], which theoretically shows that the random projection can be used as a low-cost encryption scheme for preserving privacy in compressed sensing. To the best of our knowledge, no previous effort has been made for encrypted domain camera attribution that guarantees both utility and privacy. Some previous works, however, have focused on encrypted domain image processing [30] [33] using partial homomorphic encryption schemes, such as Shamir s secret sharing and Paillier encryption. 4 SYSTEM MODEL In our work, we consider that the law enforcement agencies have outsourced most of the camera attribution tasks to a third-party entity, such as a forensic expert or a third-party organization. The third-party is responsible for storing ngerprints and performing matching operations between stored ngerprints and the noise of an anonymous query image. In our system, we have the following entities: Fingerprint Source: This entity is an individual, an organization, or an application that computes camera ngerprint from a set of known images of the camera. This entity must ensure that the image content is not leaked to an adversary (to preserve privacy of the camera owner). In addition, this entity is also responsible to ensure that the ngerprint has not been tampered to provide false matchings. Since privacy can still be leaked from a computed ngerprint (even though it looks like a noise) by linking the ngerprint with images from social media, the Fingerprint Source encrypts the ngerprint. In this work, we assume that the application that generates the ngerprint is executed in a trusted environment. For instance, in case of a ngerprint generated from a mobile device, such as a smartphone, the application is executed in the ARM TrustZone of the phone. This prevents the phone owner to tamper with the ngerprint generation process. To prevent that the ngerprint is leaked in clear- text, the application encrypts the ngerprint still in the TrustZone before it sent off for further processing. IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING 4 Fig. 2: Overview of e-PRNU: The TrustZone takes as input some a set of known images (Step i) and calculates a ngerprint (Step ii). The ngerprint is encrypted and sent to the Fingerprint Store (Step iii). Upon request, a Match Maker takes as input a query image (Step 1) and calculates the PRNU noise (Step 2). The noise is encrypted and sent to the Third-Party Expert (Step 3). The Third-Party Expert fetches the stored ngerprints from the Fingerprint Store and, after performing encrypted matching, sends partial correlation values to the Match Maker Server (Step 5). The Match Maker Server decrypts partial correlation values (Step 6), computes the nal correlation value and sends it to the Match Maker (Step 7). The Match Maker makes the nal decision based on whether the nal correlation value is above a certain threshold (Step 8). Third-Party Expert: This entity stores encrypted nger- prints obtained from the Fingerprint Source, and matches a ngerprint with noise of a query image in the encrypted domain. This entity, however, does not know the infor- mation about the camera or the owner of the camera. Either an individual or an organization can act as a Third- Party Expert. In any case, this entity must have enough storage and processing power to store several thousand ngerprints and perform matchings in encrypted domain. To be cost-effective, this entity can outsource storage and computation to public cloud service providers, such as Amazon, Google, and Microsoft. Match Maker: This entity represents a trusted organiza- tion (e.g., law enforcement authority, a judge) who has the anonymous query image and who wants to nd the camera that took the image. The ngerprint matching process, however, has been outsourced to the Third-Party Expert, who must not know the image content or the extracted noise of the image in plaintext. The Match Maker therefore extracts noise from the query image at her end, encrypts the noise, and sends the encrypted noise to the Third-Party Expert. Match Maker Server: This entity is under the control of the Match Maker and it is used for performing the nal part of the matching on the values received from the Third-Party Expert. In comparison with the infrastructure managed by the Third-Party Expert, the Match Maker Server is smaller as it requires less computation power and storage for performing its tasks. Key Management Authority (KMA): This entity is responsible for generating public and private keys of BGN encryption. Threat Model: We assume the KMA as a fully trusted entity. The KMA can be under the direct control of the law enforcement authority. We also assume that the KMA securely transfers the keys to the Fingerprint Source, the Match Maker, and the Match Maker Server. The one-time key generation process can be pre- processed. Thus, the KMA can be assumed to be kept of ine in most of the time. The Fingerprint Source, the Match Maker, and the Match Maker Server are also assumed to be fully trusted entities. The Third-Party Expert is assumed to be honest but curious entity. That is, the Third-Party Expert is trusted to honestly perform its duty. However, it is not trusted to guarantee data con dentiality. The adversary can be either an outsider or even an insider, such as an unfaithful employee working for the Third- Party Expert. Furthermore, we assume that the Third-Party Expert has mechanisms to deal with the data integrity and availability. 5 PROPOSED APPROACH In this section, we provide an overview of our approach for en- crypted source camera attribution. Fig. 2 shows how the different entities in our architecture are interconnected. In our approach, the KMA generates encryption keys, and sends the public key to the Fingerprint Source and the Match Maker, and the private key to the Match Maker Server. Given a set of non-tampered known images (Step i) of a camera, the Fingerprint Source rst extracts the noise from the images, and then generates a ngerprint by combining the noise IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING 5 Fig. 3: Securely computation of a ngerprint using TrustZone. (as discussed in Section 2). The Fingerprint Source ensures the integrity of the images either by taking and storing the images in a trusted environment (such as in TrustZone), or detect tampered images (and hence discard them) using various image forensic techniques [34]. The generated ngerprint is encrypted using the public key received from the KMA (Step ii). The real Camera ID (CID) associated with the encrypted ngerprint is anonymized by introducing a dummy CID such that a camera cannot be linked to the Fingerprint Source. The encrypted ngerprint together with the CID is sent to the Third-Party Expert for storage and further processing (Step iii). The CID, CID tuple is sent to the Match Maker (Step iv)1. The Match Maker will either verify if a particular suspected camera has taken an anonymous query image (i.e., if a suspected CID is attached to the query image), or in the case of no suspected camera, identify the culprit camera (i.e., CID of the query image). Let us discuss the veri cation process rst. Identi cation is similar to veri cation. Given a non-tampered query image (Step 1), the Match Maker rst extracts PRNU noise. The extracted noise (Step 2) is then encrypted. The encrypted noise and its CID (Step 3) are sent to the Third-Party Expert. Using the CID , the Third-Party Expert retrieves the corresponding encrypted ngerprint (Step 4), and cor- relates the ngerprint with the encrypted PRNU noise (i.e., in the encrypted domain). Since the correlation process involves more complex operations than what homomorphically possible under the BGN encryption, the Third-Party Expert performs part of the correlation process on its end. The partial correlation result is sent to the Match Maker Server (Step 5). The Match Maker Server decrypts the encrypted result, and using the decrypted values (Step 6), completes the correlation operation. The correlation value is sent to the Match Maker (Step 7) that compares the correlation value with a threshold. If the correlation value is greater than or 1We assume that the communication between the Fingerprint Source and the Match Maker is protected. equal to the threshold, it is concluded that the image was taken by CID , and hence by CID (Step 8). The identi cation is similar to veri cation as the identi cation can be performed using a series of veri cations. In case of identi cation, the Match Maker can perform one-by-one matching for the CID, CID tuples in its database till the correlation value of a matching is more than or equal to the threshold. 6 SOLUTION DETAILS The main idea behind e-PRNU is to compute the camera nger- print and the PRNU noise of a query image in a trusted environ- ment (such as the ARM TrustZone), and match the ngerprint with the PRNU noise in encrypted domain. In the following sections, we explain in details some of the steps executed in e-PRNU. 6.1 Computing Fingerprint In this article, we assume that the ARM TrustZone is available to securely compute the ngerprint of a device. Fig. 3 outlines our approach. The images used in computing the ngerprint must be non-tampered. Thus, we take and store the images in the TrusZone. In our approach, the suspect installs the Fingerprint Creator App, an application that has the main activity Get Fingerprint in the Rich Operating System (OS) running in the normal world. When the user launches the app, Get Fingerprint activity requests the support of the Trusted OS to start the Take Picture service in the TrustZone. The Take Picture service takes several pictures with the phone camera. Because the camera is not under the TrustZone secure environment, an adversary that does not want that the cor- rect ngerprint is generated might try to modify the pictures before they reach the Take Picture service. To detect tampered images, the service uses various image forensic techniques [34]. If it detects that the pictures have been tampered with, it will discard them. Similarly, the service can mitigate ngerprint copy attacks using a previously proposed method [35], and use PRNU-based clustering technique [15] to nd out if the images are from multiple sources IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING 6 or from a source that has already been ngerprinted. Otherwise, the pictures are encrypted (before leaving the TrustZone) and stored in local storage. Once n number of pictures have been taken, the Compute Fingerprint service (still in the TrustZone) is invoked. The Compute Fingerprint service rst fetches the images from the local storage, and then computes ngerprint using wavelet lter-based method (as discussed in Section 2.1). Finally, the Compute Fingerprint service encrypts the ngerprint using our encryption mechanism described in details in the following section. Although the application presented is based on TrustZone, our work can be generalized to any computing platform where a secure environment is present, such as the Intel SGX. Another alternative, is to use a secure element such as a secure SIM card that can be deployed in the suspect s device. 6.2 Encrypting Fingerprint We consider that the ngerprint vector is represented using a vector F = {F1,F2,...,Fn} of length n. Our goal is to encrypt the value of an element of the vector (i.e., each Fi, where 1 i n) using the BGN encryption. The positions of the vector are kept in plaintext to facilitate future correlations. Each Fi, however, is a oating point number that is incompatible with the modular prime operation of the BGN scheme. Before encryption, we convert Fi to an integer Fint i by rst rounding of Fi by d decimal places and then multiplying 10d to the round-off value. The BGN scheme is computationally expensive. According to our experiments, encryption of a single oating point number requires 1.2 millisecond (ms). The encryption of a ngerprint computed from a standard 720 720 image requires 11 minutes (as the dimension of the ngerprint is equal to the dimension of the image). Such high computation overhead is not desirable for a practical solution. To overcome this issue, we used the concept of ngerprint compression. In this paper, the ngerprint digest-based compression [36] has been used. However, other techniques, such as random projection-based compression [37] [38] can also be used. A ngerprint digest is a trimmed down version of the n- gerprint. The correlation of the ngerprint digest with the PRNU digest (produced by trimming down the PRNU noise) can produce similar error rates (i.e., False Acceptance Rate FAR and False Rejection Rate FRR) to that of the correlation of the ngerprint with the PRNU noise. The ngerprint digest therefore can be used instead of the ngerprint where low overhead is desired (at the cost of slightly higher error rate). The ngerprint digest of m (where m < n) elements contains those m pixels which are more signi cant to the correlation. For example, the defective hot pixels (represented with large positive values) and dead pixels (represented with large negative values) can be part of the ngerprint digest. In practice, the ngerprint digest is found by rst sorting the ngerprint and then selecting m highest absolute value elements. In our work, we replace the full ngerprint F with ngerprint digest FD F, and encrypt the integral representation of each element of FD. The encrypted ngerprint digest E(FD) is then sent to the Third-Party Expert. One of the key requirements of our approach is to determine the number of elements in the digest, i.e., to nd value of m. The value must be chosen in such a way that both error rate and overheads are reasonable. In this article, we experimentally set the value of m to 10,000. For this number, FAR is 0.0521 and FRR is 0.12. In comparison to the non-digest method, the computational cost is decreased by more than 50 times. TABLE 1: Error rates for different k when m = 10000. k 2000 5000 6000 7000 8000 9000 FAR 0.0222 0.0556 0.0444 0.0444 0.0667 0.0778 FRR 0.05 0.05 0.1 0.25 0.3 0.35 One optimization to further decrease the overhead can be en- crypting a subset of k (where k < m) elements from the ngerprint digest and keep the remaining m k elements unencrypted. We explored this possibility, and found that this approach leaks infor- mation about the ngerprint. As a matter of fact, the correlation of m k unencrypted elements (even when k is large) can still attribute the correct camera with low error rate. For m = 10000, Table 1 shows the error rates for different k that we experimentally obtained. Therefore, to avoid leaking information that could lead to privacy breaches, we decided to encrypt all elements of the ngerprint digest FD. The encrypted ngerprint digest E(FD) is then sent to the Third-Party Expert to perform the encrypted matching with the encrypted PRNU noise E(F ) of a query image. The details of this step are discussed in the next section. 6.3 Matching Fingerprint with the PRNU Noise The Third-Party Expert obtains the encrypted ngerprint digest E(FD) from the suspect s device and the encrypted PRNU noise E(F ) of a query image from the court. To perform the match, the Third-Party Expert rst obtains an encrypted PRNU digest E(F D) from the encrypted PRNU using the location information of the elements of the ngerprint digest. The encrypted ngerprint digest and the encrypted PRNU digest are then provided as an input to the Pearson correlation coef cient formula given in Equation 1. The Pearson correlation coef cient contains additions, scalar multiplications, one multiplication, a division, and a square root operation. The additions, scalar multiplications, and one multi- plication operation can be performed in the encrypted domain as the BGN encryption is homomorphic to these operations. Thus, using the encrypted ngerprint digest E(FD) and the encrypted PRNU noise digest E(F ), the Third-Party Expert computes in the encrypted domain the following components of the Pearson correlation coef cient: E(A) = m i=1  E(Fint i ) E(Fint)  E(Fint, i ) E(Fint, )  , E(B) = |m i=1  E(Fint i ) E(Fint) 2, and E(C) = m i=1  E(Fint, i ) E(Fint, ) 2, where E(Fint) and E(Fint, ) represent mean of E(Fint) and E(Fint, ) respectively. Then, the Third-Party Expert sends the encrypted components E(A), E(B), and E(C) to the Match Maker Server for further processing. The Match Maker Server performs the remaining operations of the Pearson correlation coef cient in plaintext form. To this end, (1) the Match Maker Server obtains A, B, and C by decrypting E(A), E(B), and E(C); (2) converts back A, B, and C to their IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING 7 oat values (by dividing 10d); and (3) computes the correlation coef cient r (FD,F D) as r (FD,F D) = A BC . As last step of the process, the Match Maker obtains the correla- tion coef cient from the Match Maker Server, and compares the coef cient with a threshold to determine if the query image was taken by the suspect s camera. Note that since our scheme operates in integer domain and we consider ngerprint digest, it could be the case that our scheme might introduce some error when compared to conventional cam- era attribution method that considers full ngerprint and operates in oating point domain. However, the effect of ngerprint digest in camera attribution has been well studied in earlier work [36]. In the following section, we will therefore only study the effect of rounding error introduced by e-PRNU. 6.4 Rounding Error Analysis Without loss of generality, let us assume that both an element of the ngerprint digest, i.e., Fi, and an element of the PRNU digest, i.e., F i , are rounded off by d decimal places. Suppose the error in rounding the element of the ngerprint and rounding the element of the PRNU are denoted as Fi and F i respectively. Then, we can write Fr i = Fi+ Fi and Fr, i = F i + F i , where Fr i and Fr, i are round- off values of Fi and F i , respectively. The ngerprint and PRNU are assumed to be Gaussian with zero mean and unit variance. Thus, the rounding errors can also be assumed to be Gaussian with zero mean and unit variance. Using Equation 1, we can get the error in correlation coef - cient r as r = n i=1( FiFr, i + F i Fr i + Fi F i ) p n i=1(Fr i )2 q n i=1(Fr, i )2 . (2) Due to the property of Pearson correlation coef cient, we know that r = n i=1 Fr i Fr, i p n i=1(Fr i )2 q n i=1(Fr, i )2 is bounded by 1. We also know that both Fi and F i satisfy 0.5 10 d Fi 0.5 10 d and 0.5 10 d F i 0.5 10 d, respectively. In average case, | Fi| < Fr i 103 d and | Fr, i | < F i 103 d, as very few elements in the ngerprint and the PRNU are less than 0.01 (based on experimental observation). By putting the average case values in Equation 2, we obtain | r| < 3r 103 d . TABLE 2: Change in error rates for different d when p = 0.0157. d 1 2 3 4 FAR 0.0313 0.0500 0.0563 0.0563 FRR 0.5000 0.1000 0.0500 0.0500 In other words, r can change the value of r maximum by | 3r 103 d |, i.e., r r + 3r 103 d . This change can affect the FAR and FRR rates of the correlation since r can be greater than (or less than) a threshold T while r is less than (or greater than) T. To decrease this error in the correlation, a higher d must be chosen such that the probability of wrongful attribution decreases (as r will be small enough to make an impact). A way to choose d can be d > 3 + p, where p represents the number of decimal places in T. The higher the value of d, the lower the error (as shown in Table 2 for a single camera). For minimal error in a practical scenario, the value of d can be xed to the machine precision. Note that xing the value of d to machine precision of a normal PC (where a oat is typically represented by a 4-byte or 8-byte number) will not increase the computation cost and data overhead since the number has to be represented as a big number (e.g., a 32-byte number) after the encryption. Note that rounding errors are not affected by encryption and decryption as both encryption and decryption are lossless operations. 7 CONSTRUCTION DETAILS e-PRNU leverages the BGN scheme proposed by Boneh, Goh and Nissim in [8]. The BGN scheme is somewhat homomorphic in a sense that it allows an arbitrary number of additions and a single multiplication operation. The proposed scheme consists of the following algorithms. KeyGen(1k). The KMA runs the key generation algorithm in order to generate the public key PK and the secret key SK. It takes as input a security parameter k and generates two prime numbers q1 and q2. It computes n = q1q2. It picks two random generators g,u R G of order n. It computes h = uq2, which is a random generator of the subgroup of G of order q1. It outputs GT. It de nes a bilinear map: e : G G GT, which has the properties of bilinearity, computability and non-degeneracy [39]. The public key is PK = (n,G,GT,e,g,h). The secret key is SK = q1. Enc(PK,m). To encrypt a message m (where m < q2) using PK, the user runs the encryption algorithm. It picks a random r R Zn. It computes C = gmhr G. It outputs C. Dec(SK,C). To decrypt a ciphertext C using SK, the user runs the decryption algorithm. It computes Cq1 = (gq1)m. Let g = gq1. Let C =Cq1. To recover m, it takes the discrete log of C base g, i.e., m = log g C. Add(PK,C1,C2). To add two ciphertexts C1 = gm1hr1 and C2 = gm2hr2, the server runs the addition algorithm. It picks a random r R Zn. It calculates hr. It computes C as follows. C = C1 C2 hr = gm1hr1 gm2hr2 hr = gm1+m2hr1+r2+r Note that hr is optional. More speci cally, hr is used for re-randomization. Avoiding blinding with hr will make the homomorphic computation deterministic. Mul(PK,C1,C2). To multiply two ciphertexts C1 = gm1hr1 and C2 = gm2hr2, the server runs the multiplication al- gorithm. It computes g1 = e(g,g), which is of order n. Next, it computes h1 = e(g,h), which is of order q1. It picks a random r R Zn. It calculates h1r. Recall that IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING 8 h = uq2, which can also be re-written as h = g q2 for some (unknown) Z. It computes C as follows. C = e(C1,C2) h1r = e(gm1hr1,gm2hr2) h1r = e(gm1,gm2) e(gm1,hr2) e(hr1,gm2) e(hr1,hr2) h1r = e(g,g)m1m2 e(g,h)m1r2 e(h,g)r1m2 e(h,h)r1r2 h1r = g1m1m2 h1m1r2 e(g q2,g)r1m2 e(g q2,h)r1r2 h1r = g1m1m2 h1m1r2 e(g,g q2)r1m2 e(g,h) q2r1r2 h1r = g1m1m2 h1m1r2 e(g,h)r1m2 h1 q2r1r2 h1r = g1m1m2 h1m1r2 h1r1m2 h1 q2r1r2 h1r = g1m1m2 h1m1r2+r1m2+ q2r1r2+r = g1m1m2 h1 r where r = m1r2 + r1m2 + q2r1r2 + r is distributed uni- formly in Z. Thus, C denotes the encryption of m1m2 mod n, but in GT rather than G. Clearly, the system is still additively homomorphic in GT. Note that hr is op- tional. More speci cally, hr is used for re-randomization. Avoiding blinding with hr will make the homomorphic computation deterministic. 8 SECURITY ANALYSIS In this section, we present the security analysis of e-PRNU. Since e-PRNU is based on the BGN scheme, our security analysis is also based on similar settings as in [8]. In general, a scheme is considered secure if no adversary can break the scheme with prob- ability signi cantly greater than random guessing. The adversary s advantage in breaking the scheme should be a negligible function (de ned below) of the security parameter. De nition 1 (Negligible Function). A function f is negligible if for each polynomial p(.), there exists K such that for all integers k > K it holds that: f(k) < 1 p(k) We consider a realistic adversary that is computationally bounded and show that our scheme is secure against such an adversary. We model the adversary as a randomized algorithm that runs in polynomial time and show that the success probability of any such adversary is negligible. An algorithm that is randomized and runs in polynomial time is called a Probabilistic Polynomial Time (PPT) algorithm. The scheme relies on the existence of a pseudorandom func- tion f. Intuitively, the output of a pseudorandom function cannot be distinguished by a realistic adversary from that of a truly random function. Formally, a pseudorandom function is de ned as: De nition 2 (Pseudorandom Function). A function f : {0,1} {0,1} {0,1} is pseudorandom if for all PPT adversaries A , there exists a negligible function negl such that: |Pr[A fs( ) = 1] Pr[A F( ) = 1]| < negl(k) where s {0,1}k is chosen uniformly randomly and F is a function chosen uniformly randomly from the set of function mapping n-bit string to n-bit string. Our proof relies on two assumptions. The rst assumption is that the Discrete Log (DL) problem is hard in G, i.e., given g and g , it is hard for an adversary to compute . The second assumption is that the integer factorization of a large composite number is hard, i.e., given n, it is hard compute (non-trivial) q1 and q2 such that n = q1 q2. Without knowing the factorization of the group order n, it is hard to decide whether x is in a subgroup of G . This problem is known as the subgroup decision problem and we formally de ne it as follows. De nition 3 (Subgroup Decision Problem). Let G and GT are groups of order n = q1q2, where q1 and q2 are primes. Let g be a generator of G and e : G G GT be the bilinear map. Let x is an element of G , i.e., x G . For an algorithm A , the advantage of A in solving the subgroup decision problem is de ned as: SD Adv(A ,G) = |Pr[A (n,G ,GT,e,x) = 1] Pr[A (n,G ,GT,e,xq2) = 1]| < negl(k) We say that G satis es the subgroup decision problem if for all PPT adversaries A , SD Adv(A ,G) < negl(k). Now, we can prove security of the BGN scheme. Theorem 1. If the subgroup decision problem is hard relative to G, the BGN scheme is semantically secure. Proof (Sketch). Let us assume that the BGN scheme is not semantically secure and there exists a PPT B that can break the BGN scheme in negl(k). We assume there exists an adversary A that breaks the subgroup decision assumption with the same advantage. Given (n,G ,GT,e,x), A works as follows: A chooses a random generator g G and gives the public key (n,G ,GT,e,x) to B. B outputs two messages m0 and m1 to which A responds with C = gmbhr G for a random b R {0,1} and r R Zn. B outputs b {0,1}. If b = b , A outputs 1 (meaning x is uniform in a subgroup of G ); otherwise, A outputs 0 (meaning x is uniform in G ). As we know that x is uniform in G , the challenge ciphertext C is uniformly distributed in G . Thus, Pr[b = b ] = 1/2 On the other hand, if x is uniform in the (q1) subgroup of G , the public key (n,G ,GT,e,x) and the challenge ciphertext C given to B are the ones that are given in the real game. By de nition of B, we know that: Pr[b = b ] > 1/2+negl(k) A satis es SD Adv(A ,G) > negl(k). This implies that A breaks the subgroup decision problem with negl(k). Note that the proof is for G. Without loss of generality, it also holds for GT. For more details, an interested reader is referred to [8]. Also note that both homomorphic operations including ad- dition (i.e., Add) and multiplication (i.e., Mul) functions are pseudorandom due to blinding with hr. hr makes both homomor- phic operations semantically secure. If we remove it, then both homomorphic operations will not be semantically secure. Theorem 2. If the BGN scheme is semantically secure, e-PRNU is also semantically secure. Proof (Sketch). In our solution, recall that we represent the camera ngerprint and the PRNU noise of the query image using two IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING 9 integer vectors (the conversion from a oating point number to an integer has been explained in Section 6.2), F = {F1,F2,...,Fn} and F = {F 1,F 2,...,F n} respectively, where each vector is of length n. In our solution, we perform matching of the camera ngerprint with the PRNU noise of the query image. Since this matching should be performed without revealing the data, all the elements in each vector are encrypted using the BGN scheme. This matching is based on the correlation coef cient explained in Section 6.3, requiring addition and multiplication operations. Technically, the respective elements (i.e., Fi and F i , where 1 i n) in both vectors are added and multiplied in an encrypted manner. As we use semantically secure addition and multiplication operations, the resultant elements after running the correlation are also semantically secure. Thus, the correlation vector consisting of the resultant elements is also semantically secure. 9 RESULTS AND ANALYSIS In this section, we discuss the experimental results of e-PRNU. The experiments were performed by executing the Third-Party Expert, Match Maker Server, and the Match Maker in our Lab s infrastructure. We simulated the TrustZone using Open-TEE 2, a virtual, hardware-independent software-based TrustZone, that was in- stalled on a PC powered by Intel Core i5-3570 Quad-Core 3.4 GHz processor and 8 GB RAM. Our version of Open-TEE runs on Ubuntu 16.04 LTS operating system. In Open-TEE, we implemented the ngerprint and ngerprint encryption modules using C++ language. Our ngerprint module was based on the wavelet lter, which was discussed in Section 2. In this module, we also computed the ngerprint digest by considering 10000 highest elements of the ngerprint. In our ngerprint encryption module, we rst converted the oating point numbers in the ngerprint digest to integers by rounding off the oats by two decimal places, and then encrypted the integers using BGN encryption. Our implementation of BGN encryption had a key length of 1024 bits. The Third-Party Expert was executed in a cluster of 64 nodes, to recreate a large deployment on a cloud environment. Each node was powered by Intel Xeon E5-2680 8 Core 2.7GHz processor and 128G RAM, and was running Red Hat Enterprise Linux 6.3 OS. The nodes were connected using QDR In niband (40Gb/s). We used MPI (Message Passing Interface) message passing system to maintain communication among the nodes. The Third-Party Expert was implemented using C++ language. Note that for lower computation cost, we used a variant of Pearson correlation coef cient3 in our implementation. We executed the Match Maker Server and the Match Maker on a single node that is powered by Intel Xeon E5-2680 8 Core 2.7GHz processor and 128G RAM. As we have clari ed before, the Match Maker does two jobs: computation and encryption of the PRNU noise of the query image. On the other hand, the Match Maker Server decrypts the partially-computed Pearson correlation coef cient, completes the computation of the Pearson correlation 2https://github.com/Open-TEE 3http://www.stat.wmich.edu/s216/book/node122.html coef cient, and matches the Pearson correlation coef cient with a threshold. The computation of the PRNU noise and the encryption of PRNU computed noise were implemented in C++ language on Ubuntu 16.04 LTS platform. The PRNU noise was computed using a wavelet lter-based method discussed in Section 2, and the PRNU noise was also encrypted using BGN encryption. The de- cryption of the partially-computed Pearson correlation coef cient, and the remaining computation of the decrypted Pearson correla- tion coef cient were also implemented using C++ language. TABLE 3: List of cameras used in our experimentation. Name No. Name No. HUAWEI H30 0 Casio EX-Z150 5 iPadMini 1 Kodak M1063 6 Bobi LD700 2 Nikon CoolPix S710 7 SONY C6903 3 Olympus Mju 1050SW 8 Samsung Galaxy S4 4 Samsung L74 9 Our test environment consisted of 10 cameras of 10 different brands as shown in Table 3. From each camera, we took 10 images for calculating the ngerprint and 40 query images for the correlation. The chosen images had not gone through geometric processing, such as scaling, cropping, and rotation. The generated Pearson correlation coef cient was matched against a threshold that was set per each camera. Fig. 4: ROC curve: e-PRNU with digest vs conventional scheme with digest. Fig. 5: ROC curve: e-PRNU without digest vs conventional scheme without digest. IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING 10 To study the practicality of e-PRNU, we compared e-PRNU with the plaintext domain camera attribution that was implemented using the above setup. In the plaintext domain scheme, we com- puted ngerprint in Open-TEE and computed Pearson correlation coef cient in the cluster of nodes (i.e., Third-Part Expert). Since the ngerprint and PRNU noise were not encrypted ( oating point numbers were also not rounded off), the Pearson correlation coef cient was fully computed by the Third-Part Expert without any involvement of the Match Maker Server. The Match Maker computed the PRNU noise of the query image, and compared the Pearson correlation coef cient with the threshold. (in red) with the ROC curve of the plaintext-based conven- tional scheme (in blue). Fig. 4 shows the comparison of ROC curve of e-PRNU (in red) with the ROC curve of the plaintext-based conventional scheme (in blue) when ngerprint digest was used. These curves were obtained by averaging the error rates experimentally obtained from 10 different cameras. As can be seen in the graph, e-PRNU has comparable error rates with respect to the conventional scheme. This means that even if we round off values to perform the encryption, the lack of precision does not affect too much the validity of the results obtained with e-PRNU. Fig. 5 shows the ROC curve of e-PRNU (in pink) and the conventional scheme (in green) when ngerprint digest was not used. As expected, the error rates when a digest was used is more than the error rates without a digest. Performance Analysis. In this section, we analyze the com- putational and storage overheads incurred by e-PRNU. Clearly, because our scheme uses encryption it introduces more overhead when compared to a plaintext scheme. Our goal here is to study and quantify such overhead. In e-PRNU, the encryption of an element of the ngerprint or the encryption of an element of the PRNU noise involves one round-off operation, three exponential operations, and two multiplication operations. The encryption of the ngerprint is a one-time operation. This operation therefore can be performed of ine. The encryption of the PRNU noise, however, needs to be performed by the Match Maker at runtime. The addition, scalar multiplication, and multiplication of the encrypted values need to be implemented using addition, multiplication, and exponentia- tion. Thus, in comparison to the conventional scheme, the Third- Party Expert needs more computation cost to partially compute the Pearson correlation coef cient. The partially-computed Pearson correlation coef cient needs to be decrypted by the Match Maker Server. This process requires 12 exponential operations, three discrete log operations, and one division operation. Note that the operation at the Third-Party Expert-end and Match Maker Server- end need to be performed at runtime. Similar to the computational cost, e-PRNU also increases the data overhead. Each oating point number is represented as a b-bit integer, where b is the number of bits in encryption key. Typically, b = 1024 and the oat is represented as 32 bits. Thus, the data overhead in storing encrypted ngerprint and sending encrypted ngerprint to the Third-Party Expert is increased by 32 times. Similarly, the data overhead in sending encrypted PRNU is also increased by 32 times. In addition to the above analysis, we also experimentally studied the computation cost of e-PRNU and the conventional plaintext scheme. In our experiment, extra computation cost at the TrustZone is negligible. Therefore, we do not report it. The TABLE 4: Computation cost of e-PRNU and conventional scheme at the Third-Party Expert-end. Scheme Time Conventional scheme 0.54 ms e-PRNU (#1 node) 404.17 s e-PRNU (#4 nodes) 102.58 s e-PRNU (#16 nodes) 26.60 s e-PRNU (#64 nodes) 10.26 s signi cant computation overhead at the Third-Party Expert-end, however, is reported in Table 4 for a different number of nodes in the cluster. As expected, the computation cost decreases with the increase in the number of nodes used by the Third-Party Expert. The rate of decrease however is not strictly proportional to the rate of increase as the communication cost increases when the number of nodes increases. In our experiment, the computation cost at the Match Maker Server-end and Match Maker-end are 23.05s and 42.73s, respectively. 10 CONCLUSIONS AND FUTURE DIRECTIONS PRNU-based camera attribution is a widely used technique to identify the source camera of an anonymous questionable image. In this technique, a ngerprint of the camera is rst computed from the PRNU noise of a set of images taken by the camera. Then this ngerprint is correlated with the PRNU noise of the query image to determine if the camera has taken the image. Although the PRNU-based method is very useful for digital forensics, privacy is one of the main concerns. Using this method, an adversary can unlawfully link a camera with an anonymous image, or vice versa. As a result, unethical linking of individuals to sensi- tive/anonymous information can occur. For example, anonymous social network accounts can be linked to known accounts if images of both the accounts belong to the same camera. In this article, we address this privacy concern by encrypting both the ngerprint and the noise, and performing the correlation in the encrypted domain. The PRNU noise and the camera ngerprint are computed in unencrypted form, but in a trusted environment (e.g., in the ARM TrustZone). e-PRNU is such that the camera attribution can be performed by authorized users, who hold decryption keys. Experiment and analysis showed that e-PRNU incurs reasonable overhead. As future work, the performance overhead of the proposed ap- proach can be further improved by investigating various schemes. For example, it will be worth to study if a cluster of Graphical Processing Units (GPUs) can be used. Also, if other optimization schemes, such as random projection-based compression, a hybrid of ngerprint digest and binarization, can be used. Furthermore, the proposed approach can be made more general by using the Peak-to-Correlation Energy (PCE) instead of Pearson correlation co-ef cient. Although the PCE is based on the Pearson correlation co-ef cient, a universal threshold for all the cameras (unlike per- camera threshold) can be obtained using PCE. This universal threshold will not only make the proposed approach more general but also decrease the computation cost by eliminating the need for per-camera threshold computation. ACKNOWLEDGEMENTS This research is supported by STRATUS (Security Technologies Returning Accountability, Trust and User-Centric Services in the IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING 11 Cloud), a project funded by the Ministry of Business, Innovation and Employment (MBIE), New Zealand. REFERENCES [1] M. Mohanty, M. Zhang, M. R. Asghar, and G. Russello, PANDORA: Preserving privacy in PRNU-based source camera attribution, in 2018 17th IEEE International Conference On Trust, Security And Privacy In Computing And Communications/ 12th IEEE International Conference On Big Data Science And Engineering (TrustCom/BigDataSE), New York, USA, Aug 2018, pp. 1202 1207. [2] J. Luk a s, J. Fridrich, and M. Goljan, Digital camera identi cation from sensor pattern noise, IEEE Transactions on Information Forensics and Security, vol. 1, no. 2, pp. 205 214, 2006. [3] A. E. Dirik, H. T. Sencar, and N. Memon, Digital single lens re ex camera identi cation from traces of sensor dust, IEEE Transactions on Information Forensics and Security, vol. 3, no. 3, pp. 539 552, 2008. [4] S. Bayram, H. T. Sencar, and N. Memon, Seam-carving based anonymization against image & video source attribution, in IEEE International Workshop on Multimedia Signal Processing, 2013, pp. 272 277. [5] A. E. Dirik, H. T. Sencar, and N. Memon, Analysis of seam-carving- based anonymization of images against PRNU noise pattern-based source attribution, IEEE Transactions on Information Forensics and Security, vol. 9, no. 12, pp. 2277 2290, 2014. [6] F. Bertini, R. Sharma, A. Iann` , and D. Montesi, Smartphone veri cation and user pro les linking across social networks by camera ngerprinting. Springer International Publishing, 2015, pp. 176 186. [7] A. Karak uc uk, A. E. Dirik, H. T. Sencar, and N. Memon, Recent advances in counter PRNU based source attribution and beyond, IS&T Electronic Imaging Media Watermarking, Security, and Forensics, vol. 9409, April 2015. [8] D. Boneh, E.-J. Goh, and K. Nissim, Evaluating 2-DNF formulas on ciphertexts, in Proceedings of the Second International Conference on Theory of Cryptography, 2005, pp. 325 341. [9] H. T. Sencar and N. Memon, Digital image forensics: There is more to a picture than meets the eye. New York, USA: Springer, 2013. [10] S. Bayram, H. T. Sencar, and N. Memon, Ef cient techniques for sensor ngerprint matching in large image and video databases, pp. 754 109 754 109, 2010. [11] Y. Sutcu, S. Bayram, H. T. Sencar, and N. Memon, Improvements on sensor noise based source camera identi cation, in International Conference on Multimedia and Expo, 2007, pp. 24 27. [12] C. T. Li and Y. Li, Color-decoupled photo response non-uniformity for digital image forensics, IEEE Transactions on Circuits and Systems for Video Technology, vol. 22, no. 2, pp. 260 271, 2012. [13] G. Chierchia, S. Parrilli, G. Poggi, C. Sansone, and L. Verdoliva, On the in uence of denoising in PRNU based forgery detection, in ACM Workshop on Multimedia in Forensics, Security and Intelligence, 2010, pp. 117 122. [14] C. T. Li, Source camera identi cation using enhanced sensor pattern noise, IEEE Transactions on Information Forensics and Security, vol. 5, no. 2, pp. 280 287, 2010. [15] R. Caldelli, I. Amerini, F. Picchioni, and M. Innocenti, Fast image clustering of unknown source images, in IEEE International Workshop on Information Forensics and Security, 2010, pp. 1 5. [16] J. Luk a s, J. Fridrich, and M. Goljan, Detecting digital image forgeries using sensor pattern noise, in Electronic Imaging 2006. International Society for Optics and Photonics, 2006, pp. 60 720Y 60 720Y. [17] G. Chierchia, G. Poggi, C. Sansone, and L. Verdoliva, A Bayesian-MRF approach for PRNU-based image forgery detection, IEEE Transactions on Information Forensics and Security, vol. 9, no. 4, pp. 554 567, 2014. [18] T. Gloe, M. Kirchner, A. Winkler, and R. B ohme, Can we trust digital image forensics? in ACM International Conference on Multimedia, 2007, pp. 78 86. [19] A. Karak uc uk and A. E. Dirik, Adaptive photo-response non-uniformity noise removal against image source attribution, Digital Investigation, vol. 12, no. C, pp. 66 76, 2015. [20] A. E. Dirik and A. Karak uc uk, Forensic use of photo response non- uniformity of imaging sensors and a counter method, Optics Express, vol. 22, no. 1, pp. 470 482, January 2014. [21] R. B ohme and M. Kirchner, Counter-forensics: Attacking image foren- sics, in Digital Forensics, H. T. Sencar and N. Memon, Eds. Springer- Verlag, 2013, pp. 327 366. [22] J. Entrieri and M. Kirchner, Patch-based desynchronization of digital camera sensor ngerprints, in IS&T Electronic Imaging Media Water- marking, Security, and Forensics, 2016. [23] M. Goljan and J. Fridrich, Sensor ngerprint digests for fast camera identi cation from geometrically distorted images, in SPIE Media Watermarking, Security, and Forensics, 2013. [24] , Camera identi cation from cropped and scaled images, in Elec- tronic Imaging 2008. International Society for Optics and Photonics, 2008, pp. 68 190E 68 190E. [25] K. Rosenfeld, T. Sencar, and N. Memon, A study of the robustness of PRNU-based camera identi cation, in SPIE Conference on Media Forensics and Security, 2010, pp. 90 93. [26] M. Goljan, J. Fridrich, and M. Chen, Sensor noise camera identi cation: Countering counter-forensics, in IS&T/SPIE Electronic Imaging. Inter- national Society for Optics and Photonics, 2010, pp. 75 410S 75 410S. [27] S. Taspinar, M. Mohanty, and N. Memon, PRNU based source attri- bution with a collection of seam-carved images, in IEEE International Conference on Image Processing, Phonix, USA, 2016. [28] D. Valsesia, G. Coluccia, T. Bianchi, and E. Magli, User authentication via PRNU-based physical unclonable functions, IEEE Transactions on Information Forensics and Security, vol. 12, no. 8, pp. 1941 1956, 2017. [29] T. Bianchi, V. Bioglio, and E. Magli, Analysis of one-time random pro- jections for privacy preserving compressed sensing, IEEE Transactions on Information Forensics and Security, vol. 11, no. 2, pp. 313 327, 2016. [30] M. Mohanty, P. K. Atrey, and W. T. Ooi, Secure cloud-based medical data visualization, in ACM Multimedia, Nara, Japan, 2012, pp. 1105 1108. [31] M. Mohanty, W. T. Ooi, and P. K. Atrey, Scale me, crop me, know me not: supporting scaling and cropping in secret image sharing, in IEEE International Conference on Multimedia and Expo, San Jose, USA, 2013. [32] , Secure cloud-based volume ray-casting, in IEEE IEEE Interna- tional Conference on Cloud Computing Technology and Science, Bristol, UK, 2013. [33] M. Mohanty, M. R. Asghar, and G. Russello, 2DCrypt: Image scaling and cropping in encrypted domains, IEEE Transactions on Information Forensics and Security, no. 99, pp. 1 14, 2016. [34] H. Farid, Image forgery detection, IEEE Signal Processing Magazine, vol. 26, no. 2, pp. 16 25, 2009. [35] M. Goljan, J. Fridrich, and M. Chen, Defending against ngerprint- copy attack in sensor-based camera identi cation, IEEE Transactions on Information Forensics and Security, vol. 6, no. 1, pp. 227 236, 2011. [36] M. Goljan, J. Fridrich, and T. Filler, Managing a large database of camera ngerprints, in IS&T/SPIE Electronic Imaging. International Society for Optics and Photonics, 2010, pp. 754 108 754 108. [37] D. Valsesia, G. Coluccia, T. Bianchi, and E. Magli, Compressed nger- print matching and camera identi cation via random projections, IEEE Transactions on Information Forensics and Security, vol. 10, no. 7, pp. 1472 1485, 2015. [38] D. Valsesia and E. Magli, Binary adaptive embeddings from order statistics of random projections, IEEE Signal Processing Letters, vol. 24, no. 1, pp. 111 115, 2017. [39] D. Boneh and M. Franklin, Identity-based encryption from the weil pairing, in Advances in Cryptology - CRYPTO 2001, ser. Lecture Notes in Computer Science, J. Kilian, Ed. Springer Berlin Heidelberg, 2001, vol. 2139, pp. 213 229. Manoranjan Mohanty is Lecturer in Digital Se- curity in the School of Computer Science at The University of Auckland in New Zealand. Previ- ously, he was a Post-Doctoral Researcher in Center for Cyber Security, New York University Abu Dhabi, UAE, and SICS Swedish ICT, Swe- den. He received B.Sc. in Computer Science from Ravenshaw College, Cuttack, Odisha, In- dia, Master of Computer Applications from Jawa- harlal Nehru University, New Delhi, India, and Ph.D. in Computer Science from School of Com- puting, National University of Singapore, Singapore. His research inter- ests include cyber security, digital forensics, and privacy. IEEE TRANSACTIONS ON DEPENDABLE AND SECURE COMPUTING 12 Ming Zhang has been a Scienti c Program- mer in the School of Computer Science at The University of Auckland in New Zealand. He re- ceived his Ph.D. degree in Image Processing and Pattern Recognition from Shanghai Jiaotong University, China, and his M.Sc degree as well as B.Sc. degree from Huazhong University of Science and Technology, China. His research interests include applied cryptography, security, and privacy. Muhammad Rizwan Asghar is a Senior Lec- turer in the School of Computer Science at The University of Auckland in New Zealand, where he is a Founding Member of Cyber Security Foundry (CSF) and Co-founder and Co-director of the SECRET Lab. Previously, he was a Post- Doctoral Researcher at international research institutes including the Center for IT-Security, Privacy, and Accountability (CISPA) at Saar- land University in Germany and CREATE-NET in Trento Italy. He received his Ph.D. degree from the University of Trento, Italy in 2013. As part of his Ph.D. programme, he was a Visiting Fellow at the Stanford Research Institute (SRI), California, USA. He obtained his M.Sc. degree in Information Security Technology from the Eindhoven University of Technology (TU/e), The Netherlands in 2009. His research interests include access control, cyber security, privacy, and consent management. Giovanni Russello is an Associate Professor in the School of Computer Science at the Uni- versity of Auckland, New Zealand. He is also the Founding Director of the Cyber Security Foundry, the rst New Zealand multi-disciplinary centre in Cyber Security. He received his M.Sc. (summa cum laude) degree in Computer Sci- ence from the University of Catania, Italy in 2000, and his Ph.D. degree from the Eindhoven University of Technology (TU/e) in 2006. After obtaining his Ph.D. degree, he moved to the Policy Group in the Department of Computing at Imperial College Lon- don, UK. His research interests include policy-based security systems, privacy and con dentiality in cloud computing, smartphone security, and applied cryptography. He has published more than 60 research articles in these research areas and has two granted US Patents in smartphone security.