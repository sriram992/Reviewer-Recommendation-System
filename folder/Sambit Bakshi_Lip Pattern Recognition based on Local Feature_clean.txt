Lip Pattern Recognition based on Local Feature Extraction Sambit Bakshi , Rahul Raman and Pankaj K Sa sambitbaksi@gmail.com rahulraman2@gmail.com pankajksa@gmail.com Department of Computer Science and Engineering National Institute of Technology Rourkela Odisha - 769 008, India Abstract Lip is claimed to be a unique organ in human body and hence a candidate for being a biometric. The uniqueness of lip has been proven by the researchers by using color information and shape analysis. These measures of lip are unique for every person. This paper proposes that grayscale lip images constitute local features. The claim has been experimentally established by extracting local features from 23 grayscale lip images from 10 di erent subjects and measuring the accuracy of match. There are two techniques applied for extraction and matching of local features from lip, viz. SIFT and SURF. The accuracy turns out to be very high (>90%) in both the experiments conducted. I. Introduction Lip is the tactile sensory organ constituting the visible portion of the mouth. The external-most skin of the lip is strati ed squamous epithelium. The lip skin has visible wrinkles that are identi able and unique for each human. For this very reason, lip image or latent lip print is a candidate to be a biometric trait [1]. Moreover lip patterns have temporal stability [2] and can be captured in non-invasive manner. The importance of lip print recognition comes into play in forensics as well. The science of gender classi cation on the basis of lip print analysis is termed as cheiloscopy [3]. There has been signi cant analysis of recognition through lip shape and lip color [4]. This paper approaches to extract the local features from grayscale lip image applying Scale Invariant Feature Transform (SIFT) [5] and Speeded up Robust Features (SURF) [6]. Both the approaches e ciently detect and match the local features of two images of same lip even when the size of two images are di erent or the lip images are having rotation due to tilt of subject s face. The experimental results establish the existence of unique local features in lip prints. II. Lip Segmentation The objective of lip segmentation is to obtain accurate inner and outer lip borders. The authors in [7] have devised a novel approach for lip segmentation by exploiting the color information from video of a speaker. First a logarithmic color transform is performed from RGB to HI color space. Second a statistical approach of Markov random eld modeling is deployed to determine the red hue prevailing region and motion in spatiotemporal neighborhood [7]. Subsequently authors in [8] have proposed spatial fuzzy clustering algorithm for lip segmentation. The distribution of data in feature space and the spatial interactions between neighboring pixels during clustering are taken into consideration for this implementation. However, the quality of frames obtained from video are inferior to a captured still image. In the proposed research, lip images are captured by Cannon PowerShot A1100IS camera in constrained illumination avoiding re ection of surrounding light on the lip. Acquired images are accurately segmented by human experts. To test the recognition performance through lip prints, segmented images are fetched to the local feature extraction and matching technique. III. Lip Feature Extraction Methodologies There are researches carried out in the direction of extracting feature from lip image by shape analysis, color analysis. However lip shape can be deliberately changed by a subject to a large extent with the change of expression. Furthermore the color of lip is subject to acquisition conditions. Hence analysis and recognition of an individual by lip-shape and lip-color analysis can only work ne in a constrained scenario. However the local feature points of a lip image can be exploited as they are invariant to illumination, rotation, scaling and other a ne transforms. Section III-A and Section III-B discusses review of work by the researchers in this direction and Section III-C describes the proposed scheme of applying SIFT and SURF to lip image for identi cation. A. Lips Shape Feature Extraction Researchers in [9], [10] have proposed central, Zernike and Hu moments to describe geometrical parameters of human lip. Moreover standard geometrical parameters viz. Malinowska ratio, Feret ration, Blair-Bliss ratio, Danielsson ratio, Haralick ratio, Lp1 ratio and Lp2 ratio are also used for analysis of lip shape. However author in [4] has proposed 9 additional novel parameters for lips biometrics as follows: 1) Lips width to perimeter ratio 2) Upper to lower lips height ratio 3) Upper lip height to width ratio 4) Lower lip height to width ratio 5) Inner to outer circle ratio 6) Width to middle height ratio 7) Left side upper to lower lip convexity ratio 8) Right side upper to lower lip convexity ratio 9) Indent ratio B. Lips Color Feature Extraction Author in [4] has used statistical color features in three di erent color spaces viz. RGB, HSV and YUV. Each channels of the color space is explored separately for feature extraction; however for monochromatic images, MONO channels are used. Color feature vector consists of features like maximum and minimum density of pixels having the most common intensity present in the image, mean and variance of pixel coordinates, and slantity [4]. C. Proposed Feature Extraction Through SIFT and SURF Scale Invariant Feature Transform (SIFT) [5] is a method to detect local keypoints in a scene which are signi cantly important and can represent the scene. The technique has three steps: keypoint detection by Di erence of Gaussian (DoG) method, 128 dimensional keypoint descriptor computation by analysing orientation histogram, keypoint matching between two scenes by nearest neighbor method. The lip images are rich in features. The features are extracted using SIFT and matched with the features extracted from another lip image. If number of keypoints matched is above a threshold, the lip images are concluded to be from the same subject. Speeded up Robust Features (SURF) [6] is a method developed subsequently after SIFT. SURF detects the keypoints by using Hessian matrix. 64 dimensional descriptors are computed from the keypoints using Haar wavelet approach. The features of one image to that of another image are matched by nearest neighbor method. SURF takes less time than SIFT for computation due to its low dimensionality of features. These techniques are applied in the proposed experiment to prove the existence of unique local features in lip images. IV. Experimental Results The experiments of extracting local feature from a gallery lip image and to match it with local features of probe lip image have been carried out in this proposed research. To serve the purpose, 23 images captured from 10 subjects are matched with each other to generate 23 2  = 253 test-combinations. Out of these, 30 test cases represent matching between two lip images from the same subject. Rest 223 test cases represent matching between two lip images from di erent subjects. In this research, two experiments are carried out for testing the feasibility to recognise an individual through lip print. The rst experiment uses Scale Invariant Feature Transform (SIFT) [5] which uses Di erence of Gaussian (DoG) for keypoint detection. In the second experiment, Speeded up Robust Features (SURF) [6] is applied where keypoint detection is performed by Hessian matrix. Performance measures such as False Acceptance Rate (FAR) and False Rejection Rate (FRR) are calculated to quantify the e ciency of the system. Accuracy (ACC) percentage is measured as: ACC = 100 FAR + FRR 2 (1) The d index [11] is also calculated which signi es the separability between the genuine and imposter scores. The higher the value of d , higher the separability. The value of d is measured as: d = 2 | genuine imposter|  2 genuine + 2 imposter (2) (a) No. of matches: 17 (b) No. of matches: 16 (c) No. of matches: 14 Fig. 1. Some example of SIFT matching on lip prints of two di erent subjects (a) No. of matches: 196 (b) No. of matches: 127 (c) No. of matches: 119 Fig. 2. Some example of SIFT matching on two lip prints of same subject 0 20 40 60 80 100 120 140 160 180 200 220 50 60 70 80 90 100 Threshold Accuracy (in %) SIFT SURF (a) Accuracy Curve 0 10 20 30 40 50 60 70 80 90 100 5 0 5 10 15 20 25 30 35 40 False Acceptance Rate (FAR) False Rejection Rate (FRR) SIFT SURF (b) ROC Curve 10 1 10 2 0 5 10 15 20 Matching Score by SIFT Score Distribution Imposters Genuine (c) Separation between imposter and genuine by SIFT 10 1 10 2 0 5 10 15 20 Matching Score by SURF Score Distribution Imposters Genuine (d) Separation between imposter and genuine by SURF Fig. 3. Accuracy Results A. Experiment 1: Applying SIFT Fig. 1 depicts few examples where lip images from two di erent subjects are matched. Likewise Fig. 2 depicts few examples where lip images from same subject are matched. Each red line between two lip-images represents a match. The starting and end points of a match denote the two similar (having same local feature) locations detected in two images respectively. It is evident from the examples that the number of matches found in Fig. 1 are less in number compared to number of matches in Fig. 2. Also it is observable that there exists some matches in Fig. 1 which are unfeasible, because, the location of start point of the match and the location of end point of the match are not from same regions of lip-images. For example, there may exist a spurious match between left-upper region of gallery lip image and right-lower region of probe image. Table I lists the accuracy percentage along with the FAR and FRR and d index for both the experiments with SIFT and SURF. The accuracy obtained by applying SIFT is 93.9980% with FAR and FRR values as 0.8929% and 11.1111% respectively. The FAR value is very low, signifying the security of the recognition system. B. Experiment 2: Applying SURF Similar observations are made when SURF is applied to match two lip images. The accuracy attained by SURF is 94.0972% with FAR and FRR values as 6.25% and 5.5556% respectively as texted in Table I. The value of d index for SURF turns out to be 2.7004 which is less than the value obtained for SIFT (2.9654). Fig. 3(a), Fig. 3(b) shows the accuracy obtained at di erent thresholds and the Receiver Operating Characteristic (ROC) curve respectively. Fig. 3(c) and Fig. 3(d) depicts the imposter-genuine score separation plots indicating the FAR and FRR values at highest accuracy. TABLE I Performance measures of SIFT and SURF feature matching approaches Approach FAR FRR ACC d SIFT 0.8929 11.1111 93.9980 2.9654 SURF 6.2500 5.5556 94.0972 2.7004 V. Conclusion and Future Works The experiments are carried out from images taken with a camera that is used for the regular use. And the color features of a lip are not explored in the proposed research. Still the recognition system exploits the grayscale local features of a lip images and e ciently matches it with local features of another lip image. If the color properties of a lip image is explored for recognition along with local features, the accuracy values would increase further. The results obtained by applying SIFT and SURF are substantial enough to experimentally establish the existence of unique local features in lip images through which an individual can be recognised. The future works in this research direction await database indexing of lip images exploiting color features of a lip image and to minimise the penetration ratio of the gallery database as well as increasing the accuracy while identifying an individual. Acknowledgment The authors of this paper would like to convey their sincere gratitude to all the co-researchers at Image Processing Laboratory of National Institute of Technology Rourkela for their active and hidden cooperation towards manifesting this research. References [1] Y. Tsuchihashi, Studies on personal identi cation by means of lip prints, Forensic Science, vol. 3, pp. 233 248, Jun 1974. [2] R. C. Coward, The stability of lip pattern characteristics over time, J Forensic Odontostomatol, vol. 25, no. 2, pp. 40 56, 2007. [Online]. Available: http://www.biomedsearch.com/nih/ stability-lip-pattern-characteristics-over/18183687.html [3] J. Kasprzak, Possibilities of cheiloscopy, Forensic Science International, vol. 45, pp. 145 151, 2000. [4] M. Choras, The lip as a biometric, Pattern Anal. Appl., vol. 13, pp. 105 112, January 2010. [Online]. Available: http://dx.doi.org/10.1007/ s10044-008-0144-8 [5] D. G. Lowe, Distinctive image features from scale-invariant keypoints, Int. J. Comput. Vision, vol. 60, pp. 91 110, Nov 2004. [Online]. Available: http://portal.acm.org/citation.cfm?id=993451.996342 [6] H. Bay, T. Tuytelaars, and L. Van Gool, SURF: Speeded up robust features, vol. 3951, pp. 404 417. [7] M. Lievin and F. Luthon, Lip features automatic extraction, in Image Processing, 1998. ICIP 98. Proceedings. 1998 International Conference on, vol. 3, Oct 1998, pp. 168 172. [8] A.-C. Liew, S. H. Leung, and W. H. Lau, Segmentation of color lip images by spatial fuzzy clustering, Fuzzy Systems, IEEE Transactions on, vol. 11, no. 4, pp. 542 549, aug. 2003. [9] C.-H. Teh and R. Chin, On image analysis by the methods of moments, Pattern Analysis and Machine Intelligence, IEEE Transactions on, vol. 10, no. 4, pp. 496 513, jul 1988. [10] A. Khotanzad and Y. Hong, Invariant image recognition by zernike moments, Pattern Analysis and Machine Intelligence, IEEE Transactions on, vol. 12, no. 5, pp. 489 497, may 1990. [11] A. K. Jain, P. Flynn, and A. A. Ross, Handbook of Biometrics. Secaucus, NJ, USA: Springer-Verlag New York, Inc., 2007.