See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/268237325 Performance of students across assessment methods and courses using Correlation analysis Conference Paper December 2013 DOI: 10.1109/MITE.2013.6756359 CITATIONS 5 READS 157 2 authors, including: Some of the authors of this publication are also working on these related projects: Drug Discovery and Development View project Summarization View project Aruna Malapati BITS Pilani, Hyderabad 43 PUBLICATIONS 508 CITATIONS SEE PROFILE All content following this page was uploaded by Aruna Malapati on 06 May 2015. The user has requested enhancement of the downloaded file. Performance of students across assessment methods and courses using Correlation analysis Aruna Malapati, N.L.Bhanu Murthy Assistant Professor, Department of Computer Science and Information Systems Birla Institute of Technology and Sciences, Pilani Hyderabad Campus Hyderabad, India arunam@hyderabad.bits-pilani.ac.in bhanu@hyderabad.bits-pilani.ac.in Abstract Professional education aims to provide students with requisite knowledge and skills to face today s competitive environment. To achieve this currently practices like systematically assessing student learning and measuring learning outcomes are presently in place. The primary goal achieved by this process is the continued improvement of academic quality for the institution. This paper investigates the application of correlation analysis for finding relationships between skills acquired is one test with the other components like assignments, individual marks with the final result and the correlation of performances of students across courses. The results obtained for the first study indicates that there exists moderately strong relationship. The second study shows that correlation coefficients of related courses are better while that of some unrelated courses have moderate value. This means that in case of related courses the skills acquired in a prerequisite course can help them to do better in the current course. This exploratory analysis when properly interpreted can help plan and retrospect and readjust the mode of assessment or course delivery to enhance student learning. Keywords Education Assessments, Evaluation, Correlation analysis, student performanc. I. INTRODUCTION Students tend to realise, in all countries and economies, that academic achievement is a determinant of success in higher education and form their expectations accordingly. However, students do not know their actual underlying skills and performance level. While they know what problems they can solve and how much effort they need to invest to learn new material, they lack a standardised metric to compare themselves with others and infer their likelihood to attend and succeed at university. Or do they? Do students use marks to form their opinions about their future[1]? Marks are a consistent, accessible and easy-to-interpret source of information about students own achievement, habits and attitudes. Research has highlighted that marks are significantly related to long-term student outcomes, such as university completion and earnings, inasmuch as they convey information about students non-cognitive skills, after accounting for test scores. Yet the fact that a relationship between marks and long-term outcomes exists does not necessarily mean that students will use the information marks convey when forming their expectations. In fact, employers tend to dismiss marks as subjective and consider them to be unlikely to provide much relevant information about workers prospects[2]. Little is known about whether students use marks as a relevant source of information when they form their educational and career expectations, even though in recent years some have suggested that marks be included as a key component in the analysis of student expectations[3][4][5] . In the United States, for example, students from their expectations early on in their lives and only adapt them to only large changes in their grade point averages [6]. Marks are an important source of information on which students may rely to evaluate their success in school and their potential in higher education. Yet, not all teachers assign marks using the same criteria. While some assign marks on the basis of absolute knowledge, attitudes and behaviours, others tend to reward students relative position within the class or the school and attitudes and behaviours that have less bearing on students future success. Hence, while marks represent a readily available source of information, at times they can be unreliable predictors of students potential success at university and beyond. This is particularly true when marks reflect students relative position within the school (as observed when teachers and schools use normative grading practices) rather than their absolute level of performance and likelihood of succeeding in their educational careers.[1] After accounting for performance in reading and mathematics as well as the ISCED programme a student attends (sources of standardised and structural information related to success in obtaining a university degree), students with higher marks are more likely to expect to complete a university degree. Beyond any standardised measure of performance and structural paths that enable access to and success in university, students still rely on their marks to form their expectations. Marks are positively related to the expectation of completing a university degree in all countries and economies that distributed the ECQ: students who receive higher marks have higher expectations. [1] Assessment and evaluation are essential components of teaching and learning in higher education. Every course has been designed and offered to students with some predefined learning objectives. Large class sizes, limited time and several other constraints dictate use of traditional testing formats in many universities. Hence the instructors switch to multiple choice questions or short answers which provide a little opportunity for the students to express their knowledge and problem solving skills. In many of the universities offering engineering programs typically the course instructor plans to have several assessment techniques like quizzes, projects, seminar, written exam etc to have a holistic view of students learning process. This also provides students flexibility to perform and express their skills acquired in a better way. When two variables covary, there exists a relationship between them. The Correlation coefficient measures the strength and direction of linear association between two variables. In this paper we evaluate the performance of the students in two courses using the correlation analysis. We evaluate the correlation between their performances in previous courses verses the existing course. The correlation value indicates weather that the current course is in pace with the other courses. A negative value gives us an indication that the there is a serious problem in the existing course. This could be due to the consequence of the level of difficulty in the questions , teachers evaluation methodology or students understanding on the topics tested. A proper introspection on these indicators by the instructors can help them to take proactive measures like correct the course structure, depth at which topics are covered, revision of the module etc. The rest of the paper is organized as follows: section II describes the related work in this area and section III gives fundamental theory of correlation. Section IV descries the methodology and the insights into the experiment and finally conclusion in section V. II. RELATED WORK Several studies have recently begun in the area of educational data mining. Some of the studies have used machine learning techniques to predict the students outcome in a course given their previous performance. In this section we have summarized three case studies that are related to this paper where correlation analysis has been used. Moldabayev at el s work show cases the experiences of the School of Engineering, Nazarbayev University relationship between attendance and overall academic performance of students. An analysis of data from the first year of the School of Engineering at Nazarbayev University has indicated a strong positive correlation between overall semester GPA and overall student attendance. The correlation coefficient relating attendance and semester GPA was 0.454 for the first semester and 0.403 for the second semester. Interestingly, this correlation (attendance and semester GPA) indicated a stronger correlation for male students as compared to female students in semester 1 (0.584 to 0.460) but the opposite effect in semester 2 (0.317 to 0.507). The correlation between final mark and attendance was course dependent, ranging from - 0.048 (Fluid Mechanics) to 0.597 (Introduction to Civil Engineering).[7] Adeeb at el main objective of the research was to find out the correlation between the marks obtained by the students of Allama Iqbal Open University in assignments and final examination of M.A (Education) M.Ed in autumn 2006. The value of correlation in the subject, Elementary Education was 0.228, in Secondary Education -0.033, in Higher Education was 0.069 and in Teacher Education in Pakistan was 0.154.There were 16 students who got more than 80 marks in assignments but they were fail in the final examination because they did not get at least 40 marks in the final examination.[8] The main goal of Z iga-Vicente at el is to carry out a comparative analysis of the relative importance of the so- called generic skills within several degrees offered by most public and private Spanish universities. Following the guidelines of the Tuning Project, they have differentiated among three types of generic skills, namely: a) instrumental skills; b) interpersonal skills; and c) systemic skills. On the other hand, the comparative analysis was performed on several degrees that are representative of five main areas of knowledge: 1) Legal and Social Sciences (i.e. Economics and Business Degree, Law Degree and Tourism Degree); 2) Health Sciences (i.e. Medicine Degree, Nursing Degree and Physiotherapy Degree); 3) Engineering (i.e. Industrial Engineering Degree and Architecture Degree); 4) Sciences (i.e. Chemistry Degree, Computing Degree and Mathematics Degree); and 5) Liberal Arts (i.e. Language and Literature Degree, History Degree and Teaching Degree)[9]. III. FUNDERMENTAL THEORY Correlation analysis is one of the most widely used and reported statistical methods in summarizing scientific research data. It is popular in many applications because it is a quantitative way to evaluate whether two or more variables are related or not. Thus, correlation analysis allows reducing the information contained in n observations that have been measured on pairs or groups of data to a single number falling into a normed interval. It is then convenient to proceed with the derived correlation coe cients for interpreting the relations [4]. It is often useful to determine if a relationship exists between two different variables. If so, how significant or how strong is this association between the two variables? For example, is there a relationship between the years of service as a sonographer and scores achieved on the registry examination? The correlation coefficient or r coefficient is a statistic used to measure the degree or strength of this type of relationship [10]. Given the two samples X and Y of n measurements, the sample correlation coefficient can be computed using the formula: (1) where the standard deviation Sx and sample mean x of the sample X are computed as: The values for Sy and y are calculated in the same fashion. The sign of r (+ or -) indicates the direction of the relationship between X and Y. The magnitude of r (how far away from zero it is) indicates the strength of the relationship. r ~1: Very strong positive linear relationship between X and Y. Y increases as X increases. r~0: No linear relationship between X and Y. Y does not tend to increase or decrease as X increases. r~-1: Very strong negative linear relationship between X and Y. Y decreases as X increases. Table I summarizes the strength of linear relationship with the Correlation Coefficient value. TABLE I STRENGTH OF LINEAR RELATIONSHIP Correlation Coefficient value Strength of linear relationship At least 0.8 Very strong 0.6 up to 0.8 Moderately strong 0.3 to 0.5 Fair Less than 0.3 Poor IV. CORRELATION ANALYSIS METHODOLOGY The marks were synthesized for 10 courses in various assessments a sample of which is shown in Table II. TABLE-II DATA SET COLLECTED FOR A SPECIF COURSE Idno Test Quiz Seminar project Assignment xx01 50 36 28 27.5 46.5 xx02 45 23 14 23 48 xx03 24.5 14.5 20 18 24.5 xx04 30 13 28 26 17 xx05 44.5 30.5 22 23.5 42 xx06 35 28.5 27 27.5 24 xx07 18.5 9.5 19 11.5 9.5 xx08 39.5 25 27 26 25.5 xx09 55.5 47 58 24 67.5 xx10 44 41.5 51 24 68.5 . . . . . . xx120 42.5 30.5 35 15 38 The following are the studies done: 1. Examine the correlation between the performance in written test and the other components. To investigate this we have analyzed the relationship between written exam and a coding assignment. We have investigated the relationship between the written test with a coding assignment for all the 10 courses and the correlation is ranging between 0.477056 and 0.48652122 which indicates that the there exist a fair relationship between them. A sample relationship is shown for one such course in Figure1. Figure 1: Relationship between the compnents considered. 2. Examine the correlation between the performances in written test in a course with that of the other course. Here we have analyzed the relationship that exists between two similar components in different courses. A sample compariosion between two written tests is shown in Figure2. The results of this study have demonstrated surprising results. Initially we randomly selected two courses and in this process we discovered that for some set courses the value was less than 0.3 and for some it revealed greater than 0.6. A careful investigation revealed that the values depend on the contents in the course. For example a course in Mathematics can be related to operational research. Henceforth our experimental results reveal that the related courses have moderately strong relationships ranging between 0.66753 - 0.69456 while the courses that no common content has shown poor relationship. Further we can also exploit the relationships to the topic levels difficulty of questions etc. A detailed investigation into these can give better insights into student s performance. Figure 2: Relationship between the compnents considered. V. CONCLUSIONS There are relatively few applications of multivariate statistics in the area of education data mining at present. This paper brings forth preliminary results in this direction. Two experiments we conducted in the first study an attempt is made to explore correlations that exist between written exam and coding assignment which revealed that there exist fair correlation between them. A future work could also try to investigate the type of relationships between all types of assessment methods for the course and we could plan to have those components that show better relationships. The second study our observation shows that for 4 courses we have been able to identify a poor correlation. Our future work in this direction is to analyze the reasons for these at topic level, content delivered verses questions distribution over the topics etc. We would also find the possibly of application of regression analysis between all the courses to predict the result of a student. REFERENCES [1] http://www.oecd.org/edu/school/Grade%20Expectations.pdf [2] Rosenbaum, J. (2001), Beyond College for All: Career Paths for the Forgotten Half, Russell Sage Foundation, New York, New York. [3] Buchmann, C. and B. Dalton (2002), Interpersonal Influences and Educational Aspirations in 12 Countries: The Importance of Institutional Context , Sociology of Education, Vol. 75, No. 2, pp. 99-122. [4] Buchmann, C. and H. Park (2009), Stratification and the Formation of Expectations in Highly Differentiated Educational Systems , Research in Social Stratification and Mobility, Vol. 27, No. 4, pp. 245-267. [5] McDaniel, A. (2010), Cross-National Gender Gaps in Educational Expectations: The Influence of National-Level Gender Ideology and Educational Systems , Comparative Education Review, Vol. 54, No. 1, pp. 27-50. [6] Andrew, M. and R. Hauser (2012), Adoption? Adaptation? Evaluating the Formation of Educational Expectations , Social Forces, Vol. 90, No. 2, pp. 497-520. [7] Moldabayev, D.; Menicucci, J.A.; Al-Zubaidy, S.; Abdulaziz, N., "Attendance, performance and culture Experience of the School of Engineering, Nazarbayev University - An update," Global Engineering Education Conference (EDUCON), 2013 IEEE , vol., no., pp.5,10, 13-15 March 2013 doi: 10.1109/EduCon.2013.6530079 [8] Adeeb, M. A., Gujjar, A. A., & Malik, M. A. Correlation between marks obtained by students in assignments and final examination of master of education conducted by Alam Iqbal Open University. Turkish Online Journal of Distance Education 8, 120-126,2007. [9] J.A. Z iga-Vicente, A. Blanco Gonz lez, C. Prado Rom n (2011) HOW SIMILAR OR DIFFERENT ARE THE GENERIC SKILLS AMONG DIFFERENT AREAS OF KNOWLEDGE? A COMPARATIVE ANALYSIS IN THE SPANISH HIGHER EDUCATION, EDULEARN11 Proceedings, pp. 3945-3954. [10] Tryon, R. C. The interpretation of the correlation coefficient. Psychological Review, Vol 36(5), 419-445, 1929. doi: 10.1037/h0074981 View publication stats