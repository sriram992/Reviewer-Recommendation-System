IEEE TRANSACTIONS ON CYBERNETICS 1 Consistencies and Contradictions of Performance Metrics in Multiobjective Optimization Siwei Jiang, Yew-Soon Ong, Jie Zhang, Liang Feng Abstract An important consideration of Multiobjective Op- timization (MOO) is the quantitative metrics used for de ning the optimality of different solution sets, which is also the basic principle for the design and evaluation of MOO algorithms. Although a plethora of performance metrics have been proposed in the MOO context, there has been a lack of insights on the relationships between metrics. In this paper, we rst group the major MOO metrics proposed to date according to four core performance criteria considered in the literature, namely Ca- pacity, Convergence, Diversity, and Convergence Diversity. Then, a comprehensive study is conducted to investigate the relation- ships among representative group metrics, including Generational Distance (GD), -indicator (I1 +), Spread ( ), Generalized Spread ( ), Inverted Generational Distance (IGD) and Hypervolume (HV). Experimental results indicated that these six metrics show high consistencies when Pareto fronts (PFs) are convex, whereas they show certain contradictions on concave PFs. Index Terms Multiobjective Optimization, Performance Met- rics, Capacity, Convergence, Diversity, Hypervolume, jMetal I. INTRODUCTION Multiobjective Optimization Problems (MOPs) involve sev- eral con icting objectives to be optimized simultaneously [1 5]. A plethora of approaches, such as Multiobjective Evolu- tionary Algorithms (MOEAs), have been well established as ef cient methods to deal with MOPs that are now prevalent in the elds of engineering, nance, logistic, etc [1 40]. To evaluate different approaches, it is critical to design ap- propriate performance metrics in various context. For instance, the goal of Single-objective Optimization Problems (SOPs) is to nd an optimal solution with regards to minimization or maximization. It is relatively easy in SOPs to compare two solutions and regard the one with a better tness as superior. In MOPs, however, evaluating solution superiority is much more complex due to the presence of con icting objectives. Various approaches often obtain an optimal solution set comprising a number of solutions that fair equivalently according to Pareto dominance concept [1 19]. However, it is often non-trivial to provide a quantitative comparison of different optimal solution sets in Multiobjective Optimization (MOO) [1 5]. To date, a number of quantitative metrics have been pro- posed in MOO for de ning solution set optimality and the assessment of MOEAs [4 6, 41 45]. Each metric is designed with a standpoint that takes one or more performance cri- Siwei Jiang, Yew-Soon Ong, Jie Zhang, Liang Feng are with the School of Computer Engineering, Nanyang Technological University, Singapore 639798 (e-mail: {sjiang1, asysong, zhangj, feng0039}@ntu.edu.sg). Manuscript received August 20, 2013; Revised January 2, 2014; Accepted February 11, 2014 teria into considerations. The typical performance criteria1 include the capacity of the non-dominated solutions set, the convergence of solutions to true Pareto fronts (PFs), the diversity of solutions in the objective space, the dominated volume of solutions with respect to the reference sets, etc. For instance, Van Veldhuizen et al. [41] designed metrics to tally the number of non-dominated solutions. The Generational Distance (GD) metric [6, 42] is introduced to measure the proximity of solutions to the true PFs. Zhou et al. [43] de ned the Generalized Spread ( ) metric to measure the diversity of solutions on high dimensional MOPs. Zitzler et al. [44, 45], on the other hand, established the popular Hypervolume (HV) metric to calculate the dominated volume of the optimal solution sets, with respect to the reference sets. With the plethora of performance metrics that have been proposed in the last decade, research efforts devoted to surveys on MOO metrics have also emerged alongside [46 51]. For instance, Okabe et al. [46] in their survey categorized MOO metrics in terms of cardinality, distance, volume, distribution and spread. Zitzler et al. [47] classi ed the MOO metrics using a mathematical framework. After analysing the classical MOO metrics, Tan et al. [48] proposed the Uniform Distribution (UD) as a parameter dependent metric. Wu et al. [51], on the other hand, summarized six variants of metrics associated with HV, and studied them on a bi-objective engineering MOP. It is worth noting that several notable surveys, experimental studies and analyses made on MOO metrics [46 51] have been limited to a focus on individual metric. Little or no work on establishing the relationships among MOO metrics have been explicitly considered to date. This paper thus makes an attempt to ll in this gap. In particular, we begin with a categorization of existing MOO metrics into four groups according to the core performance criteria typically used in the literature, namely Capacity, Convergence, Diversity, and Convergence Diversity. With the categorization, we are then able to systematically study the relationships among representative group metrics on the symmetric and continuous PFs. More speci cally, we investigate six representative metrics, including Generational Distance (GD), -indicator (I1 +), Spread ( ), Generalized Spread ( ), Inverted Generational Distance (IGD) and Hy- pervolume (HV). Experimental studies indicated that all the six metrics show high consistencies when the Pareto Fronts (PFs) are convex. Surprisingly, contradictions among metrics are found on concave PFs, even on metrics of the same group that cater to a common performance criterion. 1Performance criteria in MOO: the particular standard of the true quality of optimal solution sets, i.e., capacity, convergence, diversity. IEEE TRANSACTIONS ON CYBERNETICS 2 In summary, the contributions of this paper are listed: 1) A classi cation of MOO metrics according to the per- formance criteria, including Capacity, Convergence, Di- versity, and Convergence Diversity, is presented. 2) The inadequacies of some MOO metrics in omitting par- tial information on the true quality of optimal solution sets are illustrated. 3) The relationships of six representative metrics are an- alyzed based on experimental studies. Speci cally, two metrics, I1 + and IGD, are consistent with HV on convex PFs, whereas, certain contradictions to HV are uncov- ered on concave PFs. 4) Last but not least, the presented results will serve as a guide on the appropriate use of MOO metrics. The rest of the paper is organized as follows. Section II gives a brief background on MOO. In Section III, we survey various MOO metrics and categorize them into four groups. Then, the inadequacies of some MOO metrics are highlighted in Section IV. In Section V, experimental results on the re- lationships among representative group metrics are presented. The conclusions and future works are then given in Section VI. II. BACKGROUND Without loss of generality, Multiobjective Optimization Problem (MOP) for minimization can be stated as [1 5]: min F( x) = (f1( x), . . . , fm( x)) s.t. G( x) 0, H( x) = 0, x , (1) where x = (x1, . . . , xD), is the variable space, Rm is the objective space, and F : Rm consists of m real-valued objective functions with constraints G( x) 0 and H( x) = 0, the feasible solution space is = D i=1[Li, Ui], and Li, Ui are the lower and upper bound of xi, respectively. Let u = (u1, , um), v = (v1, , vm) be two vectors. Here, three Pareto dominance concepts are de ned as follows: 1) u is said to weakly dominate v, notated as u v iff i : ui vi; 2) u dominates v, notated as u v iff i : ui vi and i : ui < vi; and 3) u strongly dominates v, notated as u v iff i : ui < vi. Other important de nitions of MOPs are outlined: Pareto Set. All solution vectors in the variable space that non-dominates each other form the Pareto Set (PS), and notated as PS = { x | y : F( y) F( x)}. Pareto front. The Pareto front (PF) lies in the objective space, and has relation to PS such that PF = {F( x)| x PS}. In general, it is impossible to nd all solutions on the contin- uous PFs. Hence, a nite number of non-dominated solutions that approximates the true PFs is termed as P. Optimal Solution Set. The optimal solution set obtained by the optimizers (e.g., MOEAs) is termed as S. Reference Set. The reference set is designed with prede- ned solutions, and is de ned as R. Good (Utopian) Point and Bad Point. A Good Point is termed as PG = (f G 1 , , f G m), where x PS : PG F( x). A Bad Point is de ned as PB = (f B 1 , , f B m), x PS : PB F( x). To evaluate the quality of set S, three major performance criteria have been considered in MOO: 1) the number of non- dominated solutions in S, 2) the convergence of S to the true PFs, and 3) the diversity of S in the objective space [1 5, 52]. In particular, an optimal solution set with large number of non- dominated solutions, approaching the true PFs and scattering evenly are generally desirable. III. PERFORMANCE METRICS IN MOO In the design of MOO metrics, three major performance criteria, namely capacity, convergence and diversity, have typ- ically been taken into considerations. Based on these criteria, we categorize the MOO metrics into four core groups: Capacity metrics: This group metrics tally the number or ratio of non-dominated solutions in S that satis es given prede ned requirements. Convergence metrics: These are metrics for measuring the proximity of optimal solution set S to PF (P). Diversity metrics: These metrics include two forms of information: 1) Distribution measures how evenly scat- tered are the solutions of S in the objective space, and 2) Spread indicates how well do the solutions of S arrive at the extrema of true PFs. Convergence Diversity metrics: They indicate both the convergence and diversity of S on a single scale. A. Capacity Metrics Capacity metrics quantify the number or ratio of non- dominated solutions in S that conforms to the prede ned requirements. In general, a large number of non-dominated solutions in S is preferred. In [41], the Overall Non-dominated Vector Generation (ON- VG) metric is introduced as: ONVG(S) = |S|. (2) This gives the number of the non-dominated solutions in the optimal solution set (S). Hereafter | | de nes the cardinality or number of elements in the set, unless explicitly indicated. The Overall Non-dominated Vector Generation Ratio (ON- VGR) [41], which gives the capacity ratio of the optimal solution set (S) with respect to the PF (P), is given as: ONVGR(S, P) = |S| |P|. (3) Several metrics have also been designed by considering the search stages. For instance, [41] de ned three metrics: 1) Generational Non-dominated Vector Generation GNVG(S) = |S(t)|, 2) Generational Non-dominated Vector Generation Ratio GNVGR(S, P) = |S(t)| |P | , and 3) Non-dominated Vector Additional NVA(S, t) = GNVG(S, t) GNVG(S, t 1), where t is the generation index. Thus, they measure the capacity of S or the changes in capacity along the MOO search. While the above ve metrics are associated with the size of set S, the Error Ratio (ER) in [53], on the other hand, considered the solution intersections between S and PF (P). It takes the form of: ER(S, P) = 1 |S P| |P| , (4) IEEE TRANSACTIONS ON CYBERNETICS 3 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 f1 f2 Pareto front Optimal solution set (S) (a) Good distribution, poor spread 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 f1 f2 Pareto front Optimal solution set (S) (b) Poor distribution, good spread Fig. 1. Two components (distribution and spread) in diversity metrics. where S P denotes the solutions existing in both S and P. By replacing P with reference set R, the Ratio of the Reference Points Found in [54, 55] is proposed as C1R = |S R| |R| . As mentioned in Section II, set P consists of a nite number of non-dominated solutions that approximate the true PFs. Hence, it is often infeasible to arrive at the exact same solutions (usually comprising of real values in the objective space) in both S and P. For this reason, the metric Non- dominated Points by Reference Set (C2R) [55], which adopts the Pareto dominance concept, is introduced as follows: C2R(S, R) = |{ s S| r R : r s}| |S| . (5) In other words, Eq. 5 estimates how many solutions of S are non-dominated by reference set R. In contrast to the eight capacity metrics presented, which only elicit information from one optimal solution set, the Coverage of Two Sets (or Metric C) in [44, 45] concentrates on the overlaps between two optimal solution sets. C(S1, S2) = |{ s2 S2| s1 S1 : s1 s2}| |S2| . (6) Note that this metric is independent of PF (P) or reference set (R). Based on pairwise comparisons between solutions, the computational complexity of C1R and C2R is O(m|S| |R|), and that of C(S1, S2) is O(m|S1| |S2|). B. Convergence Metrics Convergence metrics measure the degree of proximity based on the distance between the solutions in S to those in PF (P). The Generational Distance (GD) metric [6, 42] is among those commonly used in MOEAs, and has the formulation as: GD(S, P) = ( |S| i=1 dq i )1/q |S| , (7) where di = min p P ||F( si) F( p)||, si S and q = 2. Thus, di is the smallest distance from s S to the closest solution in P. Hereafter || || denotes the Euclidean distance unless explicitly indicated. Two similar metrics have been proposed as index [52] and M 1 [56] with q = 1. Among the convergence metrics, Zitzler et al. introduced the commonly used metric -indicator [47] as follows: I1 +(S, P) = inf R { p P| s S : s p + }, (8) and s p is an alternative formulation of s p+ . In these two metrics, thus de nes the value required to translate/scale the optimal solution set S such that S dominates P. The metric Seven Points Average Distance (SPAD) in [57], on the other hand, considers the solution distance between S and reference set R. The formulation of SPAD is de ned as: SPAD(S, R) = |R| i=1 di |R| , (9) where di = min s S ||F( ri) F( s)||, ri R. The seven points in R are generated as: (0, 1 3f max 2 ), (0, 2 3f max 2 ), (0, f max 2 ), (0, 0), ( 1 3f max 1 , 0), ( 2 3f max 1 , 0), (f max 1 , 0), where f max 1 and f max 2 denote the maximum values of objective 1 and objective 2, respectively. Thus, SPAD only applies to 2-dimensional PFs. Another constraint of SPAD is that the solutions of R are strictly linearly distributed, irregardless of the shapes of PFs. Based on the analysis of the above metrics, the time com- plexity of GD, index, M 1 and -indicator is O(m|S| |P|), and that of SPAD is O(m|S|). C. Diversity Metrics Diversity metrics indicate the distribution and spread of solutions in the optimal solution set S. To illustrate the difference between distribution and spread, Fig. 1 showcases two representative examples. Particularly, the 5 non-dominated solutions of S in Fig. 1(a) possess good distribution but poor spread, since S does not contain the extreme points (0, 1), (1, 0) of the 2-dimensional PF. On the other hand, Fig. 1(b) illustrates the example of an optimal solution set with good spread but unfavorable distribution. 1) Distribution in diversity metrics: Distribution is derived from the discrepancy of pairwise solutions in set S. In [52], Deb et al. proposed a metric that compares all the solutions consecutive distances with the average distance: (S) = |S| 1 i=1 (di d) |S| 1 , (10) where di is the Euclidean distance between consecutive solu- tions in S, and d is the average of di. If all the pair of consec- utive solutions share equal distance, then di = d, (S) = 0, and S has a perfect distribution. To nd consecutive solutions, the prerequisite of this metric is to sort the solutions of S by lexicography order. Two similar metrics have also been introduced in [56, 57]. The M 3 metric [56] considers the maximum distance instead of the average distance in . In [57], the Spacing (SP) metric is designed as SP(S) = |S| i=1(di d)2/(|S| 1), where di = min sj S, sj = si ||F( si) F( sj)|| and si S. In contrast to the consecutive distance in , metric SP calculates the closest distance of pairwise solutions in S. In addition to the parameter-free metrics , M 3 and SP, the following two metrics are designed with user-speci ed parameters. The M2 metric in [56] is equipped with a niche radius and takes the form of: M 2 (S) = s1 S |{ s2 S| || s1 s2|| < }| |S| 1 . (11) IEEE TRANSACTIONS ON CYBERNETICS 4 For a solution s1 S, M 2 (S) measures how many solutions s2 S are located in its local vicinity || s1 s2|| < . In [48], Tan et al. proposed the parameter dependent metric Uniform Distribution (UD) as follows: UD(S) = 1 1 + Dnc , (12) where Dnc = si S(nc( si) nc( s))2/(|S| 1), nc( si) = |{ sj S| || si sj|| < }| 1, and ns( s) is the average of nc( si). The computational complexity of , M 3 , SP, M 2 and UD is derived as O(m|S|2). It is worth noting that the diversity metrics presented thus far are important indicators on the distribution property of S. They however do not capture the spread characteristics of S. As shown in Fig. 1(a), a perfect distribution of solutions in S is indicated on all 5 metrics , M 3 , SP, M 2 and UD. However, the spread property of S is low as it does not cover the PF completed (e.g., extreme points are left unexplored). 2) Spread in diversity metrics: Spread quanti es how much of the extreme regions are covered by set S. The Overall Pareto Spread (OS) in [51] is proposed as: OS(S, PG, PB) = m k=1 | max s S fk( s) min s S fk( s)| |fk(PB) fk(PG)| , (13) where max s S fk( s), min s S fk( s) are the maximum and minimum values of the kth objective in S, respectively. The metric OS has a computational complexity of O(m|S|). From metric OS, there exists a contradiction between distribution and spread. For instance, suppose PG = (0, 0), PB = (1, 1), the spread of solutions in Fig. 1(b) is superior to that of Fig. 1(a) under the OS metric, whereas solutions of Fig. 1(b) is inferior to those of Fig. 1(a) in terms of distribution. 3) Distribution and Spread in diversity metrics: The fol- lowing MOO metrics in this section consider the distribution and spread of optimal solution set S simultaneously. The metric , as introduced by Deb et al. [6], is commonly used in MOEAs. The formulation of is derived as follows: (S, P) = df + dl + |S| 1 i=1 |di d| df + dl + (|S| 1) d , (14) where di is the Euclidean distance between consecutive so- lutions and d is the average of di. The terms df and dl are the minimum Euclidean distances from solutions in S to the extreme (bounding) solutions of the PF (P). The consecutive sorting in metric makes it applicable to 2-dimensional PFs only. To cope with high dimensional MOPs, Zhou et al. [43] introduced the Generalized Spread ( ) as an extension of , which takes the form: (S, P) = m k=1 d( ek, S) + |S| i=1 |di d| m k=1 d( ek, S) + (|S|) d , (15) where d( ek, S) = min s S ||F( ek) F( s)|| and ek P is the extreme solutions on the kth objective. Another distance in is di = min sj S, sj = si ||F( si) F( sj)|| to identify the closest pairwise solutions in S, and d is the average of di. Fig. 2. The performance metric Hypervolume (HV) in MOO. From Eqs. 14-15, both and share a computational complexity of O(m|S|2 + m|S| |P|). In some special cases, metric may bring misleading information due to the closest distance calculations. In Fig. 1(b), the optimal solution set S comprises ve points: A(0, 1), B(0.02, 0.75), C(0.58, 0.06), D(0.75, 0.02), E(1, 0). Under the closest distance concept of metric , the distance values of AB, CD would be considered twice, whereas, BC is disregarded. In addition to those presented, other notable diversity met- rics have also been introduced in the MOO context [51, 58, 59]. Instead of describing all of them individually, we refer the readers to the existing literature [51, 58, 59] for the details. Nevertheless, the major ideas are summarized in what follows. The Entropy-based metric [58] measures the uniformity and coverage. It employs in uence functions to estimate the solution densities. The metric value is then calculated based on Shannon entropy in the discrete objective space. Metrics NDC and CL [51] divide the objective space into ( 1 )m grids ( [0, 1]). The metric value is evaulated based on the number of grids containing solutions. Metrics and [59] divide the objective space into equal angles based on a set of reference lines that emanate from the origin. The metric value is the number of reference lines that are suf ciently close to the solutions of S at a prede ned Euclidean distance. A potential constraint of the above ve metrics (i.e., entropy-based metric, NDC , CL and , ), nonetheless, is the sensitivity to the number of grids, subregions or angles in the objective space, which are de ned by the user-speci ed parameters |grids|, , , respectively. D. Convergence Diversity Metrics Convergence Diversity metrics measure the quality of the optimal solution set S in terms of convergence and diversity on a single scale. In [44, 45], Zitzler et al. proposed the popular performance metric Hypervolume (HV) as: HV(S, R) = volume( |S| i=1 vi). (16) IEEE TRANSACTIONS ON CYBERNETICS 5 TABLE I A CLASSIFICATION OF PERFORMANCE METRICS IN MULTIOBJECTIVE OPTIMIZATION (MOO). Performance criteria Performance metrics Parameter requirements Comparison set Computational compleixity Capacity ONVG, GNVG, NVA None None Low ONVGR, GNVGR, ER None Pareto front (P ) Low C1R , C2R None Reference set (R) O(m|S| |R|) Metric C None Optimal solution set (S) O(m|S1| |S2|) Convergence GD, -indicator, index, M 1 None Pareto front (P ) O(m|S| |P |) SPAD None Pareto front (R) O(m|S|) Diversity Distribution , M 3 , SP None None O(m|S|2) M 2 , UD Niche radius ( ) None O(m|S|2) Spread OS None Good, Bad points (PG, PB) O(m|S|) Distribution Spread , None Pareto front (P ) O(m|S|2 + m|S| |P |) Entropy, NDC , CL , , |grids|, , |lines| None High Convergence Diversity HV, HD, HR, Metric S, Metric D None Reference set (R) O(|S|m 1) IGD, q, MPFE None Pareto front (P ) O(m|S| |P |) This gives the volume (in the objective space) that is dom- inated by the optimal solution set S. Using the example in Fig. 2, where S = {A, B, C} is attained when minimizing a bi-objective MOP. The HV(S, R) is thus the area ABCWA enclosed by the discontinuous boundary, where reference set R = {W}2. Mathematically, for each solution si S, a hypercube vi is constructed with the reference set and the solution si as the diagonal corners of the hypercube. Hypervolume (HV) is a set quality measure that is strictly monotonic with regards to the Pareto dominance concept [60, 61]. It quanti es and encapsulates both the convergence and diversity information of S. In particular, the closer are the solutions of S to the true PFs, the larger is the value of HV. At the same time, a higher HV could also indicate solutions of S are scattered more evenly in the objective space. Other metrics adopting the similar concept have also been introduced in the MOO context, such as Hypervolume Dif- ference (HD) [51], Hypervolume Ratio (HR), Metric S [44], Coverage Difference of Two Sets or Metric D [62]. The downside of HV lies in the high computational com- plexity of O(|S|m 1), which can become intractable when the number of objectives is large (e.g., m 4). Although some research efforts have been devoted to reduce the computational burden, such as Monte Carlo sampling [60, 63], the accuracy of HV is however compromised. For the fast approaches on calculating the exact HV, the reader is referred to [61, 64 69]. The metric Inverted Generational Distance (IGD) in [9, 42, 47], which has a similar formulation to GD, is introduced as: IGD(P, S) = ( |P | i=1 dq i )1/q |P| , (17) where di = min s S ||F( pi) F( s)||, pi P, q = 2, and di is the smallest distance of p P to the closest solutions in S. The metric Averaged Hausdorff Distance ( q) [70], which combines the properties of GD and IGD, is de ned as: q(S, P) = max(GD(S, P), IGD(P, S)). (18) The parameter q in q is a positive integer. A larger q value penalizes the outlier solutions in S more. Both IGD and q share a computational complexity of O(m|S| |P|). 2Point W can be simply attained by constructing a vector of worst objective function values. Meanwhile, the number of solutions in R is not limit to one. Instead of measuring the average distance in IGD, the Maximum Pareto Front Error (MPFE) [57] is de ned as: MPFE(P, S) = max p P v u u tmin s S m k=1 |fk( s) fk( p)|2. (19) This metric nds the maximum distance from solutions in P to the closest solution in S. In contrast to HV and IGD, MPFE focuses on the extreme solutions rather than the entire solution set. In particular, when some outliers exist in S, MPFE is inclined to show the worst value of S and ignores the information of other high quality solutions. To summarize, Table I classi es the major MOO metrics proposed to date in terms of performance criteria, parameter requirements, comparison set and computational complexity. In what follows, we highlight and analyze the potential is- sues of some of these metrics in Section IV. The empirical investigation on the relationships among representative group metrics, with special focus on the consistencies or contradic- tions on PFs of diverse geometrical shapes, is then presented in Section V. IV. INSIGHTS ON EXTREME CASES OF MOO METRICS In this section, we highlight and analyse the inadequacies of MOO metrics. In particular, on extreme cases, some MOO metrics are noted to omit partial information that describes the true quality of the optimal solution set S. The Capacity metrics focus on tallying the number of solutions in the optimal solution set S. Hence, they are not designed to provide the convergence and diversity information of S. For instance, two optimal solution sets S1 and S2 of Fig. 3 are obtained by minimizing a bi-objective MOP. Notably, S2 is better than S1 in terms of convergence, since the solutions of S2 approach the origin (0, 0) closer than those of S1. However, under Metric C, both of them share a common value of C(S1, S2) = C(S2, S1) = 0.5. In MOO, capacity metric is generally used as the basic criterion for assessing the optimal solution sets [4, 5]. If two optimal solution sets obtain the same number of solutions, we can then compare the convergence and diversity information in a fair and detail manner. With regards to the convergence metrics, two critical issues can be asserted. First of all, most of them (e.g., GD and I1 +) IEEE TRANSACTIONS ON CYBERNETICS 6 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 f1 f2 Optimal solution set S1 Optimal solution set S2 Fig. 3. The inadequacy of Metric C, C(S1, S2) = C(S2, S1) = 0.5 [46]. require the PF (P) to be prede ned. In practice, however, it is almost impossible to know the true PFs, especially when no prior knowledge about the problem is available. On the other hand, even if the geometrical characteristics of PFs is known, constructing P for many objectives, discrete and asymmetric PFs, is non-trivial. Secondly, convergence metrics often omit the diversity property of S. Taking Fig. 1 as the illustration example, which comprises two optimal solution sets with perfect convergence (i.e., GD(S, P) = 0), but both display poor diversity. Among the diversity metrics, only a few of them (i.e., and ) are designed with comparison sets, e.g., PF (P) or reference set R. In addition, and only consider the extreme solutions of PF (P), e.g., df and dl in Eq. 14. Hence, a large number of solutions in P are not used in the comparison with solutions in S. In Fig. 4, the solutions in S are scattered evenly along the linear dash line, and (S, P) = (S, P) = 0. This means that S has a perfect diversity. However, they do not assert whether the solutions had converged to the true PFs. On the other hand, the convergence diversity metrics mea- sure two types of information on a single scale. As mentioned in Section III-D, the high computational complexity makes it cumbersome to apply HV in MOO. In addition, the potential limitation of the other three metrics (i.e., IGD, q and MPFE) lies in the need to construct the comparison sets. In HV, the comparison set is the reference set R. As shown in Fig. 2, R can be constructed with ease using single point W. However, the comparison set for IGD, q and MPFE is P, which is the set of representative solutions on PF. For instance, a popular method [4, 5] is to divide the objectives evenly and sample a large number of solutions on the true PF to form P. In Fig. 4, set P of 10, 000 points can be obtained by dividing f1 [0, 1] into 10, 000 segments equally. However, this results in unevenly distributed solutions, where nearly 5,000 points are crowded in (f1 [0.5, 1], f2 [0, 0.1]) when the PF is convex. Thus, this method is insuf cient to approximate the true PFs. For these metrics, i.e., IGD, q and MPFE, where the reliance on set P is high, the ability to construct well scattered solutions of P is crucial for assessing the true quality of set S. 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 f1 f2 Pareto front Optimal solution set (S) Fig. 4. The inadequacy of and , (S, P) = (S, P) = 0. Convergence Diversity Hypervolume (HV), Inverted Generational Distance (IGD) Generational Distance (GD) Epsilon ( ) Generalized Spread ( *) Spread ( ) Fig. 5. Relationships of GD, I1 +, , , IGD and HV as introduced in [4]. V. EMPIRICAL STUDIES AND ANALYSES With the categorization of MOO metrics based on the performance criteria, namely capacity, convergence, diversity, convergence diversity, in this section, a systematic investiga- tion on the relationships among metrics is presented. After constructing various Pareto fronts (PFs) and reference sets, six representative metrics are investigated on two optimal solution sets. In the experiments, we used hypervolume (HV) [4, 5, 16, 60], which is the most widely accepted metric in the MOO community, as the baseline to study the relationships among metrics on different geometrical shapes of PFs. Two representative metrics from each of the following categories are considered in the study3: Convergence metrics: GD, I1 +; Diversity metrics: , ; Convergence Diversity metrics: IGD, HV. In general, an optimal solution set with small GD, I1 +, , , IGD and large HV is desirable. In the literature [4, 5], the relationships of six metrics were intuitively and brie y discussed (As shown in Fig. 5). In this paper, we not only validate the relationships, but also provide the details on the potential consistencies and contradictions among the six metrics when the PFs are convex and concave. 3Since capacity metrics only provide cardinality information, it does not serve as meaningful when used alone to assess the optimal solution set. IEEE TRANSACTIONS ON CYBERNETICS 7 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 f1 f2 HV(S1,R) = 0.774252, 0.169539 on f 0.5 1 + f 0.5 2 = 1, f 2.0 1 + f 2.0 2 = 1 Pareto front lines Optimal solution set (S1) (a) Two optimal solution sets S1 by 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 f1 f2 HV(S2, R) = 0.793305 on f0.5 1 + f0.5 2 = 1 Pareto front lines Optimal solution set (S2) (b) Optimal solution set S2 by pa 0 0.2 0.4 0.6 0.8 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 f1 f2 HV(S2, R) = 0.178965 on f2.0 1 + f2.0 2 = 1 Pareto front lines Optimal solution set (S2) (c) Optimal solution set S2 by pa Fig. 6. 10 intersection points along 2-dimensional PFs. (a) HV(S1, R) = 0.774252, 0.169539 by method [8, 9] on convex and concave PFs, respectively, (b) HV(S2, R) = 0.793305 by pa method [16] on convex PF f0.5 1 + f0.5 2 = 1, (c) HV(S2, R) = 0.178965 by pa method on concave PF f2.0 1 + f2.0 2 = 1. 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 f1 HV(S2, R) = 0.980774 on f0.5 1 + f0.5 2 + f0.5 3 = 1 f2 f3 (a) Optimal solution set S1 by 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 f1 HV(S2, R) = 0.984072 on f0.5 1 + f0.5 2 + f0.5 3 = 1 f2 f3 (b) Optimal solution set S2 by pa Fig. 7. 153 points along 3-dimensional convex PF f0.5 1 + f0.5 2 + f0.5 3 = 1. (a) HV(S1, R) = 0.980744 by method [8, 9], (b) HV(S2, R) = 0.984072 by pa method [16]. A. PFs and Reference Sets Design In general, the true PFs have many different shapes and forms, which can be convex, concave, discrete, no-differential, multi-modal, asymmetric, etc [1 5]. Instead of considering all forms of PFs, our interest in the current paper is on the symmetric and continuous PFs. Without loss of generality, we consider the true PFs as f p 1 + f p 2 + + f p m = 1, (20) where the objectives are normalized in the range [0, 1] and p (0, ) is the parameter to control the geometrical shapes of PFs. As shown in Fig. 6(b), when p = 0.5, the PF is convex in the 2-dimensional objective space. On the other hand, the PF is 2-dimensional concave when p = 2 in Fig. 6(c). To obtain P, a number of non-dominated solutions need to be selected to approximate the true PFs. A simple approach for constructing P is to adopt the popular method [8, 9]. Let = ( 1, , m)T be a weight vector, where i 0 and m i=1 i = 1. As shown in Fig. 6, each weight vector de nes a line of prede ned gradient. All the weight vectors then take values from the following set: { 0 H , 1 H , , H H }, where H is a control parameter and the number of weight vectors is Cm 1 H+m 1. Every line meets the PF and each intersect point denotes a solution. In this case, the number 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 f1 HV(S2, R) = 0.428826 on f2.0 1 + f2.0 2 + f2.0 3 = 1 f2 f3 (a) Optimal solution set S1 by 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 0 0.2 0.4 0.6 0.8 1 f1 HV(S2, R) = 0.435165 on f2.0 1 + f2.0 2 + f2.0 3 = 1 f2 f3 (b) Optimal solution set S2 by pa Fig. 8. 153 points along 3-dimensional concave PF f2.0 1 +f2.0 2 +f2.0 3 = 1. (a) HV(S1, R) = 0.428826 by method [8, 9], (b) HV(S2, R) = 0.435165 by pa method [16]. of points in P is thus |P| = Cm 1 H+m 1. Taking Fig. 6 as an illustration example, we set H = 9, m = 2, and the C1 10 = 10 weight vectors can be derived as {( 0 9, 9 9), ( 1 9, 8 9) , ( 9 9, 0 9)}. The 10 solutions are then obtained by solving Eq. 20 based on the 10 weight vectors. In MOO, set P typically comprises many non-dominated so- lutions to approximate the true PFs at reasonable accuracies [4, 5]. In the experimental studies, the parameters are set as H = 10, 000 and |P| = 10, 001 on the bi-objective PFs. Their values are H = 140 and |P| = 10, 011 on the tri-objective PFs. They are H = 38, |P| = 10, 660 on the quad-objective PFs. In comparison, the reference set R is easy to construct, which is generated as R = {(1, 1)}, {(1, 1, 1)}, {(1, 1, 1, 1)} on 2, 3, 4-dimensional PFs, respectively. B. Optimal Solution Sets The goal in MOO is to nd the optimal solution set S with both good convergence and diversity. The special case of solutions in S that are not on PFs (Called poor convergence) will not be considered in the present study. As shown in Fig. 4, it may not make good sense to evaluate the diversity of S alone if it does not satisfy the basic requirement of convergence. In this paper, two optimal solution sets (S1 and S2) are constructed on the true PFs (Called good convergence) with different diversities. The set S1 is attained based on the method [8, 9]. The Pareto-adaptive weight vectors (pa method [16]) is adopted to maximize HV and generate S2. IEEE TRANSACTIONS ON CYBERNETICS 8 0 0.5 1 1.5 2 2.5 3 6 5 4 3 2 1 0 1 x 10 3 p [0.1, 3.0] GD(S1, P) GD (S2, P) 25 points 50 points 100 points (a) Convergence GD(S1, P) GD(S2, P) 0 0.5 1 1.5 2 2.5 3 5 0 5 10 15 20 x 10 3 p [0.1, 3.0] I1 +(S1, P) I1 +(S2, P) 25 points 50 points 100 points (b) Convergence I1 +(S1, P) I1 +(S2, P) 0 0.5 1 1.5 2 2.5 3 0.4 0.2 0 0.2 0.4 0.6 0.8 1 p [0.1, 3.0] (S1, P) (S2, P) 25 points 50 points 100 points (c) Diversity (S1, P) (S2, P) 0 0.5 1 1.5 2 2.5 3 0.3 0.2 0.1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 p [0.1, 3.0] (S1, P) (S2, P) 25 points 50 points 100 points (d) Diversity (S1, P) (S2, P) 0 0.5 1 1.5 2 2.5 3 4 3 2 1 0 1 2 3 4 x 10 4 p [0.1, 3.0] IGD(S1, P) IGD(S2, P) 25 points 50 points 100 points (e) Conv. Div. IGD(S1, P) IGD(S2, P) 0 0.5 1 1.5 2 2.5 3 2 0 2 4 6 8 10 12 14 x 10 3 p [0.1, 3.0] HV(S2, R) HV(S1, R) 25 points 50 points 100 points (f) Conv. Div. HV(S2, R) HV(S1, R) Fig. 9. 2-dimensional PFs: Differences in the metrics of S1 and S2 for cases of 25, 50 or 100 points along fp 1 + fp 2 = 1, p [0.1, 3.0]. The optimal solution sets S1 and S2 are obtained based on [8, 9] and pa [16], respectively. A small GD, I1 +, , and IGD while large HV is desirable. 0 0.5 1 1.5 2 2.5 3 9 8 7 6 5 4 3 2 1 0 1 x 10 3 p [0.1, 3.0] GD(S1, P) GD (S2, P) 45 points 91 points 153 points (a) Convergence GD(S1, P) GD(S2, P) 0 0.5 1 1.5 2 2.5 3 0.01 0 0.01 0.02 0.03 0.04 0.05 p [0.1, 3.0] I1 +(S1, P) I1 +(S2, P) 45 points 91 points 153 points (b) Convergence I1 +(S1, P) I1 +(S2, P) 0 0.5 1 1.5 2 2.5 3 0.1 0 0.1 0.2 0.3 0.4 0.5 0.6 p [0.1, 3.0] (S1, P) (S2, P) 45 points 91 points 153 points (c) Diversity (S1, P) (S2, P) 0 0.5 1 1.5 2 2.5 3 0.1 0.05 0 0.05 0.1 0.15 0.2 0.25 0.3 p [0.1, 3.0] (S1, P) (S2, P) 45 points 91 points 153 points (d) Diversity (S1, P) (S2, P) 0 0.5 1 1.5 2 2.5 3 6 5 4 3 2 1 0 1 2 x 10 4 p [0.1, 3.0] IGD(S1, P) IGD(S2, P) 45 points 91 points 153 points (e) Conv. Div. IGD(S1, P) IGD(S2, P) 0 0.5 1 1.5 2 2.5 3 0.005 0 0.005 0.01 0.015 0.02 0.025 p [0.1, 3.0] HV(S2, R) HV(S1, R) 45 points 91 points 153 points (f) Conv. Div. HV(S2, R) HV(S1, R) Fig. 10. 3-dimensional PFs: Differences in the metrics of S1 and S2 for cases of 45, 91 or 153 points along fp 1 + fp 2 + fp 3 = 1, p [0.1, 3.0]. The optimal solution sets S1 and S2 are obtained based on [8, 9] and pa [16], respectively. A small GD, I1 +, , and IGD while large HV is desirable. IEEE TRANSACTIONS ON CYBERNETICS 9 0 0.5 1 1.5 2 2.5 3 3 2.5 2 1.5 1 0.5 0 0.5 1 1.5 2 x 10 3 p [0.1, 3.0] GD(S1, P) GD (S2, P) 56 points 120 points 220 points (a) Convergence GD(S1, P) GD(S2, P) 0 0.5 1 1.5 2 2.5 3 0.04 0.02 0 0.02 0.04 0.06 0.08 p [0.1, 3.0] I1 +(S1, P) I1 +(S2, P) 56 points 120 points 220 points (b) Convergence I1 +(S1, P) I1 +(S2, P) 0 0.5 1 1.5 2 2.5 3 0.1 0 0.1 0.2 0.3 0.4 0.5 0.6 p [0.1, 3.0] (S1, P) (S2, P) 56 points 120 points 220 points (c) Diversity (S1, P) (S2, P) 0 0.5 1 1.5 2 2.5 3 0.15 0.1 0.05 0 0.05 0.1 p [0.1, 3.0] (S1, P) (S2, P) 56 points 120 points 220 points (d) Diversity (S1, P) (S2, P) 0 0.5 1 1.5 2 2.5 3 1.5 1 0.5 0 0.5 1 1.5 2 x 10 4 p [0.1, 3.0] IGD(S1, P) IGD(S2, P) 56 points 120 points 220 points (e) Conv. Div. IGD(S1, P) IGD(S2, P) 0 0.5 1 1.5 2 2.5 3 0.005 0 0.005 0.01 0.015 0.02 0.025 0.03 0.035 0.04 0.045 p [0.1, 3.0] HV(S2, R) HV(S1, R) 56 points 120 points 220 points (f) Conv. Div. HV(S2, R) HV(S1, R) Fig. 11. 4-dimensional PFs: Differences in the metrics of S1 and S2 for cases of 56, 120 or 220 points along fp 1 + fp 2 + fp 3 + fp 4 = 1, p [0.1, 3.0]. The optimal solution sets S1 and S2 are obtained based on [8, 9] and pa [16], respectively. A small GD, I1 +, , and IGD while large HV is desirable. In Fig. 6(a), the optimal solution set S1 has HV(S1, R) = 0.774252 when the PF is f 0.5 1 + f 0.5 2 = 1, and HV(S1, R) = 0.169539 for f 2 1 + f 2 2 = 1. In Fig. 6(b), the hypervolume of S2 is HV(S2, R) = 0.793305 on the convex PF. The solutions of S2 are distributed at near the two extreme points of PF and scattered more evenly than those of S1. On the other hand, Fig. 6(c) depicts HV(S2, R) = 0.178965 on the concave PF. The solutions of S2 are close to the median of PF and exhibit a better distribution than those of S1 in the central PF. Figs. 7-8 depict two optimal solution sets (S1 and S2) on 3-dimensional PFs, which are also constructed based on the method [8, 9] and pa method [16], respectively. The convex PF (f 0.5 1 + f 0.5 2 + f 0.5 3 = 1) of Fig. 7 has HV(S1, R) = 0.980774 and HV(S2, R) = 0.984072. The solutions of S2 in Fig. 7(b) are noted to be more evenly spread than those of S1 in Fig. 7(a) on all three objectives. On the other hand, for the concave PF (f 2.0 1 + f 2.0 2 + f 2.0 3 = 1) of Fig. 8, the hypervolumes are HV(S1, R) = 0.428826 and HV(S2, R) = 0.435165. Solutions of S1 in Fig. 8(a) are crowded near the three extreme points {(1, 0, 0), (0, 1, 0), (1, 0, 0)}, while they are sparse in the central region of PF. Furthermore, in contrast to S1, the solutions of S2 in Fig. 8(b) are crowded near the center of the PF ( 1 3, 1 3, 1 3). C. Performance Metric Studies on 2-dimensional PFs Upon constructing the set P, which represents the true PFs (Section V-A), we can then proceed to assess and compare the two optimal solution sets S1 and S2 (Section V-B) using the six representative metrics, rst on 2-dimensional PFs. The member size of the optimal solution set is con gured as |S1| = |S2| {25, 50, 100} and the formulation of PFs is f p 1 + f p 2 = 1, where p [0.1, 3.0]. In Fig. 9, the differences among the six MOO metrics for S1 and S2 on 2-dimensional PFs are presented. The values above the origin in Fig. 9 indicate that S2 is superior to S1. Fig. 9(a) depicts the differences between S1 and S2 on metric GD. Note that GD(S2, P) GD(S1, P) is near to zero when p [0.3, 3.0]. This implies that GD could not uncover the differences between the two optimal solution sets, which are revealed by the I1 + metric of Fig. 9(b). The result of I1 + is quite similar to HV in Fig. 9(f), where their curves exhibit similar trends, despite at the different scales. As the solution number of S increases from 25 to 50 and 100, |I1 +(S2, P) I1 +(S1, P)| becomes smaller. The reason is that a small is need to make S1 and S2 dominate the PFs (P) by Eq. 8 when the solution number of S is large. The two plots, Figs. 9(c)-(d), summarize the differences be- tween S1 and S2 on the diversity metrics ( and ). Notably, both metrics arrive at similar results. The optimal solution set S2 exhibits superior diversity over S1 when p [0.1, 1.5) (i.e., (S2, P) < (S1, P) and (S2, P) < (S1, P)), whereas, S2 is inferior to S1 when p [1.5, 3.0]. As shown in Fig. 6, solutions in S2 are scattered on convex PFs, however, they tend to congregate together when the PF is concave. Overall, both and share similar results with HV on convex PFs, but are in con ict with HV on concave PFs. Taking focus on the convergence diversity metrics (IGD and IEEE TRANSACTIONS ON CYBERNETICS 10 2 0 2 4 6 8 10 12 14 x 10 3 7 6 5 4 3 2 1 0 1 x 10 3 HV(S2, R) HV(S1, R) GD(S1, P) GD (S2, P) Convex PFs p [0.1, 1.0] p [0.1, 0.3] p [0.3, 1.0] (a) Convergence GD 2 0 2 4 6 8 10 12 14 x 10 3 2 0 2 4 6 8 10 12 14 16 x 10 3 HV(S2, R) HV(S1, R) I1 +(S1, P) I1 +(S2, P) Convex PFs p [0.1, 1.0] p [0.1, 0.3] p [0.3, 1.0] (b) Convergence I1 + 2 0 2 4 6 8 10 12 14 x 10 3 0.1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 HV(S2, R) HV(S1, R) (S1, P) (S2, P) Convex PFs p [0.1, 1.0] p [0.1, 0.3] p [0.3, 1.0] (c) Diversity 2 0 2 4 6 8 10 12 14 x 10 3 0.1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 HV(S2, R) HV(S1, R) (S1, P) (S2, P) Convex PFs p [0.1, 1.0] p [0.1, 0.3] p [0.3, 1.0] (d) Diversity 2 0 2 4 6 8 10 12 14 x 10 3 0.5 0 0.5 1 1.5 2 2.5 3 x 10 4 HV(S2, R) HV(S1, R) IGD(S1, P) IGD(S2, P) Convex PFs p [0.1, 1.0] p [0.1, 0.3] p [0.3, 1.0] (e) Conv. Div. IGD 1 0 1 2 3 4 5 6 x 10 3 2.5 2 1.5 1 0.5 0 0.5 x 10 6 HV(S2, R) HV(S1, R) GD(S1, P) GD (S2, P) Concave PFs p [1.0, 3.0] p [1.0, 3.0] (f) Convergence GD 1 0 1 2 3 4 5 6 x 10 3 0 0.002 0.004 0.006 0.008 0.01 0.012 0.014 0.016 0.018 HV(S2, R) HV(S1, R) I1 +(S1, P) I1 +(S2, P) Concave PFs p [1.0, 3.0] p [1.0, 3.0] (g) Convergence I1 + 1 0 1 2 3 4 5 6 x 10 3 0.3 0.25 0.2 0.15 0.1 0.05 0 0.05 HV(S2, R) HV(S1, R) (S1, P) (S2, P) Concave PFs p [1.0, 3.0] p [1.0, 3.0] (h) Diversity 1 0 1 2 3 4 5 6 x 10 3 0.3 0.25 0.2 0.15 0.1 0.05 0 0.05 0.1 HV(S2, R) HV(S1, R) (S1, P) (S2, P) Concave PFs p [1.0, 3.0] p [1.0, 3.0] (i) Diversity 1 0 1 2 3 4 5 6 x 10 3 3 2.5 2 1.5 1 0.5 0 0.5 x 10 4 HV(S2, R) HV(S1, R) IGD(S1, P) IGD(S2, P) Concave PFs p [1.0, 3.0] p [1.0, 3.0] (j) Conv. Div. IGD Fig. 12. The relationships of ve metrics (GD, I1 +, , and IGD) to the baseline HV on 2-dimensional convex PFs (a-e) and concave PFs (f-j). The I1 +, , and IGD are consistent with HV on 2-dimensional convex PFs, whereas, , and IGD contradict with HV on 2-dimensional concave PFs. HV) in Figs. 9(e)-(f), both S1 and S2 share the same scattered solutions and HV(S2, R) = HV(S1, R) when p = 1 (i.e., the PF is a straight line). When p = 1, S2 displays better HV than S1, i.e., HV(S2, R) > HV(S1, R). In Fig. 9(e), the IGD value of S2 is superior to S1 when p [0.1, 1.5), but S2 becomes inferior to S1 under the same IGD metric when p [1.5, 3.0]. This indicates that IGD shares similar estimations with HV on convex PFs, but displays con icting information to HV on concave PFs. To summarize, from the studies of the MOO metrics on 2- dimensional PFs, metric GD is found to be unable to provide diversity information on S1 and S2. The results of metric I1 +, on the other hand, is similar to those of HV. Other three metrics , and IGD share two characteristics: they display similar trends with HV on 2-dimensional convex PFs, but in some special cases (i.e., {f p 1 + f p 2 = 1|1.5 p 3}), they are in con ict with HV on 2-dimensional concave PFs. D. Performance Metric Studies on 3-dimensional PFs In this section, we extend the MOO metric studies to 3- dimensional PFs. The parameter H is set as H {8, 12, 16} and the number of solutions in S1, S2 are thus C2 H+2 = {45, 91, 153}, respectively. The 3-dimensional PFs are formu- lated as f p 1 +f p 2 +f p 3 = 1, where p [0.1, 3.0]. Figs. 10(a)-(f) present the assessments of the optimal solution sets S1 and S2 on the six representative metrics, i.e., GD, I1 +, , , IGD and HV, respectively. Fig. 10(a) shows similar GD values on S1 and S2 when p [0.3, 3.0], despite the two sets of solutions being unique to one other. This indicates that metric GD cannot distinguish between S1 and S2 on their diversities. With respect to metric I1 + in Fig. 10(b), it displays similar shapes to HV in Fig. 10(f), except for p [0.1, 0.5]. This means that an optimal solution set with a better HV will likely also imply a better I1 +. From the results in Fig. 10(c), metric does not display a stable trend, since its consecutive sorting procedure only works well on 2-dimensional PFs (See Section III-C3). Figs. 10(d)-(e) show that the two metrics, and IGD, exhibit similar trends, although at different scales. In particular, both and IGD share similar estimations with HV on the 3-dimensional con- vex PFs. However, when the PFs are 3-dimensional concave, i.e., {f p 1 + f p 2 + f p 3 = 1|1.5 p 3}, both and IGD are observed to be in con ict with HV. E. Performance Metric Studies on 4-dimensional PFs In this section, we proceed further to the study of the six MOO metrics on 4-dimensional PFs. The parameter H is con gured as H {5, 7, 9} and the number of solutions in S1, S2 are C3 H+3 = {56, 120, 220}, respectively. The 4- dimensional PFs are formulated as f p 1 + f p 2 + f p 3 + f p 4 = 1, where p [0.1, 3.0]. Figs. 11(a)-(f) show the measurements of the optimal solution sets S1 and S2 on the six representative metrics, i.e., GD, I1 +, , , IGD and HV, respectively. The results in Figs. 11(a, c) do not display clear trends on the two metrics GD and , which is similar to the results on 2, 3-dimensional PFs. Hence we are unable to draw any concrete conclusions on metrics GD and . On the other hand, the results of metric I1 + in Fig. 11(b) shows similar trends to HV in Fig. 11(f), except for p [0.1, 0.7]. This indicates that an optimal solution set with a large HV will likely also report a small I1 +. From the results of Fig. 11(d), metric is in con ict with HV on the 4-dimensional convex PFs (p [0.1, 1.0)), whereas it shares a similar estimation with HV on the 4-dimensional concave PFs (p [1.0, 3.0]). Last but not least, metric IGD in Fig. 11(e) exhibits similar and con icting trends to HV on the 4-dimensional convex and concave PFs, respectively. F. Relationship of MOO Metrics In this section, we analyse the relationships of the six repre- sentative metrics statistically and systematically. In particular, we discuss the case where |S1| = |S2| = 25, 45, 56 for 2, 3, 4-dimensional PFs, respectively. IEEE TRANSACTIONS ON CYBERNETICS 11 1 0 1 2 3 4 5 6 7 x 10 3 9 8 7 6 5 4 3 2 1 0 1 x 10 3 HV(S2, R) HV(S1, R) GD(S1, P) GD (S2, P) Convex PFs p [0.1, 1.0] p [0.1, 0.5] p [0.5, 1.0] (a) Convergence GD 1 0 1 2 3 4 5 6 7 x 10 3 0.01 0.005 0 0.005 0.01 0.015 HV(S2, R) HV(S1, R) I1 +(S1, P) I1 +(S2, P) Convex PFs p [0.1, 1.0] p [0.1, 0.5] p [0.5, 1.0] (b) Convergence I1 + 1 0 1 2 3 4 5 6 7 x 10 3 0.1 0 0.1 0.2 0.3 0.4 0.5 0.6 HV(S2, R) HV(S1, R) (S1, P) (S2, P) Convex PFs p [0.1, 1.0] p [0.1, 0.5] p [0.5, 1.0] (c) Diversity 1 0 1 2 3 4 5 6 7 x 10 3 0.05 0 0.05 0.1 0.15 0.2 0.25 0.3 HV(S2, R) HV(S1, R) (S1, P) (S2, P) Convex PFs p [0.1, 1.0] p [0.1, 0.5] p [0.5, 1.0] (d) Diversity 1 0 1 2 3 4 5 6 7 x 10 3 0.5 0 0.5 1 1.5 2 2.5 3 3.5 4 x 10 5 HV(S2, R) HV(S1, R) IGD(S1, P) IGD(S2, P) Convex PFs p [0.1, 1.0] p [0.1, 0.5] p [0.5, 1.0] (e) Conv. Div. IGD 5 0 5 10 15 20 x 10 3 1 0.5 0 0.5 1 1.5 2 2.5 x 10 4 HV(S2, R) HV(S1, R) GD(S1, P) GD (S2, P) Concave PFs p [1.0, 3.0] p [1.0, 3.0] (f) Convergence GD 5 0 5 10 15 20 x 10 3 0.01 0 0.01 0.02 0.03 0.04 0.05 HV(S2, R) HV(S1, R) I1 +(S1, P) I1 +(S2, P) Concave PFs p [1.0, 3.0] p [1.0, 3.0] (g) Convergence I1 + 5 0 5 10 15 20 x 10 3 0.04 0.02 0 0.02 0.04 0.06 0.08 HV(S2, R) HV(S1, R) (S1, P) (S2, P) Concave PFs p [1.0, 3.0] p [1.0, 3.0] (h) Diversity 5 0 5 10 15 20 x 10 3 0.04 0.02 0 0.02 0.04 0.06 0.08 HV(S2, R) HV(S1, R) (S1, P) (S2, P) Concave PFs p [1.0, 3.0] p [1.0, 3.0] (i) Diversity 5 0 5 10 15 20 x 10 3 5 4 3 2 1 0 1 2 x 10 4 HV(S2, R) HV(S1, R) IGD(S1, P) IGD(S2, P) Concave PFs p [1.0, 3.0] p [1.0, 3.0] (j) Conv. Div. IGD Fig. 13. The relationships of ve metrics (GD, I1 +, , and IGD) to the baseline HV on 3-dimensional convex PFs (a-e) and concave PFs (f-j). The I1 +, and IGD are consistent with HV on 3-dimensional convex PFs, whereas, and IGD contradict with HV on 3-dimensional concave PFs. Suppose two metrics M1 and M2 are considered for assess- ing the two optimal solution sets S1 and S2 (See Section V-B), the following concepts de ne the Consistency and Contradic- tion relationships between M1 and M2. Consistency: 1) S1 S2 on the two metrics (M1, M2); 2) Corr(M1(S1) M1(S2), M2(S1) M2(S2)) > 0. In the rst condition4, S1 dominates S2, which means that S1 reports better results than S2 on both metrics (M1, M2). The second condition5 reveals a positive cor- relation on the metric value differences. Contradiction: 1) S1 S2 on the two metrics (M1, M2); 2) Corr(M1(S1) M1(S2), M2(S1) M2(S2)) < 0. In the rst condition6, S1 and S2 are non-dominated. This implies that S1 is better than S2 on one metric, but worse on the other metric. The second condition indicates a negative correlation on the metric value differences. Figs. 12-14 show the relationships of the ve metrics (GD, I1 +, , and IGD) with the HV as baseline, on 2, 3, 4- dimensional PFs, respectively. Since a large HV and small GD, I1 +, , and IGD are desirable, we set the x-axis as HV(S2) HV(S1) and the y-axis is set in a reverse order for the other ve metrics (e.g., GD(S1) GD(S2)). In Figs. 12(a-e), for the 2-dimensional convex PFs {f p 1 + f p 2 = 1|0.1 p 1}, the ve metrics show positive corre- lations to the baseline HV, except for GD with p [0.3, 1.0] and I1 + with p [0.3, 0.6]. For instance, when p [0.1, 0.3], the correlation coef cients of GD, I1 +, , and IGD to HV are 0.986, 0.889, 0.831, 0.985, 0.994, respectively. The curve of GD in Fig. 12(a), which is below the origin, indicates a con ict. This indicates that an optimal solution set with better HV (e.g., HV(S2) > HV(S1)) will perform poorer on 4S1 S2 means S1 is better than S2 on both metrics (M1, M2). 5Corr(X, Y ) = E[(X X)(Y Y )] X Y . 6S1 S2 means S1 non-dominates S2 on the two metrics (M1, M2). GD (e.g., GD(S2) > GD(S1)). In addition, I1 +, , and IGD are consistent with HV on the 2-dimensional convex PFs, since their curves are above the origin and they are positively correlated to HV. A special case is that I1 + has a negative correlation to HV when p [0.3, 0.6], i.e., I1 +(S1) I1 +(S2) decreases when HV(S2) HV(S1) increases in Fig. 12(b). Figs. 12(f-j) showcase the relationships of the ve metrics to the baseline HV on 2-dimensional concave PFs {f p 1 +f p 2 = 1|1 p 3}. Fig. 12(g) shows that I1 + is consistent with HV, whereas, IGD contradicts with HV in Fig. 12(j). In particular, the correlation coef cient of I1 + to HV is 0.996, and that of IGD to HV is 0.934. In addition, GD does not show clear trends in Fig. 12(f) due to the high p-value (p = 0.0846 > 0.05) under Pearson statistical test7. The other two metrics and show negative correlations to HV at 0.955, 0.978, respectively. At the same time, the curves of and are above the origin when p [1.0, 1.5] in Figs. 12(h-i). This implies that an optimal solution set with good HV (e.g., HV(S2) > HV(S1)) is likely to also show good and (e.g., (S2) < (S1) and (S2) < (S1)). On the other hand, and contradict with HV on {f p 1 + f p 2 = 1|1.5 p 3}, since their curves are below the origin and they also exhibit negative correlations to HV. Fig. 13 shows the relationships of the ve metrics to the baseline HV on 3-dimensional PFs. From Figs. 13(a, f), GD does not exhibit stable trends. In general, I1 + is consistent with HV, because the curve of I1 + is above the origin and it is positively correlated to HV in most cases, when p [0.8, 3.0]. In addition, the metric in Fig. 13(c) shows a negative correlation to HV on the 3-dimensional convex PFs, whereas, it is positively correlated to HV on the 3-dimensional concave PFs (Fig. 13(h)). On the other hand, metrics and IGD share similar trends. Both and IGD are consistent with HV on the 3-dimensional convex PFs, except for p [0.3, 0.5], whereas, they contradict with HV on {f p 1 + f p 2 + f p 3 = 1|1.5 p 3}. 7If p < 0.05, the correlation of two metrics is signi cant with 95% con dence level. Otherwise, the correlation of two metrics is insigni cant. IEEE TRANSACTIONS ON CYBERNETICS 12 0.5 0 0.5 1 1.5 2 2.5 x 10 3 8 6 4 2 0 2 4 x 10 4 HV(S2, R) HV(S1, R) GD(S1, P) GD (S2, P) Convex PFs p [0.1, 1.0] p [0.1, 0.6] p [0.6, 1.0] (a) Convergence GD 0.5 0 0.5 1 1.5 2 2.5 x 10 3 0.04 0.035 0.03 0.025 0.02 0.015 0.01 0.005 0 0.005 0.01 HV(S2, R) HV(S1, R) I1 +(S1, P) I1 +(S2, P) Convex PFs p [0.1, 1.0] p [0.1, 0.6] p [0.6, 1.0] (b) Convergence I1 + 0.5 0 0.5 1 1.5 2 2.5 x 10 3 0.1 0 0.1 0.2 0.3 0.4 0.5 0.6 HV(S2, R) HV(S1, R) (S1, P) (S2, P) Convex PFs p [0.1, 1.0] p [0.1, 0.6] p [0.6, 1.0] (c) Diversity 0.5 0 0.5 1 1.5 2 2.5 x 10 3 0.14 0.12 0.1 0.08 0.06 0.04 0.02 0 HV(S2, R) HV(S1, R) (S1, P) (S2, P) Convex PFs p [0.1, 1.0] p [0.1, 0.6] p [0.6, 1.0] (d) Diversity 0.5 0 0.5 1 1.5 2 2.5 x 10 3 2 0 2 4 6 8 10 12 14 x 10 5 HV(S2, R) HV(S1, R) IGD(S1, P) IGD(S2, P) Convex PFs p [0.1, 1.0] p [0.1, 0.6] p [0.6, 1.0] (e) Conv. Div. IGD 0.005 0 0.005 0.01 0.015 0.02 0.025 0.03 0.035 0.04 1 0.5 0 0.5 1 1.5 x 10 3 HV(S2, R) HV(S1, R) GD(S1, P) GD (S2, P) Concave PFs p [1.0, 3.0] p [1.0, 3.0] (f) Convergence GD 0.005 0 0.005 0.01 0.015 0.02 0.025 0.03 0.035 0.04 0 0.01 0.02 0.03 0.04 0.05 0.06 0.07 HV(S2, R) HV(S1, R) I1 +(S1, P) I1 +(S2, P) Concave PFs p [1.0, 3.0] p [1.0, 3.0] (g) Convergence I1 + 0.005 0 0.005 0.01 0.015 0.02 0.025 0.03 0.035 0.04 0 0.01 0.02 0.03 0.04 0.05 0.06 HV(S2, R) HV(S1, R) (S1, P) (S2, P) Concave PFs p [1.0, 3.0] p [1.0, 3.0] (h) Diversity 0.005 0 0.005 0.01 0.015 0.02 0.025 0.03 0.035 0.04 0.02 0.01 0 0.01 0.02 0.03 0.04 0.05 0.06 HV(S2, R) HV(S1, R) (S1, P) (S2, P) Concave PFs p [1.0, 3.0] p [1.0, 3.0] (i) Diversity 0.005 0 0.005 0.01 0.015 0.02 0.025 0.03 0.035 0.04 6 5 4 3 2 1 0 1 x 10 5 HV(S2, R) HV(S1, R) IGD(S1, P) IGD(S2, P) Concave PFs p [1.0, 3.0] p [1.0, 3.0] (j) Conv. Div. IGD Fig. 14. The relationships of ve metrics (GD, I1 +, , and IGD) to the baseline HV on 4-dimensional convex PFs (a-e) and concave PFs (f-j). The I1 + and IGD are consistent with HV on 4-dimensional convex PFs, whereas, and IGD contradict with HV on 4-dimensional concave PFs. Fig. 14 summarizes the relationships of the ve metrics to HV on 4-dimensional PFs. From Figs. 14(a, f), GD once again does not exhibit clear relationships to HV. On the other hand, in Figs. 14(b, g), I1 + is consistent with HV in most cases, when p [0.7, 3.0]. Further, metric displays contradiction with HV on the 4-dimensional convex PFs (Fig. 14(c)), where- as, it is consistent with HV on the 4-dimensional concave PFs (Fig. 14(h)). In Figs. 14(d, i), metric displays negative correlations to HV. Last but not least, Figs. 14(e, j) indicate that IGD is consistent with HV on the 4-dimensional convex PFs, except for p [0.3, 0.6], whereas, it contradicts with HV on {f p 1 + f p 2 + f p 3 + f p 4 = 1|1.0 p 3}. From our studies on the optimal solution sets (S1 and S2) on 2, 3, 4-dimensional PFs, we summarize the characteristics and relationships of the six representative metrics (GD, I1 +, , , IGD and HV) considered in what follows. HV, which gives the convergence and diversity perfor- mance on a single scale, is identi ed as one of the most important metric to consider in MOO. Meanwhile, HV also requires little prior knowledge relative to the other ve metrics. In particular, the comparison set of HV and other ve metrics are reference set R and PF (P), respectively. It is easy to construct R but hard to generate P. The reasons are that constructing P requires the geometrical characteristics of the true PFs and |R| |P| (e.g., |R| = 1, |P| = 10, 001 for 2-dimensional PFs in Section V-A). The metric GD is solely designed for measuring solution set convergence. Hence, it does not provide diversity information. The metric I1 + is consistent with HV. Although I1 + belongs to the family of convergence metrics, it can measure diversity when P approximates the true PFs accurately. The metric works well for measuring diversity on bi- objective PFs, but it is not suitable for high dimensional PFs (m 3). The metric is an extension of to deal with different forms of PFs. The metric IGD is consistent with HV on convex PFs. On concave PFs, in some special case {f p 1 + f p 2 = 1, f p 1 + f p 2 + f p 3 = 1, f p 1 + f p 2 + f p 3 + f p 4 = 1|1.5 p 3}, the metric IGD contradicts with HV. G. Discussion of MOO Metrics In this section, we present a discussion which we hope would serve as a guide on the appropriate use of MOO metrics. In particular, we summarize the three key points as follows: 1) As an important performance criterion in MOO, capacity is commonly used as the prerequisite ahead of the other criteria, when one attempts to measure the quality of optimal solution sets [4, 5]. The reasons being that all the other criteria would become statistical insigni cant if the capacity measure, for example, the number of non-dominated solutions in any two optimal sets for comparison, differs or is too small in size. Hence, capacity metric serves as the paramount criterion for assessing multiobjective search algorithms. 2) On the convex PFs, two metrics, I1 + and IGD, have shown high consistencies to metric HV (Section V-F). This indicates that these three metrics, i.e., I1 +, IGD and HV, can be jointly used to assess solution sets optimality on the convex PFs [4, 5]. In particular, IGD or HV gives the convergence and diversity information of solution sets on a single scale. In general, IGD is less costly to compute than HV, especially for the high dimensional PFs. However, as shown in Section V-A, the comparison set P of IGD can be more dif cult to construct than the reference set R in HV. On the other hand, when interests are solely on the convergence quality of the optimal solution set, then, I1 + can be adopted independently. 3) On the concave PFs, it is worth noting that only one metric I1 + is found to be consistent with HV. As shown in Section V-F, IGD exhibit contradictions to HV. This indicates that any attempts to report the IGD measures jointly with HV on concave PFs may not make good sense. From here, the present study thus highlights the important need for the design of new diversity metrics that are consistent and appropriate for use jointly with HV, when dealing with concave PFs. IEEE TRANSACTIONS ON CYBERNETICS 13 VI. CONCLUSION AND FUTURE WORK In this paper, we have classi ed the performance metrics of Multiobjective Optimization (MOO) into four groups, name- ly Capacity, Convergence, Diversity, Convergence Diversity. With the presence of extreme cases, the inadequacies of some MOO metrics are analysed. Then, the relationship among representative metrics are investigated via empirical studies. In particular, metrics I1 + and IGD are found to be consistent with HV on convex Pareto fronts (PFs). When the PFs are concave, however, IGD displayed contradictions to HV. As such, there is thus room for the introduction of new MOO metrics that are appropriate for use with HV on concave PFs. Another future work is to investigate the relationship of MOO metrics on PFs of different geometrical characteristics, such as discrete, many-objective, asymmetric PFs, etc. The Matlab source codes of Pareto-adaptive weight vectors (pa ) [16], and the relationships among the six metrics (GD, I1 +, , , IGD and HV) are at http://www.ntu.edu.sg/home/ asysong/MOPmetrics-matlab.rar. ACKNOWLEDGMENT This work is partially supported under the A*Star-TSRP funding, the Singapore Institute of Manufacturing Technology- Nanyang Technological University Joint Laboratory and Col- laborative research Programme on Complex Systems, and the Center for Computational Intelligence (C2I) at NTU. REFERENCES [1] K. Deb. Multi-objective optimization using evolutionary algorithms, volume 16. Wiley, 2001. [2] C.A.C. Coello. Evolutionary multi-objective optimization: a historical view of the eld. IEEE Comput. Intell. Mag., 1(1):28 36, 2006. [3] H.A. Abbass, A. Bender, S. Gaidow, and P. Whitbread. Computational red teaming: Past, present and future. IEEE Comput. Intell. Mag., 6(1):30 42, 2011. [4] J.J. Durillo, A.J. Nebro, and E. Alba. The jmetal framework for multi- objective optimization: Design and architecture. In Proc. IEEE Cong. Evol. Comput., pages 1 8, 2010. [5] J.J. Durillo and A.J. Nebro. jMetal: A java framework for multi-objective optimization. Advances in Engineering Software, 42(10):760 771, 2011. [6] K. Deb, A. Pratap, S. Agarwal, and T. Meyarivan. A fast and elitist multiobjective genetic algorithm: NSGA-II. IEEE Trans. Evol. Comput., 6(2):182 197, 2002. [7] E. Zitzler, M. Laumanns, and L. Thiele. SPEA2: Improving the strength pareto evolutionary algorithm. Computer Engineering and Networks Laboratory (TIK), Zurich, Switzerland, (103), 2001. [8] Q. Zhang and H. Li. MOEA/D: A multiobjective evolutionary algorithm based on decomposition. IEEE Trans. Evol. Comput., 11(6):712 731, 2007. [9] H. Li and Q. Zhang. Multiobjective optimization problems with complicated pareto sets, MOEA/D and NSGA-II. IEEE Trans. Evol. Comput., 13(2):284 302, 2009. [10] E. Zitzler and S. K unzli. Indicator-based selection in multiobjective search. In Proc. Parall. Problem Solv. Nature, pages 832 842. Springer, 2004. [11] N. Beume, B. Naujoks, and M. Emmerich. SMS-EMOA: Multiobjective selection based on dominated hypervolume. European Journal of Operational Research, 181(3):1653 1669, 2007. [12] S. Kukkonen and J. Lampinen. GDE3: The third evolution step of generalized differential evolution. In Proc. IEEE Cong. Evol. Comput., volume 1, pages 443 450, 2005. [13] A.J. Nebro, J.J. Durillo, J. Garcia-Nieto, Coello C.A.C., F. Luna, and E. Alba. SMPSO: A new PSO-based metaheuristic for multi-objective optimization. In Proc. IEEE Sympo. Comput. Intell. in MiultiCriteria Decision Making, pages 66 73, 2009. [14] S. Jiang, J. Zhang, and Y.S. Ong. Asymmetric pareto-adaptive scheme for multiobjective optimization. In Proc. Conf. Artif. Intell., pages 351 360. Springer, 2011. [15] I.W. Tsang C.W. Seah, Y.S. Ong and S. Jiang. Pareto rank learning in multi-objective evolutionary algorithms. In Proc. IEEE Cong. Evol. Comput., pages 1 8, 2012. [16] S. Jiang, Z. Cai, J. Zhang, and Y.S. Ong. Multiobjective optimization by decomposition with pareto-adaptive weight vectors. In Proc. Conf. Natural Computation, volume 3, pages 1260 1264, 2011. [17] S. Jiang, J. Zhang, and Y.S. Ong. A multiagent evolutionary frame- work based on trust for multiobjective optimization. In Proc. Conf. Autonomous Agents and Multiagent Systems, pages 299 306, 2012. [18] M.N. Le, Y.S. Ong, S. Menzel, C.W. Seah, and B. Sendhoff. Multi co-objective evolutionary optimization: Cross surrogate augmentation for computationally expensive problems. In Proc. IEEE Cong. Evol. Comput., pages 1 8, 2012. [19] C.K. Goh, K.C. Tan, C.Y. Cheong, and Y.S. Ong. Noise-induced features in robust multi-objective optimization problems. In Proc. IEEE Cong. Evol. Comput., pages 568 575, 2007. [20] Y. Wang, Z. Cai, G. Guo, and Y. Zhou. Multiobjective optimization and hybrid evolutionary algorithm to solve constrained optimization problems. IEEE Trans. Sys., Man and Cybern., Part B, 37(3):560 575, 2007. [21] S. Mostaghim and J. Teich. Strategies for nding good local guides in multi-objective particle swarm optimization (MOPSO). In Proc. IEEE Swarm Intell. Symposium, pages 26 33, 2003. [22] D. Liu, K.C. Tan, C.K. Goh, and W.K. Ho. A multiobjective memetic algorithm based on particle swarm optimization. IEEE Trans. Sys., Man and Cybern., Part B, 37(1):42 50, 2007. [23] W.F. Leong and G.G. Yen. PSO-based multiobjective optimization with dynamic population size and adaptive local archives. IEEE Trans. Sys., Man and Cybern., Part B, 38(5):1270 1293, 2008. [24] S. Bandyopadhyay, S.K. Pal, and B. Aruna. Multiobjective GAs, quantitative indices, and pattern classi cation. IEEE Trans. Sys., Man and Cybern., Part B, 34(5):2088 2099, 2004. [25] X. Zou, Y. Chen, M. Liu, and L. Kang. A new evolutionary algorithm for solving many-objective optimization problems. IEEE Trans. Sys., Man and Cybern., Part B, 38(5):1402 1412, 2008. [26] M. Daneshyari and G.G. Yen. Cultural-based multiobjective particle swarm optimization. IEEE Trans. Sys., Man and Cybern., Part B, 41(2):553 567, 2011. [27] E. Masazade, R. Rajagopalan, P.K. Varshney, C.K. Mohan, G.K. Sendur, and M. Keskinoz. A multiobjective optimization approach to obtain decision thresholds for distributed detection in wireless sensor networks. IEEE Trans. Sys., Man and Cybern., Part B, 40(2):444 457, 2010. [28] G.G. Yen and W.F. Leong. Dynamic multiple swarms in multiobjective particle swarm optimization. IEEE Trans. Sys., Man and Cybern., Part A, 39(4):890 911, 2009. [29] R.V. Kulkarni and G.K. Venayagamoorthy. Particle swarm optimization in wireless-sensor networks: a brief survey. IEEE Trans. Sys., Man and Cybern., Part C, 41(2):262 267, 2011. [30] S. Bandyopadhyay. Multiobjective simulated annealing for fuzzy clus- tering with stability and validity. IEEE Trans. Sys., Man and Cybern., Part C, 41(5):682 691, 2011. [31] G. Avigad and A. Moshaiov. Interactive evolutionary multiobjective search and optimization of set-based concepts. IEEE Trans. Sys., Man and Cybern., Part B, 39(4):1013 1027, 2009. [32] C.K. Goh and K.C. Tan. A competitive-cooperative coevolutionary paradigm for dynamic multiobjective optimization. IEEE Trans. Evol. Comput., 13(1):103 127, 2009. [33] C.K. Goh and K.C. Tan. An investigation on noisy environments in evolutionary multiobjective optimization. IEEE Trans. Evol. Comput., 11(3):354 381, 2007. [34] K. Tang, K.C. Tan, and H. Ishibuchi. Guest editorial: Memetic algorithms for evolutionary multi-objective optimization. Memetic Computing, 2(1):1 1, 2010. [35] H. Ishibuchi, Y. Sakane, N. Tsukamoto, and Y. Nojima. Simultaneous use of different scalarizing functions in moea/d. In Proc. Genet. Evol. Comput., pages 519 526. ACM, 2010. [36] Z. Wang, K. Tang, and X. Yao. Multi-objective approaches to optimal testing resource allocation in modular software systems. IEEE Trans. Reliability, 59(3):563 575, 2010. [37] Y. Mei, K. Tang, and X. Yao. Decomposition-based memetic algorithm for multiobjective capacitated arc routing problem. IEEE Trans. Evol. Comput., 15(2):151 165, 2011. IEEE TRANSACTIONS ON CYBERNETICS 14 [38] Z. Wang, T. Chen, K. Tang, and X. Yao. A multi-objective approach to redundancy allocation problem in parallel-series systems. In Proc. IEEE Cong. Evol. Comput., pages 582 589. IEEE, 2009. [39] K. Tang, Z. Wang, X. Cao, and J. Zhang. A multi-objective evolutionary approach to aircraft landing scheduling problems. In Proc. IEEE Cong. Evol. Comput., pages 3650 3656. IEEE, 2008. [40] A.J. Nebro, J.J. Durillo, and Carlos A. Coello Coello C.A. Coello Coello. Analysis of leader selection strategies in a multi-objective particle swarm optimizer. In Proc. IEEE Cong. Evol. Comput., 2013. [41] D.A. Van Veldhuizen and G.B. Lamont. On measuring multiobjective evolutionary algorithm performance. In Proc. IEEE Cong. Evol. Com- put., pages 204 211, 2000. [42] D.A. Van Veldhuizen and G.B. Lamont. Multiobjective evolutionary algorithm test suites. In Proc. ACM Symposium on Applied Computing, pages 351 357, 1999. [43] A. Zhou, Y. Jin, Q. Zhang, B. Sendhoff, and E. Tsang. Combining model-based and genetics-based offspring generation for multi-objective optimization using a convergence criterion. In Proc. IEEE Cong. Evol. Comput., pages 892 899, 2006. [44] E. Zitzler and L. Thiele. Multiobjective optimization using evolutionary algorithms A comparative case study. In Proc. Parall. Problem Solv. Nature, pages 292 301. Springer, 1998. [45] E. Zitzler and L. Thiele. Multiobjective evolutionary algorithms: A comparative case study and the strength pareto approach. IEEE Trans. Evol. Comput., 3(4):257 271, 1999. [46] T. Okabe, Y. Jin, and B. Sendhoff. A critical survey of performance indices for multi-objective optimisation. In Proc. IEEE Cong. Evol. Comput., volume 2, pages 878 885, 2003. [47] E. Zitzler, L. Thiele, M. Laumanns, C.M. Fonseca, and V.G. da Fonseca. Performance assessment of multiobjective optimizers: An analysis and review. IEEE Trans. Evol. Comput., 7(2):117 132, 2003. [48] K.C. Tan, T.H. Lee, and E.F. Khor. Evolutionary algorithms for multi- objective optimization: performance assessments and comparisons. Artif. Intell. Review, 17(4):251 290, 2002. [49] J. Knowles and D. Corne. On metrics for comparing nondominated sets. In Proc. IEEE Cong. Evol. Comput., volume 1, pages 711 716, 2002. [50] C. Grosan, M. Oltean, and D. Dumitrescu. Performance metrics for multiobjective optimization evolutionary algorithms. In Proc. Applied and Industrial Mathematics, 2003. [51] J. Wu and S. Azarm. Metrics for quality assessment of a multiobjec- tive design optimization solution set. Journal of Mechanical Design, 123(1):18 25, 2001. [52] K. Deb, S. Agrawal, A. Pratap, and T. Meyarivan. A fast elitist non- dominated sorting genetic algorithm for multi-objective optimization: NSGA-II. In Proc. Parall. Problem Solv. Nature, pages 849 858, 2000. [53] D.A. Van Veldhuizen. Multiobjective evolutionary algorithms: classi - cations, analyses, and new innovations. Evol. Comput., 1999. [54] P. Czyz zak and A. Jaszkiewicz. Pareto simulated annealinga metaheuris- tic technique for multiple-objective combinatorial optimization. Journal of Multi-Criteria Decision Analysis, 7(1):34 47, 1998. [55] M.P. Hansen and A. Jaszkiewicz. Evaluating the quality of approxi- mations to the non-dominated set. Technical University of Denmark, Denmark, IMM Technical Report IMM-REP-1998-7, 1998. [56] E. Zitzler, K. Deb, and L. Thiele. Comparison of multiobjective evolutionary algorithms: Empirical results. Evol. Comput., 8(2):173 195, 2000. [57] J.R. Schott. Fault tolerant design using single and multicriteria genetic algorithm optimization. Technical report, DTIC Document, 1995. [58] A. Farhang-Mehr and S. Azarm. Diversity assessment of pareto optimal solution sets: An entropy approach. In Proc. IEEE Cong. Evol. Comput., volume 1, pages 723 728, 2002. [59] S. Mostaghim and J. Teich. A new approach on many objective diversity measurement. Practical Appro. MultiObj. Optimi., page 254, 2005. [60] J. Bader and E. Zitzler. HypE: An algorithm for fast hypervolume-based many-objective optimization. Evol. Comput., 19(1):45 76, 2011. [61] L. While and L. Bradstreet. Applying the WFG algorithm to calculate incremental hypervolumes. In Proc. IEEE Cong. Evol. Comput., pages 1 8, 2012. [62] E. Zitzler. Evolutionary algorithms for multiobjective optimization: Methods and applications. PhD thesis, 1999. [63] K. Bringmann and T. Friedrich. Approximating the least hypervolume contributor: NP-hard in general, but fast in practice. Theoretical Computer Science, 425:104 116, 2012. [64] B. Naujoks, N. Beume, and M. Emmerich. Multi-objective optimisation using S-metric selection: Application to three-dimensional solution spaces. In Proc. IEEE Cong. Evol. Comput., volume 2, pages 1282 1289, 2005. [65] C.M. Fonseca, L. Paquete, and M. L opez-Ib anez. An improved dimension-sweep algorithm for the hypervolume indicator. In Proc. IEEE Cong. Evol. Comput., pages 1157 1163, 2006. [66] N. Beume, C.M. Fonseca, M. L opez-Ib a nez, L. Paquete, and J. Vahren- hold. On the complexity of computing the hypervolume indicator. IEEE Trans. Evol. Comput., 13(5):1075 1082, 2009. [67] N. Beume. S-metric calculation by considering dominated hypervolume as Klee s measure problem. Evol. Comput., 17(4):477 492, 2009. [68] L. Bradstreet. The Hypervolume Indicator for Multi-objective Optimi- sation: Calculation and Use. PhD thesis, 2010. [69] L. While, L. Bradstreet, and L. Barone. A fast way of calculating exact hypervolumes. IEEE Trans. Evol. Comput., 16(1):86 95, 2012. [70] O. Schutze, X. Esquivel, A. Lara, and C.A.C. Coello. Using the averaged hausdorff distance as a performance measure in evolutionary multiobjective optimization. IEEE Trans. Evol. Comput., 16(4):504 522, 2012. Siwei Jiang received the M.S. and Ph.D. degrees in computer science from the China University of Geosciences (CUG), Wuhan, China, in 2006 and 2011, respectively. He is currently a Ph.D. student in School of Comouter Engineering, Nanyang Technological U- niversity (NTU), Singapore. His research interests include multiagent evolutionary algorithms, multia- gent system, reputation systems and vehicle routing problems. Yew-Soon Ong received the B.S. and M.S. de- grees in Electrical and Electronics Engineering from Nanyang Technological University (NTU), Singa- pore, in 1998 and 1999, respectively, and the Ph.D. degree on arti cial intelligence in complex design from the Computational Engineering and Design Center, University of Southampton, Southampton, U.K., in 2002. He is currently an Associate Professor, Director of the Center for Computational Intelligence at the School of Computer Engineering, NTU, and co- Director of the SIMTECH-NTU Joint Lab on Complex Systems. His research interest in computational intelligence spans across memetic computation, evolutionary design, machine learning and agent-based systems. Dr. Ong is the Founding Technical Editor-in-Chief of the Memetic Computing Journal, the Chief Editor of the Springer book series on studies in adaptation, learning, and optimization, and an Associate Editor of the IEEE Computational Intel- ligence Magazine, IEEE Transactions on Evolutionary Computation, IEEE Transactions on Neural Network & Learning Systems, IEEE Transactions on Cybernetics and others. Jie Zhang received the Ph.D. degree from the University of Waterloo, Waterloo, Canada, in 2009. He is currently an Assistant Professor at the School of Computer Engineering, Nanyang Techno- logical University (NTU), Singapore. His research interests include arti cial intelligence and multia- gent systems, trust modeling and incentive mech- anisms, and mobile and vehicular ad hoc networks. Liang Feng received his B.S. degree in School of Telecommunication and Information Engineering from Nanjing University of Posts and Telecommu- nications, China, in 2009. Currently, he is working towards the Ph.D degree in computer engineering at the Center for Computational Intelligence, School of Comouter Engineering, Nanyang Technological University (NTU). His primary research interests include evolutionary computation, memetic comput- ing, and transfer learning, etc.