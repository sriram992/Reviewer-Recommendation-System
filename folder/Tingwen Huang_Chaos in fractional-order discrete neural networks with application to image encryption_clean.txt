Neural Networks 125 (2020) 174 184 Contents lists available at ScienceDirect Neural Networks journal homepage: www.elsevier.com/locate/neunet Chaos in fractional-order discrete neural networks with application to image encryption Liping Chen a, Hao Yin a, Tingwen Huang b, Liguo Yuan c, Song Zheng d, , Lisheng Yin a a School of Electrical Engineering and Automation, Hefei University of Technology, Hefei 230009, China b Texas A & M University at Qatar, PO Box 23874, Doha, Qatar c College of Mathematics and Informatics, South China Agricultural University, Guangzhou, 510642, China d Department of Mathematics, School of Data Science, Zhejiang University of Finance and Economics, Hangzhou, 310018, China a r t i c l e i n f o Article history: Received 12 November 2019 Received in revised form 3 February 2020 Accepted 13 February 2020 Available online 22 February 2020 Keywords: Fractional-order discrete systems Neural networks Synchronization Image encryption a b s t r a c t In this paper, a three-dimensional fractional-order (FO) discrete Hopfield neural network (FODHNN) in the left Caputo discrete delta s sense is proposed, the dynamic behavior and synchronization of FODHNN are studied, and the system is applied to image encryption. First, FODHNN is shown to exhibit rich nonlinear dynamics behaviors. Phase portraits, bifurcation diagrams and Lyapunov exponents are carried out to verify chaotic dynamics in this system. Moreover, by using stability theorem of FO discrete linear systems, a suitable control scheme is designed to achieve synchronization of the FODHNN. Finally, image encryption system based on the chaotic FODHNN is presented. Some security analysis and tests are given to show the effective of the encryption system. 2020 Elsevier Ltd. All rights reserved. 1. Introduction In the past few decades, the dynamic analysis and synchro- nization of continuous FO chaotic systems have attracted much attention. As a classical nonlinear dynamic system, chaotic system has the characteristics of initial value sensitivity, ergodicity and complex behaviors. It can better describe some phenomena in the real world than linear system. Chaos system has a wide range of applications in many fields such as physics, life sciences, image encryption and secure communication (N Doye, Darouach, & Voos, 2013; Rasul Enayatifar & Abdullah, 2014). With the pi- oneering progress of Miller and Ross in the discretization of fractional calculus (Miller & Ross, 1988), several scholars have paid their attention to this new field. For example, Ref. Atici and Eloe (2009) has solved the initial value problems in discrete fractional calculus; Ref. At c and eng l (2010) defined discrete fractional calculus of variation problems and provided a mathe- matical modeling method, Holm has extended the properties of Laplace transform in discrete fractional calculus and applied it to fractional initial value solving problems (Holm, 2011); Ref. Abdel- jawad (2011) has defined left and right Caputo fractional sums and differences and studied their properties; Wu has analyzed the chaotic behaviors of discrete fractional chaotic systems (Wu & Baleanu, 2014, 2015a; Wu, Baleanu, & Zeng, 2014). Ji and Lai discussed the bifurcation and chaos of a new discrete fractional- order logistic map (Ji, Lai, Zhong, & Zhang, 2018). More details Corresponding author. E-mail address: szh070318@zufe.edu.cn (S. Zheng). about some of other aspects of FO discrete systems can be found in the Refs. Abdeljawad, Baleanu, Jarad, and Agarwal (2013), Abu- Saris and Al-Mdallal (2013), Chen, Luo, and Zhou (2011) and Goodrich and Peterson (2015). Infinite-memory is a typical feature of neurons of neural networks (NN), how to accurately describe this characteristics is a very interesting topic in the field of NN theoretical re- search (Wan et al., 2019; Yang, Cao, & Qiu, 2015; Yang & Yang, 2014). Recent researches have shown that fractional derivatives are nonlocal and have weakly singular kernels (Miller & Ross, 1988; Rudolf, 2000). Compared with integer-order operators, FO calculus has been proved to be an effective tool for the de- scription of memory and hereditary properties of various ma- terials and processes (Chen, Wu, He and Yin, 2015). With this in mind, FO calculus was introduced into NN to form FO neural networks (FONN). FONN has attracted much attention in re- cent years. Chaotic dynamics, synchronization and applications of FONN became three important topics of recent research. For example, stability of various FONN was considered and some stability conditions were proposed in Chen et al. (2017), Chen, Chai, Wu, Ma, and Zhai (2013), Chen et al. (2019), Wu, Hei, and Chen (2013), Wu, Liu, Huang, and Zeng (2017) and Zhang, Yu, and Wang (2015). Refs. Bao and Cao (2015), Chen, Wu, Cao and Liu (2015), Liu, Zeng, and Wang (2018), Peng, Wu, and Cao (2018) and Yu, Hu, Jiang, and Fan (2014) addressed synchronization con- troller design problems and some effective control schemes were given. Applications of FONN, such as the defense against chip cloning attacks for anti counterfeiting, implement of FONN, infor- mation processing and biology modeling were discussed in Refs. https://doi.org/10.1016/j.neunet.2020.02.008 0893-6080/ 2020 Elsevier Ltd. All rights reserved. L. Chen, H. Yin, T. Huang et al. / Neural Networks 125 (2020) 174 184 175 Anastasio (1994), Lundstrom, Higgs, Spain, and Fairhall (2008) and Pu, Yi, and Zhou (2017). Note that these FO NN have been assumed to act in a continuous-time manner (Anastasio, 1994; Bao & Cao, 2015; Chen et al., 2013; Chen, Wu et al., 2015; Liu et al., 2018; Lundstrom et al., 2008; Peng et al., 2018; Pu et al., 2017; Wu et al., 2013, 2017; Yu et al., 2014; Zhang et al., 2015). However, when it comes to the implementation of continuous-time networks for the sake of computer-based simulation, experimentation or computation, it is essential to discretize the continuous-time networks. In fact, discrete-time NN have already been applied in a wide range of areas. On the one hand, as pointed out in Mohamad and Gopal- samy (2003), the discretization cannot preserve the dynamics of the continuous-time counterpart even for a small sampling period. Therefore, there is a crucial need to study the dynamics of discrete-time neural networks. On the other hand, theoret- ical results of continuous-time NN do not necessarily hold for discrete-time NN, which also include FO NN case. Motivated by above discussion, the novelty and contribution of this paper are summarized as follows. 1. A class of FO discrete-time NN with Caputo-like discrete fractional difference was proposed. Different from the continu- ous FONN, the introduction of the discrete method makes the FODHNN system have memory characteristics and obtain entirely different dynamic behaviors. 2. The rich variety of complex nonlinear dynamical behavior is explored and some basic dynamical properties, such as phase portraits, bifurcation diagrams, Lyapunov exponent spectrum of the new FODHNN are investigated. At the same time, FODHNN synchronization is realized based on the stability theorem of FO discrete-time linear systems. 3. Based on the sensitivity of initial values and complex chaotic behaviors of FO discrete systems, FODHNN is used as a pseudo- random number sequence generator in the encryption algorithm, and good encryption effect is achieved. The rest of this paper is as follows. In Section 2, some defini- tions, lemmas and the new FODHNN will be given. In Section 3, some basic dynamical properties are analyzed to show its complex dynamics. Synchronization problem is considered in Section 4. In Section 5, an image encryption scheme based on FODHNN is proposed and some security analysis and tests are carried out. In the end, some conclusions are given in Section 6. 2. Preliminaries and model description In this section, the model is formulated, and some definitions, properties and lemmas to be used later are presented. Firstly, the following definitions for the discrete fractional calculus are introduced. Definition 1 (Atici & Eloe, 2009). Let u : Na R and > 0 be given. Then the fractional sum of order is defined by a u(t) = 1 ( ) t v s=a ( t (s))(v 1)u(s), t Na + v, where a is the starting point, (s) = s+1, Na = {a, a+1, a+2, . . .} and t( ) is the falling factorial function defined as t( ) = (t + 1) (t + 1 ), where ( ) is Gamma function, and (s) = 0 ts 1e tdt. Definition 2 (Abdeljawad, 2011). For > 0, N and u(t) defined on Na, the Caputo-like delta difference is defined by C au(t) = (m ) a mu(t) = 1 (m ) t (m ) s=a ( t (s))(m 1) m s u(s), where t Na+m , m = [ ] + 1, m, m a means the integer order difference with starting point 0 and a, respectively. Lemma 2.1 (Chen et al., 2011). For the delta fractional difference equation, C au(t) = f ( t + 1, u(t + 1)) , ku(a) = uk, m = [ ] + 1, k = 0, . . . , m 1, the equivalent discrete integral equation can be obtained as u(t) = u0(t) + 1 ( ) t s=a+m ( t (s))( 1)f ( s + 1, u(s + 1)) , where the initial iteration u0(t) reads u0(t) = m 1 k=0 (t a)k k! ku(a), t Na+m, Lemma 2.2 (Abu-Saris & Al-Mdallal, 2013). The zero equilibrium of the linear FO discrete-time system C ax(t) = Ax(t + 1), (1) where x(t) = (x1(t), . . . , xn(t))T , 0 < < 1, A Rn n and t Na, is asymptotically stable if { z C : |z| < (2 cos |argz| 2 ) , |argz| > 2 } (2) for all the eigenvalues of A, where argz means the principal argument angle of z. The dynamic behavior, synchronization and image encryption application of FODHNN we studied in this paper are derived from a 3D-neuron fractional-order continuous Hopfield-type neural networks proposed in Zhang, Qi, and Wang (2010) D x = x + Wf (x), x R3, (3) where W = ( 2 1.2 0 1.9 + p 1.71 1.15 4.75 0 1.1 ) , f (x) = tanh(x) = ex e x ex+e x . D t0,tx(t) = 1 (n ) t t0(t )n 1x(n)( )d , n 1 < < n Z+, ( ) is the Gamma function, and (s) = 0 ts 1e tdt. When p [ 0.35, 0.5], the system (3) admits chaotic behaviors. Select p = 0.1, system (3) can be rewritten as D x = x + 2 tanh(x) 1.2 tanh(y), D y = y + 2 tanh(x) + 1.71 tanh(y) + 1.15 tanh(z), D z = z 4.75 tanh(x) + 1.1 tanh(z). (4) When order = 0.95, chaotic attractor of system (4) is displayed in Fig. 1. Then applying the Caputo difference operator in Definition 2 to system (4), one will yield the following FODHNN for t Na+1 and 0 < 1 : C ax(t) = x(t 1 + ) + 2 tanh( x(t 1 + )) 1.2 tanh( y(t 1 + )) , C ay(t) = y(t 1 + ) + 2 tanh( x(t 1 + )) + 1.71 tanh( y(t 1 + )) + 1.15 tanh( z(t 1 + )) , C az(t) = z(t 1 + ) 4.75 tanh( x(t 1 + )) + 1.1 tanh( z(t 1 + )) . (5) 176 L. Chen, H. Yin, T. Huang et al. / Neural Networks 125 (2020) 174 184 To explore the dynamic behaviors, synchronization and im- age encryption application of FODHNN (5), numerical solutions of FODHNN (5) are needed to be presented. It follows from Lemma 2.1 that the equivalent numerical solution formula of the FODHNN (5) can be given x(t) = x(a) + 1 ( ) t s=a+1 ( t (s)) 1 ( x(s + 1) + 2 tanh( x(s + 1)) 1.2 tanh( y(s + + 1)) ) , y(t) = y(a) + 1 ( ) t s=a+1 ( t (s)) 1 ( y(s + 1) + 2 tanh( x(s + 1)) + 1.71 tanh( y(s + 1)) + 1.15 tanh( z(s + 1)) ) , z(t) = z(a) + 1 ( ) t s=a+1 ( t (s)) 1 ( z(s + 1) 4.75 tanh( x(s + 1)) + 1.1 tanh( z(s + 1)) ) . (6) For convenience, as s + N, let s + = j and denote the discrete kernel function 1 ( ) ( t (s)) 1 = (t s) ( ) (t s +a). Hereafter, we always assume anchor point a = 0 and restrict ourselves to 0 < < 1. In view of this, (6) becomes x(n) = x(0) + 1 ( ) n j=1 (n j + ) (n j + 1) ( x(j 1) + 2 tanh( x(j 1)) 1.2 tanh( y(j 1))) , y(n) = y(0) + 1 ( ) n j=1 (n j + ) (n j + 1) ( y(j 1) + (p + 1.9) tanh( x(j 1)) + 1.71 tanh( y(j 1)) + 1.15 tanh( z(j 1)) ) , z(n) = z(0) + 1 ( ) n j=1 (n j + ) (n j + 1) ( z(j 1) 4.75 tanh( x(j 1)) + 1.1 tanh( z(j 1))) . (7) Remark 2.1. According to the above formulas (6) and (7), one can find that the fractionalized systems (6) and (7) have a discrete kernel function, states x(n), y(n), z(n) depend on the past infor- mation x(0), . . . , x(n 1), y(0), . . . , y(n 1), z(0), . . . , z(n 1). This phenomenon is called the memory effect of the FODHNN. 3. Chaotic dynamics analysis In this subsection, complex dynamics of FODHNN (5) will be analyzed numerically. As is well known, the maximum Lyapunov exponent (LE) of the dynamical system is an important index that characterizes the rate of separation of infinitesimally close trajectories. It is often used to identify dynamic behavior and the chaotic degree of system. Now many LE calculation algorithms are proposed for integer-order system. However, how to calculate the LE for the FO discrete maps is interesting. Here Jacobian matrix algorithm for Lyapunov exponents of the discrete fractional maps proposed in Wu and Baleanu (2015b) is employed to calculate the LE of FODHNN. The tangent map can be given in matrix Ji as follows, Jn = x1(n) x2(n) x3(n) y1(n) y2(n) y3(n) z1(n) z2(n) z3(n) (8) where xi(n) = xi(0) + 1 ( ) n j=1 (n j + ) (n j + 1) ( xi(j 1) + 2xi(j 1) ( 1 tanh2( x(j 1))) 1.2yi(j 1) ( 1 tanh2( y(j 1)))) , yi(n) = yi(0) + 1 ( ) n j=1 (n j + ) (n j + 1) ( yi(j 1) + 2xi(j 1) ( 1 tanh2( x(j 1))) + 1.71yi(j 1) ( 1 tanh2( y(j 1))) + 1.15zi(j 1) ( 1 tanh2( z(j 1)))) , zi(n) = zi(0) + 1 ( ) n j=1 (n j + ) (n j + 1) ( zi(j 1) 4.75xi(j 1) ( 1 tanh2( x(j 1))) + 1.1zi(j 1) ( 1 tanh2( z(j 1)))) , where i = 1, 2, 3. The initial conditions satisfy: x1(0) x2(0) x3(0) y1(0) y2(0) y3(0) z1(0) z2(0) z3(0) = 1 0 0 0 1 0 0 0 1 Then LE of FODNN can be derived from the following equation, (x0) 1 i ln |Ji|. In order to understand more about the behavior of the FODHNN map (7), firstly bifurcation diagrams with p as the criti- cal parameter are carried out. Assume the initial value ( x(0), y(0), z(0)) = (0.2, 0.5, 0.8), step size 0.005. We vary p over the interval [ 1, 5] in steps of p = 0.005. When = 0.05, the bifurcation diagrams of state x(t) vs. varying p are shown in Fig. 2(a). Fig. 2(b), (c), (d) show the bifurcation diagram of order = 0.45, 0.7, 0.9, respectively. It can be seen that the chaotic behavior of FODHNN changes with the order. This complex dynamic behavior is different from the traditional continuous FO NN. When parameter p = 0.1, order = 0.05, largest LE max = 0.058, system is chaotic; when order = 0.7, largest LE max = 0.0017 is close to zero, periodic orbit is observed; when order = 0.45, 0.9, system is periodic, which is consistent with the largest Lyapunov exponent calculated by means of the above Jacobian method shown in Fig. 3. Phase L. Chen, H. Yin, T. Huang et al. / Neural Networks 125 (2020) 174 184 177 Fig. 1. Chaotic behaviors of FO Hopfield neural network (4) with fractional-order = 0.95. Fig. 2. Bifurcation diagram of x(n) vs. parameter p with initial value ( x(0), y(0), z(0)) = (0.2, 0.5, 0.8) (a) = 0.05, (b) = 0.45, (c) = 0.7, (d) = 0.9,. portraits for the six different orders = 0.05, = 0.45, = 0.6, = 0.7, = 0.9 also further confirm it in Fig. 4. More specifically, Fig. 4(a) shows the chaotic attractor when = 0.05, period-5 orbits appear in Fig. 4(b) when = 0.45, which is also confirmed in Fig. 2(b), when = 0.9, 0.2 and 0.6, period-8, period-4 and period-6 orbits are observed in Fig. 4(d), (e) and (f), respectively. Periodic orbit is displayed in Fig. 4(c) when = 0.7. In what follows, we fix p = 0.1 and let a specific param- eter order vary over a certain range, then discuss the com- plex dynamics of FODHNN map (5). The bifurcation diagrams for x(n), y(n), z(n) with as the critical parameter are shown in Fig. 5. One can observe from Fig. 5 that the attractors change whenever the order increases and many periodic windows appear. A prominently visible period-4 windows, period-5 win- dows, period-6 windows, and period-8 windows around interval 178 L. Chen, H. Yin, T. Huang et al. / Neural Networks 125 (2020) 174 184 Fig. 3. The largest Lyapunov exponents with initial value ( x(0), y(0), z(0)) = (0.2, 0.5, 0.8). [0.160, 0.250], [0.435, 0.465], [0.585, 0.640] and [0.865, 0.940], can be observed respectively. When order is selected as = 0.2, = 0.45, = 0.6 and = 0.9, the phase portraits in Fig. 4 verify these periodic windows. Remark 3.1. Based on the stability theorem of fractional contin- uous systems, a necessary condition for fractional system (4) to remain chaotic is keeping the eigenvalue in the unstable region. That is > 2 arctan IM( ) Re( ) , where IM( ) means the imaginary part of and Re( ) means the real part of . Choose the same parameters as those in the system (5), the necessary condition for system (4) to exhibit a chaotic attractor is > 2 arctan IM( ) Re( ) = 0.7477. The bifurcation diagram of state variable x with varying the fractional-order is shown in Fig. 6. From Figs. 5 and 6, one can see that there is a great difference in dynamical behaviors between FO continuous HNN (4) and FODHNN (5). 4. Chaos synchronization In general, synchronization as an important research field of chaotic dynamics has attracted many researchers attention due to its great potential applications in secure communication. In this section, we will design a suitable control law to achieve derive-response synchronization of FODHNN (5). Let the FODHNN (5) be the master system and define the slave system as follows C axs(t) = xs(t 1 + ) + 2 tanh( xs(t 1 + )) 1.2 tanh( ys(t 1 + )) + u1, C ays(t) = ys(t 1 + ) + 2 tanh( xs(t 1 + )) + 1.71 tanh( ys(t 1 + )) + 1.15 tanh( zs(t 1 + )) + u2, C azs(t) = zs(t 1 + ) 4.75 tanh( xs(t 1 + )) + 1.1 tanh( zs(t 1 + )) + u3. (9) where u1, u2, u3 are the control laws that will be given later. Define the synchronization error for t Na+1 as e1(t) = xs(t) x(t), e2(t) = ys(t) y(t), e3(t) = zs(t) z(t). (10) Then equations of error system between (5) and (9) can be obtained C ae1(t) = xs(t 1 + ) + 2 tanh( xs(t 1 + )) 1.2 tanh( ys(t 1 + )) + x(t 1 + ) 2 tanh( x(t 1 + )) + 1.2 tanh( y(t 1 + )) + u1, C ae2(t) = ys(t 1 + ) + 2 tanh( xs(t 1 + )) + 1.71 tanh( ys(t 1 + )) + 1.15 tanh ( zs(t 1 + )) + y(t 1 + ) 2 tanh( x(t 1 + )) 1.71 tanh( y(t 1 + )) 1.15 tanh( z(t 1 + )) + u2, C ae3(t) = zs(t 1 + ) 4.75 tanh( xs(t 1 + )) + 1.1 tanh( zs(t 1 + )) + z(t 1 + ) + 4.75 tanh( x(t 1 + )) 1.1 tanh( z(t 1 + )) + u3. (11) If control laws can force the error system to zero asymptot- ically, the aim of synchronization is achieved. For this end, one can design the following controller u1 = 2( tanh(xs(t 1 + v)) tanh(x(t 1 + v))) + 1.2( tanh(ys(t 1 + v)) tanh(y(t 1 + v))) k1(xs(t 1 + v) x(t 1 + v)), u2 = 2( tanh(xs(t 1 + v)) tanh(x(t 1 + v))) 1.71( tanh(ys(t 1 + v)) tanh(y(t 1 + v))) 1.15( tanh(zs(t 1 + v)) tanh(z(t 1 + v))) k2(ys(t 1 + v) y(t 1 + v)), u3 = 4.75( tanh(xs(t 1 + v)) tanh(x(t 1 + v))) 1.1( tanh(zs(t 1 + v)) tanh(z(t 1 + v))) k3(zs(t 1 + v) z(t 1 + v)). (12) Theorem 4.1. For the master slave FODHNN (5) and (9), the synchronization between systems (5) and (9) will be achieved if the controller is designed as (12) where k1, k2, k3 satisfy 1 < max i=1,2,3{ki} < 2 1. (13) L. Chen, H. Yin, T. Huang et al. / Neural Networks 125 (2020) 174 184 179 Fig. 4. Phase portraits with ( x(0), y(0), z(0)) = (0.2, 0.5, 0.8) for = 0.05, 0.45, 0.7, 0.9, 0.2, 0.6. Proof. Substituting the proposed control law (12) into error system (11), one yields the simplified error dynamics C ae1(t) C ae2(t) C ae3(t) = ( 1 k1 0 0 0 1 k2 0 0 0 1 k3 ) e1(t 1 + ) e2(t 1 + ) e3(t 1 + ) . (14) Obviously, eigenvalues of the error system are 1 k1, 1 k2, 1 k3. It follows from Lemma 2.2 that error system (14) is asymptotically stable if 1 k1, 1 k2, 1 k3 satisfy the condition (2) in Lemma 2.2. Now, it is easy to see that eigenvalues 1 k1, 1 k2, 1 k3 of system (14) satisfy |arg i| = > 2 (i = 1,2,3) when ki > 1, if maxi=1,2,3 |z| = maxi=1,2,3{ 1 ki} < (2 cos |argz| 2 ) = 2 , i.e, if condition (13) holds, error system (14) is asymptotically stable based on Lemma 2.2, which implies that synchronization between (5) and (9) will be realized. This completes the proof. 180 L. Chen, H. Yin, T. Huang et al. / Neural Networks 125 (2020) 174 184 Fig. 5. Bifurcation diagrams of x(n), y(n), z(n) with respect to the fraction order with initial value ( x(0), y(0), z(0)) = (0.2, 0.5, 0.8). Fig. 6. Bifurcation diagram of fractional-order HNN (4) with respect to the order . In the simulation, choose k1 = k2 = k3 = 0.6, order = 0.8, maxi=1,2,3{ki} = 0.6 < 2 1 = 0.7411, so that the stability con- dition (13) is satisfied. Select initial conditions (x(0), y(0), z(0)) = (0.2, 0.5, 0.8) and (xs(0), ys(0), zs(0)) = (0.3, 0.3, 1.1). Fig. 7 shows the state synchronization between x, y, z and xs, ys, zs, respectively. The time evolution of the synchronization error is depicted in Fig. 8. 5. Image encryption The application of chaotic systems to image encryption (Al- Hazaimeh, Al-Jamal, Alhindawi, & Omari, 2017; Chai, Fu, Gan, Lu, & Chen, 2019; Essaid, Akharraz, Saaidi, & Mouhib, 2019) is a very popular direction in recent years. In this section, application of FODHNN in image encryption will be discussed, and an encryp- tion system based on the above chaotic system is proposed. Some security analysis and tests are given to show the effective of the encryption system. 5.1. Image encryption/decryption scheme The structure of the encryption system is shown in Fig. 9, which includes secret code stream generator, plaintext-unrelated diffusion I, plaintext-related confusion, and plaintext-unrelated diffusion II. The chaotic system FODHNN (5) is employed to generate the secret code streams. Set secret key K = (x0, y0, z0, ) that comes from system FODHNN (5). Assume that the plain image is denoted by P, the size of P is M N, and grayscale level is L-bit. Denote (x0, y0, z0) as the initial values of FODHNN (5) and as the order, three pseudo- random sequences {xi}, {yi}, {zi}, i = 1, . . . , MN, are generated by iterating Eq. (7) for MN times. The encrypted matrix can be derived by using the equation as follows: X(k, l) = round( (x(k 1) N+l) 1013 mod 2L) + 1, Y(k, l) = round( (y(k 1) N+l) 1013 mod 2L) + 1, Z(k, l) = round( (z(k 1) N+l) 1013 mod 2L) + 1, (15) L. Chen, H. Yin, T. Huang et al. / Neural Networks 125 (2020) 174 184 181 Fig. 7. Chaotic synchronization for = 0.8, ( x(0), y(0), z(0)) = (0.2, 0.5, 0.8), ( xs(0), ys(0), zs(0)) = (0.3, 0.3, 1.1) and (k1, k2, k3) = (0.6311, 0.6311, 0.6311). Fig. 8. Time evolution of the synchronization errors for = 0.8, ( x(0), y(0), z(0)) = (0.2, 0.5, 0.8), ( xs(0), ys(0), zs(0)) = (0.3, 0.3, 1.1) and (k1, k2, k3) = (0.6, 0.6, 0.6). where k (1, M), l (1, N), function round(t) denotes integer closest to t. The scheme is shown in Fig. 10 that is composed of plaintext- unrelated diffusion I, plaintext-related confusion and plaintext- unrelated diffusion II. Firstly one gets a plain image P, then transform P into A using the algorithm shown in plaintext- unrelated diffusion I. The step plaintext-related confusion will be carried out by the following two formulas: m = (( X(i, j)) + sum( A(Z(i, j), 1 to N)) mod M ) + 1, n = (( Y(i, j)) + sum( A(1 to M, X(i, j))) mod N ) + 1. if m = i or Z(i, j), or n = j or X(i, j), or Z(i, j) = i, or X(i, j) = j, then the location of the pixel A(i, j) remains unchanged, else A(i, j) and A(m, n) exchange location. When all the elements in A are all done as above, one gets the matrix B. In the end, the plaintext- unrelated diffusion II is used to carry out the operations from the last pixel of B to the first pixel of B. The matrix C can be obtained from the relation between (Bij) and Cij shown in Fig. 10, which is also the cipher image we need. The decryption scheme is the inverse process of the encryption scheme. 5.2. Security analysis Choose image Cameraman (256 256) and set keyword to (0.2, 0.5, 0.8, 0.5), the plain, cipher and decipher images using the proposed scheme in Fig. 10 are given in Fig. 11. In addition, histograms of plain image and cipher image are presented in Fig. 11. 5.2.1. Correlation coefficients test We randomly choose 2000 pairs of adjacent pixels from the original image and the encrypted image, and calculate the corre- lation coefficient by the following formula: D(u) = 1 N N i=1 ( ui E(u))2, E(u) = 1 N N i=1 ui, cov(u, ) = 1 N N i=1 ( xi E(u))( yi E(v)) , rxy = cov(u, v) D(u) D(v). (16) In general, there are three indices between adjacent points: verti- cally adjacent pixels, horizontally adjacent pixels and diagonally adjacent pixels. The correlation coefficients are shown in Ta- ble 1. Moreover, the correlation distribution of two horizontally 182 L. Chen, H. Yin, T. Huang et al. / Neural Networks 125 (2020) 174 184 Fig. 9. Image encryption/decryption scheme. (a) Encryption scheme. (b) Decryption scheme. Fig. 10. Encryption scheme. sum(t) is the sum of all the elements in the vector t, X, Y, Z are the pseudo-random sequences. Table 1 Correlation coefficient of two adjacent pixels in three directions. Cameraman(256 256) Horizontal Vertical Diagonal Plain image 0.9566 0.9340 0.8954 Cipher image 0.0208 0.0011 0.0323 adjacent pixels in the plain image and cipher image is shown in Fig. 12. One can see from Table 1 and Fig. 12, the corre- lation between the adjacent pixel points of the original image are 0.9566, 0.9340 and 0.8954, and the correlation of adjacent pixels of the cipher image are 0.0208, 0.0011 and 0.0323, they theoretically close to zero. 5.2.2. Information entropy test Information entropy is an important indicator for assessing the degree of randomness of information in pictures. For a random grayscale image with grayscale level L = 256, the ideal infor- mation entropy is 8, and it can be calculated by the following formula: H = L i=0 p(i)log2p(i). Here we calculate the information entropy of cameraman and its cipher image in Fig. 11. Table 2 shows the results of the calculation, and we can find that the information entropy of the cipher image 7.9971, is very close to 8, which means that the information of the plain image is well hidden. 5.2.3. Differential attack test NPCR (number of pixels change rate) and UACI (unified av- erage changing intensity) are two indices that we often use to describe the ability of encryption algorithm to resist differential attacks. NPCR is to compare the values of the corresponding pixels of the two pictures, and calculate the number of different points as a percentage of all pixels. The UACI records the difference be- tween all corresponding pixels of the two pictures and compares the average of the differences with the maximum difference(255). L. Chen, H. Yin, T. Huang et al. / Neural Networks 125 (2020) 174 184 183 Fig. 11. (a) plain image, (b) cipher image, (c) decipher image, (d) histograms of (a), (d) histograms of (b). Fig. 12. Correlation of horizontal adjacent pixels: (a) plain image (b) cipher image. NPCR and UACI can be calculated by the following formula: NPCR = i,j D(i, j) M N 100%, UACI = i,j |C C | M N 100%. where M and N are the sizes of the plain image, C and C are two cipher images whose corresponding plain images differ only by one pixel. Then if C(i, j) = C (i, j), D(i, j) = 1; Otherwise D(i, j) = 0. The ideal NPCR is 99.6094% and the ideal UACI is 33.4635%. NPCR and UACI of cameraman are also shown in Ta- ble 2. From the table one can see that the encryption system using our proposed new chaotic model also has good anti-differential attack characteristics. Table 2 Results of information entropy tests and differential attack test. Cameraman NPCI(99.6094%) UACI(33.4635%) Entropy(8) FODHNN 99.6158% 33.4557% 7.9971 Logistic map 99.5361% 33.4379% 7.9968 In the end, we used integer Logistic map instead of FODHNN as the pseudo-random number generator of the encryption algo- rithm, and also encrypted the image cameraman. The encryption effect was analyzed as shown in Table 2. It can be seen that the complex dynamic behavior of fractional-order chaotic sys- tem can improve the security performance of the encryption algorithm. 184 L. Chen, H. Yin, T. Huang et al. / Neural Networks 125 (2020) 174 184 6. Conclusions In this paper, a novel 3-D fractional discrete Hopfield neural networks was proposed. The dynamic behavior of the system with different orders is analyzed in detail. Phase portraits, bifur- cation diagrams and Lyapunov exponents of the discrete system agree well with each other. It is worth pointing out that the chaotic behavior of discrete fractional neural networks is com- pletely different from that of the integer order one and even the continuous fractional order one. Then based on the stability of discrete fractional-order linear systems, control schemes are designed such that synchronization of discrete fractional neural networks is achieved. Finally, the proposed FODHNN is applied to the image encryption algorithm as a pseudo-random number generator, and the simulation results show that the algorithm has good encryption characteristics. Acknowledgments This work was supported by the National Natural Science Funds of China (No. 61403115, No. 11571016, No. 11971032), the Society Science Foundation from Ministry of Education of China (Grant No. 19YJCZH265), the Fundamental Research Funds for the Central Universities, China (No. JZ2016HGXJ0022), the Science and Technology Program of Guangzhou, China (No. 201707010031) and First Class Discipline of Zhejiang-A (Zhejiang Univeristy of Finance and Economics-Statistics). References Abdeljawad, T. (2011). On Riemann and Caputo fractional differences. Computers & Mathematics with Applications, 62(3), 1602 1611. Abdeljawad, T., Baleanu, D., Jarad, F., & Agarwal, R. P. (2013). Fractional sums and differences with binomial coefficients. Discrete Dynamics in Nature and Society. Abu-Saris, Raghib, & Al-Mdallal, Qasem (2013). On the asymptotic stability of linear system of fractional-order;difference equations. Fractional Calculus and Applied Analysis, 16(3), 613 629. Al-Hazaimeh, O. M., Al-Jamal, M. F., Alhindawi, N., & Omari, A. (2017). Image encryption algorithm based on lorenz chaotic map with dynamic secret keys. Neural Computing and Applications, 1 11. Anastasio, T. J. (1994). The fractional-order dynamics of brainstem vestibulo- oculomotor neurons. Biological Cybernetics, 72(1), 69 79. Atici, F., & Eloe, P. (2009). Initial value problems in discrete fractional calculus. Proceedings of the Americal Mathematical Society, 137(3), 981 989. At c , F. M., & eng l, S. (2010). Modeling with fractional difference equations. Journal of Mathematical Analysis and Applications, 369(1), 1 9. Bao, H., & Cao, J. (2015). Projective synchronization of fractional-order memristor-based neural networks. Neural Networks, 63, 1 9. Chai, X., Fu, X., Gan, Z., Lu, Y., & Chen, Y. (2019). A color image cryptosystem based on dynamic DNA encryption and chaos. Signal Processing, 155, 44 62. Chen, L., Cao, J., Wu, R., Machado, J. T., Lopes, A. M., & Yang, H. (2017). Stability and synchronization of fractional-order memristive neural networks with multiple delays. Neural Networks, 94, 76 85. Chen, L., Chai, Y., Wu, R., Ma, T., & Zhai, H. (2013). Dynamic analysis of a class of fractional-order neural networks with delay. Neurocomputing, 111, 190 194. Chen, L., Huang, T., Machado, J. T., Lopes, A. M., Chai, Y., & Wu, R. (2019). Delay- dependent criterion for asymptotic stability of a class of fractional-order memristive neural networks with time-varying delays. Neural Networks, 118, 289 299. Chen, F., Luo, X., & Zhou, Y. (2011). Existence results for nonlinear fractional difference equation. Advances in Difference Equations, 2011(1), 713201. Chen, L., Wu, R., Cao, J., & Liu, J.-B. (2015). Stability and synchronization of memristor-based fractional-order delayed neural networks. Neural Networks, 71, 37 44. Chen, L., Wu, R., He, Y., & Yin, L. (2015). Robust stability and stabilization of fractional-order linear systems with polytopic uncertainties. Applied Mathematics and Computation, 257, 274 284. Essaid, M., Akharraz, I., Saaidi, A., & Mouhib, A. (2019). A novel image encryption scheme based on permutation/diffusion process using an improved 2D chaotic system. In 2019 International conference on wireless technologies, embedded and intelligent systems (WITS) (pp. 1 6). Goodrich, C., & Peterson, A. C. (2015). Discrete fractional calculus. Springer. Holm, M. T. (2011). The laplace transform in discrete fractional calculus. Computers & Mathematics with Applications, 62(3), 1591 1601. Ji, Y., Lai, L., Zhong, S., & Zhang, L. (2018). Bifurcation and chaos of a new discrete fractional-order logistic map. Communications in Nonlinear Science and Numerical Simulation, 57, 352 358. Liu, P., Zeng, Z., & Wang, J. (2018). Global synchronization of coupled fractional- order recurrent neural networks. IEEE Transactions on Neural Networks and Learning Systems, 1 11. Lundstrom, B. N., Higgs, M. H., Spain, W. J., & Fairhall, A. L. (2008). Fractional differentiation by neocortical pyramidal neurons. Nature Neuroscience, 11(11), 1335. Miller, K. S., & Ross, B. (1988). Fractional difference calculus. In Proceedings of the international symposium on univalent functions, fractional calculus and their applications, (pp. 139 152). Mohamad, S., & Gopalsamy, K. (2003). Exponential stability of continuous-time and discrete-time cellular neural networks with delays. Applied Mathematics and Computation, 135(1), 17 38. N Doye, I., Darouach, M., & Voos, H. (2013). Observer-based approach for fractional-order chaotic synchronization and communication. In 2013 European control conference (ECC) (pp. 4281 4286). IEEE. Peng, X., Wu, H., & Cao, J. (2018). Global nonfragile synchronization in finite time for fractional-order discontinuous neural networks with nonlinear growth activations. IEEE Transactions on Neural Networks and Learning Systems, 1 15. Pu, Y.-F., Yi, Z., & Zhou, J.-L. (2017). Fractional hopfield neural networks: Fractional dynamic associative recurrent neural networks. IEEE Transactions on Neural Networks and Learning Systems, 28(10), 2319 2333. Rasul Enayatifar, I. F. I., & Abdullah, Abdul Hanan (2014). Chaos-based image encryption using a hybrid genetic algorithm and a dna sequence. Applied Mathematics and Computation, 56, 83 93. Rudolf, H. (2000). Applications of fractional calculus in physics. world scientific. Wan, X., Yang, X., Tang, R., Cheng, Z., Fardoun, H. M., & Alsaadi, F. E. (2019). Exponential synchronization of semi-markovian coupled neural networks with mixed delays via tracker information and quantized output controller. Neural Networks, 118, 321 331. Wu, G.-C., & Baleanu, D. (2014). Discrete fractional logistic map and its chaos. Nonlinear Dynamics, 75(1 2), 283 287. Wu, G.-C., & Baleanu, D. (2015a). Discrete chaos in fractional delayed logistic maps. Nonlinear Dynamics, 80(4, SI), 1697 1703. Wu, G.-C., & Baleanu, D. (2015b). Jacobian matrix algorithm for lyapunov exponents of the discrete fractional maps. Communications in Nonlinear Science and Numerical Simulation, 22(1 3), 95 100. Wu, G.-C., Baleanu, D., & Zeng, S.-D. (2014). Discrete chaos in fractional sine and standard maps. Physics Letters. A, 378(5 6), 484 487. Wu, R., Hei, X., & Chen, L. (2013). Finite-time stability of fractional-order neural networks with delay. Communications in Theoretical Physics, 60(2), 189 193. Wu, A., Liu, L., Huang, T., & Zeng, Z. (2017). Mittag-leffler stability of fractional- order neural networks in the presence of generalized piecewise constant arguments. Neural Networks, 85, 118 127. Yang, X., Cao, J., & Qiu, J. (2015). Pth moment exponential stochastic synchro- nization of coupled memristor-based neural networks with mixed delays via delayed impulsive control. Neural Networks, 65, 80 91. Yang, X., & Yang, Z. (2014). Synchronization of ts fuzzy complex dynamical networks with time-varying impulsive delays and stochastic effects. Fuzzy Sets and Systems, 235, 25 43. Yu, J., Hu, C., Jiang, H., & Fan, X. (2014). Projective synchronization for fractional neural networks. Neural Networks, 49, 87 95. Zhang, R., Qi, D., & Wang, Y. (2010). Dynamics analysis of fractional order three- dimensional hopfield neural network. In Natural computation (ICNC), 2010 sixth international conference on, Vol. 6 (pp. 3037 3039). IEEE. Zhang, S., Yu, Y., & Wang, H. (2015). Mittag-leffler stability of fractional-order hopfield neural networks. Nonlinear Analysis. Hybrid Systems, 16, 104 121.