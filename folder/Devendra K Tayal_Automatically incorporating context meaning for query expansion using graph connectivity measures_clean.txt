Prog Artif Intell (2014) 2:129 139 DOI 10.1007/s13748-014-0041-x REGULAR PAPER Automatically incorporating context meaning for query expansion using graph connectivity measures Amita Jain Kanika Mittal Devendra K. Tayal Received: 7 June 2013 / Accepted: 14 January 2014 / Published online: 4 February 2014 Springer-Verlag Berlin Heidelberg 2014 Abstract In order to improve the retrieval performance, the query is reformulated by the process of Query expansion (QE). Most of the existing query expansion techniques do not consider the context of the terms present in the user s query which can result in low precision and recall. Through this paper, the query consisting of ambiguous terms (polysemy words) is expanded by selecting the terms, which are in close proximity to the query terms while context meaning of the terms is automatically incorporated. The basis of this query expansion method is to investigate the role of graph structure (which is being created for the query) and determining the importance of each node in the graph using WordNet. The relevant nodes representing word senses are identi ed from the graph and can be chosen as additional terms to be added to thequeryforimprovingtheretrievalofwebpages.Theexper- iments, conducted on data sets of ambiguous queries show that proposed approach outperforms other query expansion methodologies by enhancing precision and recall. Keywords Query expansion Natural language processing Information retrieval PageRank Hypertext induced topic selection (HITS) Key player problem (KPP) Centrality A. Jain (B) Department of CSE, Ambedkar Institute of Advanced Communication, Tech and Research, Delhi, India e-mail: amitajain@aiactr.ac.in; amita_jain_17@yahoo.com K. Mittal Department of CSE, Bhagwan Parshuram Institute of Technology, New Delhi, India e-mail: Kkanika_virgo@yahoo.com D. K. Tayal Department of CSE, Indira Gandhi Delhi Technical University for Women, Delhi, India e-mail: dev_tayal2001@yahoo.com 1 Introduction Information retrieval [1] is a process of retrieving the doc- uments from the document database when the user enters his query in the search engine. The main aim of information retrieval system is to evaluate the degrees of relevance of the collected documents with respect to a user s query and retrieve the documents with a high degree of satisfaction to the user. But sometimes, it results in the retrieval of irrele- vant documents along with relevant documents, as the user is unclear about the information actually needed. The uncer- tainty in the user s query induces ambiguity due to which inappropriate documents are retrieved. In addition, heteroge- neous and dynamically changing information are the major challenges of web data [2], which results in low precision. In order to improve the retrieval ef ciency, QE technique is used in which user s query is modi ed by addition of cer- tain terms into the original query The expansion of the initial query is done by nding and adding the relevant terms from the retrieved documents to the initial query, and weighing of the terms is done using an appropriate weighing technique [3,4]. Through query expansion, the ambiguity of terms can be dealt and the effects of the word mismatch problem are reduced which is a result of different terms being used in reference to a single concept, both in the documents and in the user queries. The process of adding terms to the query can either be manual, automatic or user-assisted. In literature there are several techniques for query expan- sion, such as relevance feedback technique [5] in which the user is presented with list of answers to the query and the user can then mark as relevant or irrelevant to the informa- tion need. A variation of relevance feedback, namely, pseudo relevance feedback was proposed by Buckley et al. [6]. A term cluster query expansion [7] in which classi cation infor- mation is generated based on which term clusters are made 123 130 Prog Artif Intell (2014) 2:129 139 which are then selected by user and additional query terms are selected accordingly. Manning et al. [1] categorized query expansion into two classes: global methods based on expand- ing the query independent of query terms so that new query matches other semantically related terms and local method used the documents retrieved using unmodi ed query. Query can also be expanded by using ontology, which provides vocabulary and word representations for clear communica- tion within a particular domain such as WordNet, Euro Word- Net [8] etc. The methods proposed for query expansion in the liter- ature are not deprived from drawbacks. Lioma and Ounis [9] attempted two approaches for query expansion technique that is based rstly, a purely shallow syntactic-based query expansion (SSQE) technique and second, a combination of the SSQE method and the probabilistic pseudo-relevance feedback approach. However, this assumption was not accu- rate as frequently occurring part-of-speech blocks are merely a result of sentence construction in natural language docu- ments. In addition their approach was computationally inten- sive as it required parsing of documents. Another way of expanding the query which was based on co-occurrence of terms has a drawback that two terms which co-occur in the same sentence seem more correlated than two terms which occur distantly within a document, but the simple co- occurrence does not necessarily mean that the terms are cor- related. Moreover, this approach gave more importance to rare terms than to common terms. However, there are several problems with ontology-based approach too like issues related to vocabulary mismatch between the query terms and the concepts in the ontology. Secondly, a lot of effort is required if an ontology for a partic- ulardomaindoesnotexisttoconstructontologyfromscratch. The design and construction of domain ontology is labor intensive, time consuming and dif cult. In this paper, the focus is on graph-based methods for query expansion and investigating the role of graph struc- ture to determine the importance of a node in the graph. The graph is analyzed to nd the additional and relevant nodes out of all the candidate nodes to be added to the original query nodes (terms) so as to expand the query. The various graph connectivity measures, namely, degree centrality, between- ness centrality, key player problem, PageRank & HITS have been analyzed which will assess the relative importance of the node within the graph. Through this paper, a method is derived to improve the performance of query expansion and overcome the limita- tions of other approaches proposed for query expansion. In this approach, the semantic relations between all the query termsareexploredbyconstructingaWordNetgraphasWord- Net interlinks, not just word forms but speci c senses of words. The reason behind choosing WordNet is that all the concepts/word senses are related with each other through various relations de ned in WordNet. These relations play a signi cant role in representing the concepts/word senses in a semantically enriched way. This helps in extracting the terms for query expansion. As a result, words that are found in close proximity to one another in the network are semanti- cally disambiguated. In addition, WordNet labels the seman- tic relations among words; whereas the grouping of words in a thesaurus does not follow any explicit pattern other than meaning similarity. Then based on the minimum dis- tance between the query terms (selecting a particular value for minimum distance), a sub-graph is extracted from Word- Net graph consisting of all the neighboring and candidate terms for expansion including the original query terms. This technique is regardless of the ambiguous terms present in the query. After sub-graph construction, the graph connec- tivity measures are calculated to nd out the respective value of each connectivity measure. If the average score is found out for all the measures and the candidate nodes having the respective value of any three graph connectivity measures greater than the average score calculated, then those nodes will be selected as additional and relevant nodes to be added to original query nodes. In this way, query is expanded by considering the value of graph connectivity measures con- tributing to higher accuracy as the terms having higher value will only be added to the query. In Sect. 2, the related work done in this eld is mentioned. In next section, we will discuss about the evaluation para- meters used to select the expansion terms; in Sect. 4, the proposed method for query expansion is explained. Going further, in Sect. 5, we will explain the proposed method with the help of an example along with the results, nally in last section, we conclude our research and future work. 2 Related work In the literature, different QE approaches are studied in dif- ferent ways. For instance, Manning et al. [1] provided a clas- si cation of QE approaches into global and local methods, where global methods are query-independent since all docu- ments are examined for all queries. Global methods include QE using WordNet, reformulation using automatic thesaurus generation and local methods include query expansion using relevance feedback, pseudo-relevance feedback or indirect relevance feedback. Cao et al. [10] and Collins-Thompson and Callan [11] captured both direct and indirect term rela- tionships for query expansion through external knowledge sources such as ontology and statistical processing of the document corpus, respectively, as independent usage of the sources showed minimal improvement in retrieval perfor- mance. But there is minimal improvement as several impor- tant factors have not been examined and utilized extensively; e.g., the query structure, length, and linguistic characteris- 123 Prog Artif Intell (2014) 2:129 139 131 tics. One of the noticeable limitations of using the Word- Net Ontology given by Mihalcea [12] for query expansion is the limited coverage of concepts and phrases within the ontology. There are graph-based methods for query expan- sion which determined the importance of each node. The graph can be constructed by exploring semantic relations between different concepts using WordNet. The types of rela- tions considered are hierarchical (e.g., IS-A or hypernym- hyponym, part-whole, etc.,), associative (e.g., cause-effect), equivalence (synonymy), etc., [13] and the degree of impor- tance of each node can be found out using certain graph connectivity measures [12,14]. Kim et al. in [15] proposed a query term expansion and reweighting method which consid- ers the term co-occurrence within the feedbacked documents. The further categorization of QE approaches was given by Grootjen and van der Weide [16] as extensional, intentional, or collaborative ones. The rst approach materializes infor- mation needed in terms of documents; for instance, rele- vance feedback and local analysis methods. The second cat- egory, i.e., intentional approach which takes advantage of the semantics of keywords, is primarily thesauri/ ontology- based. Collaborative approaches are focused towards exploit- ing users behavior, e.g., mining query logs, as a comple- ment to previous approaches. Sanasam et al. [17] proposed a method for query expansion based on real-time implicit feedback from user. Voorhees in his work [18] used Word- Net for query expansion by adding synonyms to the origi- nal query for expansion. Many approaches have been used for expanding queries using automatically derived thesaurus which was basically used in domain-speci c search engines. Gong et al. [19] used the combination of WordNet and Term Semantic Network (TSN) for query expansion. Salton and McGill [5] proposed a method for query expansion based on relevance feedback in which the user is presented with a list of answers to the query, and the user can then mark as relevant or irrelevant to the information need. A variation of relevance feedback, namely, pseudo-relevance feedback was proposed by Buckley et al. [6] in which the relevant terms are extracted from top ten documents that are returned in response to the original query. The additional terms are selected based on statistical heuristics and added to the orig- inal query, and the expanded query is run again to return a fresh set of documents. Certain graph-based query expan- sion methods have been proposed which disambiguate the ambiguous terms and identify the importance of each node in the graph. Graph connectivity measures have been studied exten- sively in the social sciences, especially within the eld of Social Network Analysis (SNA) [20]. A social network is basically a network consisting of groups of people with some pattern of contacts or interactions between them. Examples include the patterns of friendship between individuals or the business relationships between companies. To determine which individuals are most central or important in the net- work (by being most connected or having most in uence) and how they are connected to one another is one of the fun- damental problems in network analysis is. There are certain measures such as centrality and connectivity, which allow us to characterize the structure and properties of large net- works and make predictions about their behavior. Among these measures, PageRank [21] and HITS [22] have been extremely in uential and are widely studied link analysis algorithms for information retrieval. PageRank, has the pur- pose of measuring the relative importance of each element within the set and assigns a numerical weighting to each ele- ment of a hyperlinked set of documents. It is based on the idea of voting or recommendation i.e., when one vertex links to another one; it is casting a vote for that vertex [21]. The vertex with highest number of votes casted will have higher importance or relevance, whereas HITS rates Web pages for their authority and hub values. Hubs and authorities exhibit a mutually reinforcing relationship: a good hub is a document that points to many others, and a good authority is a docu- ment that many documents point to. The difference between PageRank and HITS is that former is computed on a sub- graph of relevant pages and later takes the entire graph into account. Rada and Mihalcea in their work [12] identify the impor- tance of a particular node in a graph by nding graph central- ity. An unsupervised graph-based method for WSD proposed by Sinha and Mihalcea, was based on an algorithm that com- putes graph centrality of nodes in the constructed semantic graph, they made use of the in-degree, the closeness, and the betweenness of the vertices in the graph, as well as Page- Rank to measure the centrality of the nodes. PageRank and HITS are variants of the another graph connectivity mea- sure, namely, eigenvector centrality measure which assigns relative scores to all nodes in the graph based on the recur- sive principle that connections to the nodes having a high score contribute more to the score of the node [23]. Free- man in his work [24], determined the closeness of a vertex by calculating the shortest geodesic distance between two nodes which in turn determine the relative importance of node. According to Freeman, the betweenness of a vertex is de ned in the terms of how in-between a vertex is among all the other vertices present in the graph. Borgatti [25] in his work proposed a measure, namely, Key player Problem (KPP) and used it to determine the importance of a vertex by its relative closeness with all the other vertices. It is cal- culated as reciprocal of total shortest distance from a given node to all other nodes. Barathi and Valli [27] in their work proposed an ontology-based query expansion for retrieving information to capture the context of particular concept(s) and discover semantic relationships between them. In [28], Marco and Navigli proposed a method for improving web results by acquiring the various senses (i.e., meanings) of an 123 132 Prog Artif Intell (2014) 2:129 139 ambiguous query and then cluster the search results based on their semantic similarity to the word senses induced. 3 Evaluation measures to select expansion terms There are certain local measures and global, which determine the degree of relevance of a vertex v in graph G and the in uence of a node over the network. They are helpful in determining the graph connectivity and can be used for both directed and undirected graphs. In this paper, we will discuss about only local measures. We can de ne a local measure l as: l : V [0, 1] Avaluecloseto1indicates that avertexis important, whereas a value close to zero indicates that the vertex is peripheral. In the literature [20], there are several local methods for deter- mining the graph connectivity and importance of a partic- ular vertex or node in the graph, namely, key player prob- lem (KPP), PageRank, HITS, centrality i.e., degree central- ity, betweenness centrality, and other variants. The measures are discussed brie y below: 3.1 Centrality The basic idea behind the graph centrality is to determine the importance of a node in the graph taking into account the relation of the node with other nodes in the graph [12]. The variants of centrality are: 3.1.1 Degree centrality It is the simplest way to determine a vertex importance by its degree [14]. The degree of a vertex refers to the number of edges incident on that vertex. For an undirected graph, the number of outgoing edges and number of incoming edges are same; i.e., in-degree is equal to out-degree. However, for directed graphs it is different. The degree of a vertex is given by: deg(v) = |{(u, v) E : u V | If a vertex is present in the center of the graph, it has high degree. The degree centrality is the degree of a vertex nor- malized by the maximum degree and calculated as [14]. CD(v) = deg(v) |V | 1 (1) 3.1.2 Betweenness centrality It is de ned in terms of how in between a vertex is among the other vertices in the graph [12]. The betweenness cen- trality of a node v is the ratio of number of shortest paths from one node to another that are passing through v and the number of shortest path between two nodes. It is a computationally expensive method owing to the number of shortest paths that needs to be calculated. Betweenness centrality is calculated as: Betweenness(v) =  i j(v) i j (2) where i j is the number of shortest paths between node i and j, and i j (v) is the number of shortest paths between node i and j passing through vertex v. The node is considered to be important if that node is involved in large number of paths as compared to the total number of paths. 3.1.3 Key player problem (KPP) KPP considers the importance of a vertex by its relative close- ness with all the other vertices [25]. It is calculated as recip- rocal of total shortest distance from a given node to all other nodes. It is calculated as: KPP(v) =  u V :u =v 1 d(u,v) |V | 1 (3) where, the inverse of the shortest distance between v and all other nodes is the numerator, and denominator is the nodes in the graph. 3.1.4 PageRank PageRank is one of the popular algorithms to rank the nodes or nd the importance of a node in a network. It is based on the idea of voting or recommendation i.e., when one vertex links to another one; it is casting a vote for that vertex [21]. The vertex with highest number of votes casted will have higher importance or relevance. Moreover, the impor- tance of vertex casting a vote determines how important a vote is. All the nodes that link to v contribute towards deter- mining its relevance. The PageRank algorithm was initially proposed for directed graphs, but it can be applied on undi- rected graphs also. The PageRank of a node v for an undirected graph is calculated using a recursive function as: PageRank (v) = 1 d |V | + d  u,v E PR(u) outdegree(u) (4) where d is the damping factor introduced, which has the role of integrating into the model the probability of jumping 123 Prog Artif Intell (2014) 2:129 139 133 given vertex to another random vertex [26] and its value is set between zero and 1. A value for zero means that the ranking of the page does not depend on its outgoing links, and 1 indicates that the score is exclusively determined by the links with neighboring pages. The typical value of d is 0.85. 3.1.5 Hypertext induced topic selection (HITS) HITS is similar to PageRank but the only main difference is, it makes a distinction between authority and hubs; i.e, in this method two values are determined for a node v i.e., author- ity (a(v)) and hub value (h(v)). The authority corresponds to the pages that are good and reliable sources and have numer- ous incoming links, whereas hub value corresponds to the pages having many outgoing links [22]. Another difference between PageRank and HITS is that the former is computed on a sub-graph of relevant pages and later takes the entire graph into account. For every vertex, HITS produce two set of scores authority score and hub score. They are found out using below equations: HITSA(Vi) =  Vj In(Vi) HITSH(V j) (5) HITSH(Vi) =  Vj Out(Vi) HITSH A(V j) (6) For each iteration, these scores are normalized, so that the authority scores for all vertices add up to 1. HITS can also be applied to undirected graphs. 4 Proposed method To improve the retrieval of documents, the user query is expanded to include more relevant terms through query expansion method. As the user query does not index prop- erly all the relevant terms other than the query terms, it can lead to low precision results. Therefore, to retrieve relevant documents, the user s query has to be expanded by addition of more terms to original query. In this regard, an approach is proposed for expanding the query by nding the appropri- ate and relevant terms matching to query terms which can properly index query terms and then adding those related terms to the original query for ef cient documents retrieval. Through this method, a query has been considered having some query terms, using which a WordNet graph G is con- structed by exploring all the relations between the original query terms (i.e., hypernymy, hyponymy, meronymy, etc.,). Using this WordNet graph G having V vertices, a sub-graph G is extracted (which is empty initially) by considering the minimum distance L between the query terms nodes so that the path between any two linked query terms is less than or equal to L . The value of L in this approach is taken as: L = (max(min distance between the respective query terms)) (7) If the path between any two linked query terms is less than or equal to L , then that path is added to the sub-graph G . After constructing the entire sub-graph, the graph connec- tivity measures (discussed in Sect. 3) are calculated and the average score A of all of the graph connectivity measures is foundout.Then,selectthenodesV fromG suchthatnodeV is not equal to any query term and is having value of any three graph connectivity measures greater than the average score A for the respective measure. Finally add the selected nodes to the original query for expanding the original user s query. Consider a user query having i terms where 1 i n. The below terms will be used further in the paper: G is the graph constructed around query terms from Word- Net, i.e., WordNet Graph G. G Sub-graph extracted from G V is the nodes present in sub-graph Ti is the total number of query terms in the query where 1 i n T j is the query term considered at a time where 1 T j n Tk is the linked query term to T j where j + 1 Tk n L is minimum distance between the query terms A is the average score calculated for graph connectivity mea- sures. The proposed algorithm is given in Fig. 1. The description of the algorithm is given as below: 1. Initially query is entered by user having terms T1, T2, T3 Tn. 2. From the WordNet graph G, having V vertices using those the query terms create sub-graph G from the graph G such that G is subset of G. 3. For term T j= 1,2 n (a) Perform depth rst search (DFS) on every term T j of the WordNet graph (G). (b) For each Tk where k = j & k is between j+1 to n, if there is a path T j Tk of length <= L , where L = 5, add all the intermediate nodes and edges of path from T j to Tk to the WordNet sub-graph G . 4. After all the query terms are examined sub-graph, i.e., G is obtained. For each node of the Sub graph G , calcu- late the Graph Connectivity Measures Degree Centrality, KPP, Betweenness, PageRank &, HITS. 5. Select the nodes V from G such that, node V should not be equal to any query term Tj and having value of 123 134 Prog Artif Intell (2014) 2:129 139 Fig. 1 The algorithm of the proposed method any three measures greater than their respective average scores. 6. Add these selected terms (nodes) to the original query. This algorithm can be shown with the help of a owchart given in Fig. 2. 5 Illustration through example The above approach can be explained through an example where a query is taken. The sample query taken is: Inven- tions in Science and Technology . Here the stop words such as in , and are neglected and the query terms selected are only invention , science , technology . A graph is constructed around all query terms from Word- Net and is used for nding the shortest distance between a pair of terms by node counting method. The graph is given in Fig. 3 Using the graph given in Fig. 3, a particular query term is selected initially and length of the shortest path will be found out between all other query terms linked to the initially cho- sen query term. If the length of the shortest path between the query terms is less than or equal to the L calculated, then that path between the two respective terms will be added to the sub-graph, which was initially empty. In this way the entire sub-graph is extracted from the WordNet graph consisting of query terms and other relevant terms. The sub-graph G is shown in Fig. 4. Aftertheconstructionofsub-graph,thegraphconnectivity measures (discussed in Sect. 3) are calculated, and results are obtained shown in Table 1. For each graph connectivity measure, the average score is found out and based on that all those terms that have values of any three connectivity measures greater than the average score are selected as nal 123 Prog Artif Intell (2014) 2:129 139 135 Fig. 2 Flowchart of the proposed method expansion terms out of all the candidate terms and will be added to the original query so as to retrieve more relevant documents and improve the ef ciency of retrieval. The table containing various evaluation parameters for each candidate term and the corresponding average score is given below: Results: From the above values obtained, we can nd out that four terms namely: creativity, ability, engineering and discipline (excluding the original query terms i.e., inven- tion, science, technology) have higher average values than the other candidate terms. Therefore, query will be expanded by adding these terms to the original query. 6 Experiments, implementation and results The given query expansion technique was tested on stan- dard ADI data set. From this data set, we have consid- ered queries having ambiguous terms, i.e., having polyse- mous words. We have used WordNet version 2.1 for deter- mining context meaning of ambiguous terms. The TMG tool, which is a MATLAB toolbox for text to matrix gen- erator, is used for generating term documents matrices, removing of stop words from query, frequent/infrequent terms removal, clustering of documents, retrieval of rele- vant documents, etc. TMG offers two alternatives for Text Mining. 123 136 Prog Artif Intell (2014) 2:129 139 Fig. 3 An excerpt of WordNet around the query terms Fig. 4 Sub-graph G constructed from WordNet graph G 123 Prog Artif Intell (2014) 2:129 139 137 Table 1 Evaluation and results The bold entries indicate the additional terms which are selected (on the basis of their centrality measures values) Terms Degree centrality KPP (key player problem) Betweenness centrality PageRank HITS Invention 0.11 0.36 0.003 0.0334 0.30 Imagination 0.17 0.39 0.005 0.0554 0.33 Creativity 0.29 0.50 0.025 0.0732 0.54 Vision 0.11 0.36 0.001 0.0334 0.29 Ingenuity 0.11 0.41 0.001 0.0271 0.28 Ability 0.29 0.55 0.025 0.0881 0.55 Knowledge 0.11 0.43 0.003 0.0394 0.26 Cognition 0.11 0.39 0.001 0.0381 0.26 Cognitive science 0.11 0.39 0.001 0.0481 0.21 Science 0.23 0.51 0.018 0.0766 0.48 Discipline 0.23 0.51 0.020 0.0591 0.57 Communication 0.11 0.40 0.003 0.0294 0.25 Engineering 0.29 0.50 0.025 0.0761 0.63 Information technology 0.11 0.36 0.003 0.0294 0.29 Technology 0.23 0.48 0.011 0.0596 0.53 Computer science 0.17 0.40 0.007 0.0417 0.36 Arti cial intelligence 0.11 0.33 0.003 0.0511 0.14 Robotics 0.05 0.25 0 0.0319 0.11 Average 0.16 0.41 0.008 0.049 0.35 Vector Space Model (VSM) Latent Semantic Analysis (LSA) Using the corresponding GUI, the user can apply a ques- tion to an ADI dataset using any of the aforementioned tech- niques and get HTML response. This retrieval GUI uses a set of parameters as insert query, stop-list, number of factors, similarity measure, etc. To test the ef ciency of the graph connectivity approaches, we have primarily made use of the inset query parameter. We took the actual input query, used a set of Java API for WordNet Searching, for calculating and evaluating the measures (Degree Centrality, KPP, Between- ness Centrality, PageRank, HITS) to select the expansion terms. As its name implies, the Java API for WordNet Searching (JAWS) is an API that provides Java applications with the ability to retrieve data from the WordNet database. It is a simple and fast API that is compatible with both the 2.1 and 3.0 versions of the WordNet database les and can be used with Java 1.4 and later. Within the application, we can use JAWS by rst obtaining an instance of WordNet Database with code like the follow- ing: WordNetDatabase database = WordNetDatabase.getFile- Instance(); After that we can begin to retrieve synsets from the data- base. We have used the same synsets to rst construct the Fig. 5 Graph showing results for Ontology-based IR & graph connectivity-based IR WordNet graph G and later the subgraph G (G and G being the graph used in the illustration earlier). Once the input query is modi ed/expanded based on the measures evaluated above the same is fed to the insert query 123 138 Prog Artif Intell (2014) 2:129 139 parameter of the retrieval GUI of TMG. The resulting docu- ment set was then tested for precision and recall.. Precision is calculated for several values of N for only the top N docu- ments. The method discussed in this paper is an improvement over the other query expansion methods, i.e., ontology-based query expansion [27], as this methodology takes into consid- eration the ambiguous terms and determines the correct sense of the same and results in a signi cant improvement in the precision by increasing the number of relevant documents. A graph is plotted between precision and recall in which, for particular values of recall, there is a signi cant increase in the precision values for graph connectivity-based expansion method. The result shows an improvement over the ontology- based query expansion method. The graph is given as below in Fig. 5. 7 Conclusion The query expansion method proposed in this paper has shown improved precision and recall for the query having polysemy words. The terms were identi ed by determining the importance of a node/word sense in the graph created for the query and these terms served as the relevant expansion terms. The computational lexicon, WordNet is being used due to various relations between words are present and it was found that these relations play a signi cant role in represent- ing the concepts/word senses in a semantically enriched way. This representation further helped in incorporating context meaning automatically while query is being expanded. Vari- ous graph connectivity measures used were able to success- fully nd out the importance of nodes. Our method provided better results as compared to similar methods deployed in the literature in past. In this way, the user s query is enriched withmorerelevanttermsforef cientretrievalofrelevantweb pages. In future, the work can be expanded for all open class words such as verbs, adverbs, adjectives along with nouns. References 1. Manning,C.D.,Raghavan,P.,Schutze,H.:Anintroductiontoinfor- mation retrieval, Cambridge University Press, (2009) 2. Stuckenschmidt, H.: Data Semantics on the Web , J Data Seman- tics: JoDS (1), Springer, Berlin [u.a.] (2012) 3. Salton, G., Buckley, C.: Term-weighting approaches in automatic text retrieval. Information Process Manag 24(5), 513 523 (1988) 4. Wang, C., Yajun, D.U., Zhang, P., Han, B.: A term-reweighting method for query expansion. J Comput Information Syst 6(11), 3779 3785 (2010) 5. Salton, G., McGill, M.: Introduction to modern information retrieval. McGraw-Hill, New York (1988) 6. Buckley, C., Salton, G., Allan, J., Singhal: A, Automatic query expansion using SMART: TREC 3. In: D. Harman, ed., Overview of the Third Text Retrieval Conference (TREC-3), NIST Special Publication 500 225, pp. 69 80 (1994) 7. Kang, J.W., Kang, H.-K.: A term cluster query expansion model based on classi cation. Information in Natural Language Informa- tion Retrieval, International Conference on Arti cial Intelligence and Computational Intelligence (2010) 8. Leroy, G. et al: Customizable and ontology-enhanced medical information retrieval interfaces, Methods of Info in Medicine, (2000) 9. Lioma, C., Ounis, I.: A syntactically-based query reformulation technique for information retrieval. Information Process Manag 44(1), 143 162 (2008) 10. Cao, G., Nie-Y, J., Bai, J. : Integrating word relationships into language models. In proceedings of the 28th annual international ACM SIGIR conference on research and development in informa- tion retrieval, pp. 298 305 (2005) 11. Collins-Thompson K., Callan, J.: Query expansion using random walk models. In: Proceedings of the 14th ACM Intl conference on information and knowledge management, pp. 704 711 (2005) 12. Sinha, R., Mihalcea, R.: Unsupervised graph-based word sense disambiguation using measures of word semantic similarity. In: Proceedings of ICSC (2007) 13. George A. Miller: WordNet: a lexical database for English: Inter- national J. Lexicogr. (1995) 14. Navigli, R., Lapata, M.: An experimental study of graph connectiv- ity for unsupervised word sense disambiguation, IEEE transaction on pattern analysis and machine learning, Vol. 32 No. 4, April (2010) 15. Kim, B.M., Kim, J.Y., Kim, J.: Query term expansion and reweight- ing using term co-occurrence similarity and fuzzy inference. In: Proceedings of the Joint 9th IFSA World Congress and 20th NAFIPS International Conference, Vancouver, Canada, Vol. 2, pp. 715 720 (2001) 16. Grootjen, F.A., van der Th Weide, P.: Conceptual query expansion. Data Knowledge. Eng. 56(2), 174 193 (2006) 17. Singh, S.R., Murthy, H.A., Gonsalves, T.A.: Inference based Query Expansion Using User s Real Time Implicit Feedback. Knowl- edge Engineering and Knowledge Management, Communications in Computer and Information Science Vol. 272, 2013, pp. 158 172, Springer (2013) 18. Voorhees, E.M.: Query Expansion using Lexical-Semantic Rela- tions. In: SIGIR 94: Proceedings of the 17th Annual International ACM SIGIR conference on Research and Development in Infor- mation Retrieval, pp. 61 69, New York (1994) 19. Gong, Z., Cheang, C., Leong Hou, U.: Web query expansion by WordNet. In: Andersen, K., Debenham, J., and Wagner, R., eds. Database and Expert Systems Applications, volume 3588 of Lec- ture Notes in Computer Science, pp. 166 175. Springer (2005) 20. Wasserman, S., Faust, K.: Social network analysis: methods and applications. Cambridge Univ, Press (1994) 21. Brin, S., Page, M.: Anatomy of a Large-Scale Hypertextual Web Search Engine. In: Proceedings Seventh Conference World Wide Web, pp. 107 117 (1998) 22. Kleinberg, J.M.: Authoritative sources in a hyperlinked environ- ment. In: Proceedings Ninth Symposium Discrete Algorithms, pp. 668 677 (1998) 23. Bonacich, B.P.: Factoring and weighing approaches to status scores and clique identi cation. J. Math. Sociol. 2, 113 120 (1972) 24. Freeman, L.C.: Centrality in social networks: conceptual clari ca- tion. Social Netw. 1, 215 239 (1979) 25. Borgatti, S.P.: Identifying Sets of Key Players in a Network. In: Pro- ceedings Conference Integration of Knowledge Intensive Multi- Agent Systems, pp. 127 131 (2003) 26. Litvak, N., Scheinhardt, W., Volkovich, Y.: In-degree and Page- Rank of web pages: why do they follow similar power laws? 123 Prog Artif Intell (2014) 2:129 139 139 Memorandum 1807, Department of Applied Math., University of Twente (2006) 27. Barathi, M., Valli, S. : Ontology Based Query Expansion Based on Word Sense Disambiguation , International Journal of Computer Science and Information, Security, Vol. 7, No. 2, February (2010) 28. Di Marco, A., Navigli, R.: Clustering and diversifying web search results with Graph Based Word Sense Induction , Computational Linguistics (2012) 123