Vol.:(0123456789) 1 3 Network Modeling Analysis in Health Informatics and Bioinformatics (2022) 11:39 https://doi.org/10.1007/s13721-022-00382-2 ORIGINAL ARTICLE Predicting pattern of coronavirus using X ray and CT scan images Payal Khurana Batra1 Paras Aggarwal1 Dheeraj Wadhwa1 Mehul Gulati1 Received: 30 November 2021 / Revised: 6 August 2022 / Accepted: 21 September 2022 / Published online: 5 October 2022 The Author(s), under exclusive licence to Springer-Verlag GmbH Austria, part of Springer Nature 2022 Abstract Novel coronavirus is a disease that can propagate easily with very minute carelessness and with very little physical contact between people. Presently, the world s central health institution called the World Health Organization has approved and advised the Reverse Transcription-Polymerase Chain Reaction (RT-PCR) swab test as the most important and effective diagnostic method to confirm if a patient has COVID-19 symptoms or not. This test takes at least a day for revealing the results, depending on the feasible resources in the neighborhood. Moreover, the RT-PCR test gives sometimes false posi- tive results and slow in the process. To keep the potential virus carriers and potential causes of the disease quarantined as early as possible, there is still a requirement for a much faster and more accurate diagnostic process to supplement RT-PCR test of finding the patients affected by the virus. In this regard, radiological images such as X-ray and CT (Computerized Tomography) scan are found to be useful. The X-ray and CT scan have good screening modality; they are quick at captur- ing and finding and widely available around the world. Therefore, a deep learning model, which makes use of CT scan and X-ray images, has been proposed to automate and analyze the diagnostic process by utilizing Convolutional Neural Network (CNN). This model makes use of InceptionV3 deep learning model, a type of CNN. It is a lightweight deep learning model that is apt for mobile, laptop, and tablet platforms. The proposed model requires low memory space and gives an accuracy of about 96%, sensitivity of 93.48% for CXRs (Chest X-rays) and accuracy of 93%, sensitivity of 89.81 % for the CT scan images respectively. The proposed model is also compared with other deep learning models like VGG 16 (Visual Geometry Group), ResNet50V2 (Residual Network) and other existing deep learning models and it is found to be better in terms of accuracy and other performance parameters. Further, a web application has been developed from the proposed model. The web application is able to detect COVID-19 cases from the CT scan and X-ray images with significant accuracy. Keywords Deep learning Coronavirus CT scan X-ray Prediction Convolutional Neural Network (CNN) 1 Introduction In December 2019, cases of unidentified pneumonia were reported in Wuhan, China (Wu et al. 2020; Huang et al. 2020). Since then, Coronavirus Disease 2019 has rapidly spread to all parts of the globe. This coronavirus disease is termed as COVID-19 and the virus named as SARS-CoV-2. The novel coronavirus has caused a pandemic resulting in over 235 million infected individuals, over 5 million deaths and this count is growing day by day (Who 2021). This inva- sive disease affects and kills our respiratory system (Kanne and Chest 2020). COVID-19 patient s symptoms match with the common flu, pneumonia, and other respiratory illnesses. These occur over a period of four to ten days from getting the infection. Acknowledged symptoms comprise fever, cough, shortness of breath, and chest tightness/pain (Singhal 2020). It may create confusion in the diagnosis of patients with COVID-19 and typical pneumonia. The patients who lost their lives due to COVID-19 were the usual victims of hypertension, diabetes, cerebral infarction, chronic bronchi- tis and coronary heart disease. The World Health Organization (WHO) has approved the Reverse Transcription-Polymerase Chain Reac- tion (RT-PCR) swab test as a screening tool to diagnose COVID-19 cases (Corman et al. 2020). The sensitivity of RT-PCR depends on various factors such as the time span of symptoms, development of the virus, the speed of viral reproduction in the human respiratory system, time when the sample taken and quality of test procedure (Green et al. * Payal Khurana Batra payal.f12@gmail.com 1 Department of CSE and IT, Jaypee Institute of Information Technology, Noida, India Network Modeling Analysis in Health Informatics and Bioinformatics (2022) 11:39 1 3 39 Page 2 of 13 2020). Beside giving a false positive result, the process is slow and sometimes takes over a day to declare the result. Moreover, the result of the RT-PCR test is in terms of posi- tive and negative only. It does not say about the severity of the disease. This gives rise to a requirement for a quick and accurate diagnostic test besides this existing method so that the growth of the virus can be restrained as soon as possible. As an alternative, no contact methods are useful to detect COVID-19. Various diagnostic tools, such as lung ultrasound (LUS), Chest X-ray (CXR), and Computerized Tomography (CT) have been used to find variations in lungs related with COVID-19 (Araujo-Filho et al. 2020; Bernheim et al. 2020). Among various medical images, portable chest X-rays (CXRs) and CT scans are suggested as a good and feasible choice for COVID-19 detection. Although CT scan has been proved to be one of the most precise diagnostic methods for COVID-19, it has some important limitations such as around 70 times higher ionizing radiation than X-ray, high cost, and is not suitable for critically ill patients. Even though the cost per utility of the CT scan is high as compared to RT-PCR (Sriwijitalai and Wiwanitkit 2020), however, after the onset of symptoms, doctors prefer CT scan images for assessing the progress of disease, but for subsequent repeated exami- nation they prefer CXRs over CT images due to high radia- tions in CT scan. Therefore, both kinds of images can be used depending upon the condition of the patient. Moreover, due to overlap between CT scan appearance of COVID-19 pneumonia and viral pneumonia, CT examinations need to be integrated with clinical measures for the detailed evalu- ation (Lee et al. 2020; Zhao et al. 2020). Even, it is dif- ficult for a radiology specialist to detect the nascent stage of COVID-19 because of CXRs peripheral distribution. In fact, there are many aspects that need to be considered in image analysis, which can affect diagnostic results such as physique of the patient, holding of breath during the scan, the presence of other medical devices on the chest and type of projection etc (Tartaglione et al. 2020). Automated decision-making tools based on machine learning and deep learning techniques could be valuable in alleviating some of this burden (Shen et al. 2017; Litjens et al. 2017). Artificial intelligence in medicine provides facilities for early diagnosis and decision making for further treatment of various diseases (Faust et al. 2018). Therefore, in this paper, a light weight deep learning model is pro- posed which helps in distinguishing and identifying non- COVID-19 viral, bacteria and other pathogens from COVID- 19 pneumonia. For the applying deep learning model, open source lungs X-ray and CT scan images database developed by of Cohen et al. (2020); Zhao et al. (2020) is used. In Fig. 1 representative chest X-rays of healthy and COVID-19 patients are given. Since publicly limited COVID-19 CXR and CT scan image data are available. Therefore, to increase the data, extra artificially data is generated via data augmentation. The proposed model helps us to predict and differentiate between COVID-19 and non-COVID-19 patients, initiating a quick screening of the virus, resulting in timely separation and treatment to cease further outspread of the virus. The major contributions of this research paper are as follows: To overcome the insufficient data, extra artificial data is generated using data augmentation. Before feeding images into the deep learning model, images are pre-processed using technique proposed by Pasa et al. (2019). Pre-trained InceptionV3 deep learning model (Szegedy et al. 2016) is used for classifying COVID-19 and Non- COVID images. The acquired results have been assessed using well- known parameters such as area under the ROC curve, model loss, confusion matrix, and training accuracy. The proposed model accurately predicts the COVID- 19 CXRs images with an accuracy of 96% and CT scan images with an accuracy of 93%. Fig. 1 Representative chest X-ray images for healthy and COVID-19 patients Network Modeling Analysis in Health Informatics and Bioinformatics (2022) 11:39 1 3 Page 3 of 13 39 The proposed model is compared with other deep learn- ing models like VGG 16 (Visual Geometry Group) (Simonyan and Zisserman 2014) used by Panwar et al. (2020) for COVID-19 detection, by ResNet50V2 Model (He et al. 2016) and other existing deep learning models. It is found to be better in terms of accuracy and other performance parameters. A web application has been developed on the proposed model using JavaScript, which helps in detecting COVID -19 on the basis of uploaded CT scan or CXR image. 2 Related works Recently, machine learning methods and deep learning mod- els have gained popularity due to their promising results without human intervention. These models are automated, robust, accurate and helps in detecting and classifying dis- eases using medical images. Since the emergence of SARS- COVID-19, many deep learning models have been proposed, some of which are summarized in this Section. In Ahsan et al. (2020), Mulilayer Preceptron-Con- volutional Neural Network is proposed in which mixed data (CXRs images, numeric/categorical data) is used for COVID-19 diagnosis. In this model, various optimizers such as Stochastic gradient descent (Sgd), Adaptive learn- ing rate optimization algorithm (Adam), and Root mean square propagation (Rmsprop) are used both for a balanced and imbalanced data set. E. Luz et al. proposed Efficient- Net architecture (Luz et al. 2020) for COVID-19 screen- ing, which requires low computational power. The model is also evaluated for cross data set to assess its generalization power. In Ozturk et al. (2020), DarkCovidNet architecture is proposed in which 17 convolutional layers are used and different filtering is used in each layer. The model multi- classify between COVID-19, non-COVID and Pneumo- nia using CXRs raw images with an accuracy of 87.02%. However, the data set used is very small in size. Hemdan et al. proposed COVIDX-Net (Hemdan et al. 2020), a deep learning framework. The framework consists of seven dif- ferent deep convolutional neural network architectures to analyze the normalized intensity of CXRs to classify the image for COVID-19. In Narin et al. (2020), five pre-trained CNN (Convolutional Neural Network) architectures have been proposed. In the proposed model, three binary clas- sifications out of four classes, namely COVID-19, healthy, viral pneumonia and bacterial pneumonia are implemented. Among them, it is shown that ResNet50 provides the highest classification accuracy. Zhou et al. (2021) proposed an ensemble deep learning model in which three pretrained classifiers namely AlexNet, GoogleNet and ResNet are used on CT scan images. The ensemble classifier is obtained using the relative majority voting method. Chen et al. (2020) introduced a deep learn- ing algorithm which segments the multiple infected regions of COVID-19 CT scan images. The algorithm based on U net architecture makes use of aggregate residual trans- formations for the better feature representation. In the study conducted by Ni et al., a deep learning model is proposed in which three stages, namely abnormality detection, pulmo- nary lobe segmentation, and voxel segmentation are used for COVID-19 detection using CT scan images (Ni et al. 2020). In Rahimzadeh et al. (2021), feature pyramid net- work is applied along with ResNet50V2 model so that the model can be able to detect disease from the images with different resolutions. Song et al. (2021) proposed a deep learning architecture for CT scan images in which firstly, the main region of the lungs is extracted, then Details Rela- tion Extraction Neural network (DRENet) is designed to get the image-level predictions. In the third stage, image level scored results are aggregated for the prediction of COVID- 19 at a personal level. Many approaches have been proposed in the literature based on CNN, which helps in the quick diagnosis of COVID-19 and many other diseases (Ghaderzadeh and Asadi 2021; Hafeez et al. 2022; Saad et al. 2022). Each approach has its own pros and cons. We, hereby, present an extension of existing techniques for detecting COVID-19 using both CT scan and CXRs images. The presented model is light weight, therefore, a web application is also developed for the proposed model which gives a single platform to the end user for examining their both CT scan or CXR images for COVID-19. 3 Materials and methods 3.1 Data set and pre processing In this study, image data set has been acquired from the open source repository outsourced by Dr. Joseph Cohen and by Cohen et al. (2020); Zhao et al. (2020). This data source is constantly being furnished with new data generated by vari- ous bodies around the globe. The same dataset is utilized by many researchers for detecting and analyzing COVID-19 patients. At the time of this study 920 X-ray and 746 CT scan images have been used for analysis and data set is organized into two categories COVID-19 and non-COVID-19. Since the data set is formed by contributions from various sources, therefore, images are in a variety of sizes depend- ing upon the imaging equipment used. In this study, images have been resized to the square form before feeding to the model. Resizing may cause distortion of the image leading to suppression of useful data. In order to avoid distortion, a pre-processing technique proposed by Pasa et al. (2019) Network Modeling Analysis in Health Informatics and Bioinformatics (2022) 11:39 1 3 39 Page 4 of 13 is used for taking out the middle part and removing black bands. Fig. 2 depicts a pre-processed image to which the following operations have been applied: Black bars appearing at the borders are eliminated. The dimensions of the image are altered till the small- est border size becomes up to 224 pixels. Middle region of 224 X 224 X 3 pixels is extracted Further, all sets of images are normalized and dataset is transformed into Gaussian (normal) distribution N(0, 1), i.e, mean value =0 and variance value 2=1. After that, mean and standard deviation values are calculated for the dataset. Then whole data set (training, testing and valida- tion sets) is normalized by adding mean value and dividing by the calculated value of standard deviation. 3.1.1 Data augmentation Deep-learning models often present better results with a large set of images. Since data set used in the present study is less, therefore, data augmentation is used to produce more data based on the available training set. In this study, augmentation is performed by ; (1) Rotating image randomly within the range of 20 degrees (2) Performing image shifting in the range of around 20%. and (3) Horizontal flipping. Original X-ray image and image after augmentation is shown in Fig. 3 3.2 Proposed model Neural Networks (NN) have recently shown outstanding results over classical machine learning techniques with large, high dimensional and unstructured data containing all kinds of data such as text, image, categorical and numerical etc (Nakada and Imaizumi 2019). The emergence of Convolu- tional Neural Networks (CNN), a category of deep neural networks, has revolutionized artificial intelligence (Kriz- hevsky et al. 2012). The word deep means increase in the size of the network with increased number of layers and the convolutional word indicates that the network make use of mathematical operator convolution. A convolution net- work consists of three components convolution layer, pool- ing layer and output layer. Convolution layer extracts the features of the image such as colors, edges, etc. depending upon the problem in hand. Pooling layer helps in reducing the trainable features for making CNN computationally effi- cient. Output layer accomplishes the task of recognition or classification after getting an output of the convolution or pooling layer. CNN model is created by one or more fully connected layers. The deep NN provides an opportunity to develop a robust model, both for small and large data sets. Instead of devel- oping a model from scratch, existing proven deep learning model is used in the present study. To design our model, GoogLeNet InceptionV3 (Szegedy et al. 2016) network, the winner of the ImageNet Large Scale Visual Recogni- tion Competition (ILSVRC) in 2014 ( an image classifica- tion competition), is chosen. The inception network helps in increasing the accuracy and decreasing the computational effort by replacing the fully connected network (many layers in depth) by the sparsely connected network architecture. Naive version of inception module and with dimensionality reduction is shown in Fig. 4. In the naive version merging (a) original CXR image with COVID-19 ; (b) Pre-processed image in a square shape. Fig. 2 Pre-processing of the image Fig. 3 Image after data augmentation Network Modeling Analysis in Health Informatics and Bioinformatics (2022) 11:39 1 3 Page 5 of 13 39 of the output of the pooling layer with outputs of the convo- lutional layer leads to computational increase within a few stages while in dimensionality reduction 1 1 convolutions are used to compute reductions before the expensive 3 3 and 5 5 convolutions (Szegedy et al. 2015). Inception V3 is 48 layers deep and makes use of RMSprop optimizer, batch normalization and 7 7 factorized convolu- tion. The final proposed model is shown in Fig. 5 Algorithm 1 describes the proposed model in detail. In the algorithm, d is the transfer model InceptionV3. Transfer model is trained with the COVID-19 X-ray and CT scan images data set (X, Y) ; where X is the set of N input data, each of size, 224 height 224 width (Pre-processed image), and Y = { y y {COVID 19, Non COVID 19} . The size of the data set is increased using data augmentation and images are normalized. Further, the data set is divided into a training set (Xtrain;Ytrain) and test data in the ratio of 80:20, i.e, 80% training data and 20% test data, further, 10% of the test data is considered as validation data. is learn- ing rate that indicates that how fast a model accustoms to the problem. To process images, training data is partitioned into mini-batch of size n=32 such that (Xp;Yp) (Xtrain;Ytrain) ; p = 1, 2, 3 N n . The transfer model d is iteratively optimized to reduce the functional loss given in Eq. (1). where d(x, w) is the InceptionV3 model that outputs label y for given input x and weight w and c(.) is the binary entropy loss function. 3.3 Performance metrics The model is evaluated for the well know deep learning met- rics such as precision, recall and F1-score. These parameters are calculated on the basis of a confusion matrix which con- sists of the following parameters True Positive (TP) = COVID-19 Patient classified as a patient. True Negative (TN) = Healthy individual classified as healthy. (1) C(w, Xi) = 1 n x Xi,y Y c(d(x, w), y), Fig. 4 Inception module (Szegedy et al. 2015) a Naive version b With dimensionality reduction Fig. 5 Proposed deep learning model Network Modeling Analysis in Health Informatics and Bioinformatics (2022) 11:39 1 3 39 Page 6 of 13 False Positive (FP) = Healthy individual classified as patient. False Negative (FN) = COVID-19 Patient classified as healthy. The various deep learning metrics are calculated as: Sensitivity = TP TP+FN 100, Specificity = TN TN+FP 100, Precision = TP TP+FP 100, Accuracy = TP+TN TP+TN+FP+FN , F1 score = 2 Precision Sensitivity Precision+Sensitivity , where sensitivity is recall or true positive rate which measures how good the model is in predicting events in positive class. Specificity is true negative rate, i,e, frac- tion of actual negatives that are correctly recognized. Precision is that how apt the model is assigning positive events to the positive class. Accuracy means how much correct predictions have been done. F1 score is the har- monic mean of precision and recall. It shows the balance between precision and recall. ROC (Receiver Operator Characteristic) curve is a two- dimensional plot between true positive rate and true nega- tive rate. It indicates the trade-off between sensitivity and specificity. The ROC curve is measured by Area Under Curve (AUC). Its value lies between 0 and 1. ROC value close to 1 indicates high sensitivity and specificity. In the medical field, ROC curve analysis is done for exploring the performance of the diagnosis (Siddiqui et al. 2020). The AUC is found by the well-known trapezoidal rule in which area is divided into sections of equal width. Then sum of area of different sections is found just like integra- tion of points - (p, q) in a functional form in which points are divided into n equal parts such that x0 = p , xn = q , and xm = x0 + m( p q n ) Panwar et al. (2020). The sum of the area of different section under the trapezoid is given in Eq. 2, This is an effective method for calculating AUC under ROC. 4 Experimental results The introduced model is programmed using Python 3.6 programming language. For training the model, benefit of the free online Linux environment called Google Colabora- tory is availed (Bisong 2019). For finding the experimental results, we have used Intel i5 processor with 16GB RAM and HD 620 graphic unit. The dataset consists of around 920 chest X-ray images and 746 CT scan images for classifica- tion purposes. The images are classified into two classes COVID and Non-COVID. The data set is partitioned in 80:20 ratio with 80% training data and 20% test data. The InceptionV3 model consists of symmetric and asymmetric building blocks, including convolutions, max pooling, aver- age pooling, concatenations, dropouts, and fully connected layers. Batch normalization is applied rigorously throughout the model. Loss is computed using the Softmax function. The architecture of InceptionV3 is shown in following Fig. 6 The batch-wise processing of InceptionV3 model is described in the Table 1. The proposed model is trained for 500 epochs and learn- ing rate is set at 0.001. 4.1 Results CT scan Figures 7 and 8 represent the proposed model accuracy, loss for CT scan images. Figures 7 and 8 are complementary to each other. With increasing epoch, training and testing accuracy are increasing and loss is decreasing. Initially sharp lows and ups can be attributed to small data set, however, (2) T(p, q, n) = (p q n ) (f(p) f(q) 2 ) (f(p) f(p q) n ) . Fig. 6 Architecture of incep- tionV3 model (Szegedy et al. 2016) Network Modeling Analysis in Health Informatics and Bioinformatics (2022) 11:39 1 3 Page 7 of 13 39 as epochs progress these ups and downs are less and it converges. Figures 9 and 10 show the confusion matrix and model metrics for the proposed model. In the Figs. 9, 1 represents COVID positive case and 0 represents Non-COVID case. A good classification model should have balance between precision and sensitivity. Figure 9 shows that the pro- posed model is having true positive rate, i.e, sensitivity of 89.81% and specificity (true negative rate) of 96.84%. This signifies that COVID-19 in infected patient CT scan can be diagnosed with an error of 6.9%. F1 score of Fig. 10 shows the balance between sensitivity and specificity. The accuracy of the proposed model is 93% which surely will increase with the increased data. Figure 11 shows the ROC curve. The AUC under ROC curve in the Figure 11 is above the threshold value and calculated as 0.725. This value indicates a good rank of classification. Table 1 Batch-wise implementation of the proposed algorithm representing processing layer, produced output shape of image, number of parameters learned at the layer and input layer respectively) Network Modeling Analysis in Health Informatics and Bioinformatics (2022) 11:39 1 3 39 Page 8 of 13 4.2 Results CXRs Figures 12 and 13 represent the proposed model accu- racy, loss for CXRs images. Again, Figs. 12 and Fig. 13 are complementary to each other. As the number of epoch increase, training and testing accuracy is increasing and loss is decreasing. Initially in CXRs, lows and ups are more sharper as compared to CT scan images. This is due to the presence of outliers in the dataset. However, eventu- ally, as the model learns it converges. Figure 14 shows the confusion matrix for the proposed model of CXRs data. The accuracy of the proposed model for CXRs is 96%, which is more than that of CT scan images. This is due to the fact that in the present study CXR images are more that the CT scan images. Figure 15 shows that the proposed model for CXRs is having true positive rate, i.e, sensitivity of 93.48% and specificity (true negative rate) of 98.83%. This implies a person that is not infected with COVID can be detected with an error of 4%. Fig. 7 Model accuracy (with CT scan images) Fig. 8 Model loss with CT scan images Fig. 9 Confusion matrix CT scan images Fig. 10 Model metrics (CT scan, 1-COVID, 0-NonCOVID) Fig. 11 ROC curve (CT scan images) Network Modeling Analysis in Health Informatics and Bioinformatics (2022) 11:39 1 3 Page 9 of 13 39 F1 score value of 0.96 of the proposed model indicates a good classification model. Figure 16 shows ROC (Receiver Operator Characteris- tic) curve. The plotted AUC under the ROC curve is calcu- lated as 0.886 which is above a threshold value. The AUC value above the threshold value is considered as excellent in the field of medical diagnosis (Siddiqui et al. 2020; AS and Korsten 2007). Fig. 12 Proposed model accuracy (with CXRs) Fig. 13 Proposed model loss (with CXRs) Fig. 14 Confusion matrix (CXRs) Fig. 15 Performance metrics (CXRs, 1-COVID, 0-NonCOVID) Fig. 16 ROC curve (with CXRs) Fig. 17 Performance metrics VGG model (1-COVID, 0-NonCOVID) a CXRs b CT scan image Network Modeling Analysis in Health Informatics and Bioinformatics (2022) 11:39 1 3 39 Page 10 of 13 4.3 Result analysis To justify the results of the InceptionV3 model, the pro- posed model is also implemented with other deep learn- ing models such as VGG 16 (Litjens et al. 2017) and ResNet50V2 (Residual Networks) model (He et al. 2016). The VGG 16 model has been used in Simonyan and Zisser- man (2014) for COVID -19 detection using CXR images. Performance metrics of these models are shown in Figs. 17 and 18 for CXRs and CT scan images respectively. From Figs. 10, 15, 17 and 18, it can be concluded that, Incep- tionV3 model has more balanced precision and recall than other models. Table 2 shows the tabular comparison of their accuracy. Table 2 indicates that InceptionV3 performs bet- ter and it is computationally efficient because of its dimen- sionality reduction feature. From Table 2, it is clear that the proposed model extracts the important features from the images in an efficient way as compared to other CNN models. Further, the proposed model is compared with existing models and tabular comparison of their accuracy is shown in Table 3 for CXRs and Table 4 for the CT scan images respectively. Table 3 shows that the proposed model works better than nCOVnet (Simonyan and Zisserman 2014) and CoroNet (Khan et al. 2020) in terms of accuracy. The nCOVnet model utilizes VGG16 (Litjens et al. 2017), and the CoroNet deep learning model makes use of pre-trained Xception architecture (Litjens et al. 2017). The accuracy of deep learning depends upon the size of the dataset. Larger the dataset, more the accuracy. In this regard, the proposed model performs a little better than nCOVnet model and significantly better than CoroNet model. Table 4 indicates that the proposed model performs better than the Ctnet-10 model (Shah et al. 2021) and the model proposed by Wu et al. (2020) for CT scan images. The Ctnet-10 model is self- developed model and model proposed by Wu et al. makes use of ResNet50 (He et al. 2016). This improvement can be attributed to the fact that dataset size is increased via data augmentation. From the obtained results, it is observed that the proposed model can provide a better replacement for the RT-PCR test which takes 4 to 8 hours for revealing out the result. As far as the complexity of the proposed model is con- cerned, the InceptionV3 model uses less trainable param- eters as compared to VGG 16 and ResNet50 deep learning models. Error rate of InceptionV3 is less as compared to other deep learning models (Alzubaidi et al. 2021). Moreo- ver, the InceptionV3 model makes use of dimensionality reduction, 1 1 convolutions are used to compute reduc- tions before the expensive 3 3 and 5 5 convolutions Fig. 18 Performance metrics for ResNet model (1-COVID, 0-Non- COVID) a CXRs b CT scan images Table 2 Result comparison Model Accuracy %age (CXRs) Accuracy %age(CT Scan Images) Inception V3 96 93 VGG16 89 86 ResNet50V2 75 49 Table 3 Comparison with other methods(CXRs) Model Population Dataset Used %age Accuracy nCOVnet Simonyan and Zis- serman (2014) 337 Open source Cohen et al. (2020) 88.10 CoroNet Khan et al. (2020) 1300 Open source Cohen et al. (2020) and https:// www. kaggle. com/ pault imoth ymoon ey/ chest- xray- pneum onia 89.60 Proposed Model 920 Open source Cohen et al. (2020) 96.00 Table 4 Comparsion with other methods (CT scan) Model Population Dataset Used %age Accuracy Wu et al. (2020) 495 Private dataset 81.90 Ctnet-10 Shah et al. (2021) 738 Open Source Zhao et al. (2020) 82.1 Proposed Model 746 Open source Zhao et al. (2020) 93.00 Network Modeling Analysis in Health Informatics and Bioinformatics (2022) 11:39 1 3 Page 11 of 13 39 which makes it more computationally efficient (Szegedy et al. 2015). 4.4 Real time implementation The benchmark for COVID-19 diagnosis is the RT-PCR test. However, increase in false positive results of the RT- PCR test caused missed infections, which in turn increase the chances of transmission. Sensitivity of RT-PCR depends on a number of factors such as the time span of symptoms, severity of viral infection, the speed of virus reproduction in the respiratory system, the time when the sample taken and the quality of the test process. To overcome this limitation, for a quick diagnosis of COVID-19, a Web application using JavaScript (Smilkov et al. 2019) and Cascading Style Sheets (CSS) is developed. The proposed deep learning model is exported into the JavaScript and used for the development of web application. In this application, user will upload its CT scan or CXR image and would be able to find the results within a fraction of seconds. Fig. 19 shows the user interface and detection results. The limitation of this web application is that when images are not vivid and have a bad orientation in terms of vis- ibility of the frontal part of the human lungs, then there is a decrease in the accuracy of correct analysis for coronavirus. 5 Discussion Artificial Intelligence (AI) based systems play a major role in early detection of COVID-19 and for finding the severity of the disease. In this study, we have proposed a lightweight deep learning model which makes use of Pre-trained CNN IncetptionV3. This model has been applied on CXRs and CT scan images. The performance of deep learning mod- els depends upon the large dataset. These images were pre- processed using the technique proposed by Pasa et al. (2019) before feeding into the model. The major challenge in this study was the lack of a large COVID -19 dataset. To over- come this challenge, image augmentation has been done. In image augmentation, images are artificially generated using shifting, flipping and rotation. The obtained dataset is fur- ther partitioned into training and test data set in the ratio of 80:20 respectively. In order to train the model, pre-trained InceptionV3 model (Szegedy et al. 2016) is utilized. The introduced model is implemented using Python 3.6 program- ming language. The model shows an accuracy of 93% and precision of 97% for the CT scan images. For CXR images, it shows an accuracy of 96% and precision of 99%. Table 2 shows the accuracy comparison of the proposed model with other deep learning models VGG16 and ResNet50V2 both for CXR and CT scan images . The proposed model performs better than the VGG 16 model and ResNet50V2 model. This due to the fact that the InceptionV3 model used in the proposed model has a low error rate, uses less trainable parameters and make use of the dimensionality reduction feature. Further, Table 3 and Table 4 show the accuracy comparison of the proposed model with other related studies for CXR and CT scan images respectively. Table 3 shows that the proposed model is little better in terms of accuracy than the existing nCOV- net model (Simonyan and Zisserman 2014) from the datasize point of view. However, it is significantly better than Coro- Net model (Khan et al. 2020) for CXR images even though the dataset size of CoroNet model is larger than the datasize used in the present study. It also shows better performance than Ctnet-10 (Shah et al. 2021) and model proposed by Wu et al. (2020) for CT scan images. These results will definitely improve with the increased dataset. From Table 3 and IV, it is clear that the proposed model learned the COVID-19 infections very well leading to fewer false detections. More- over, existing models are more complex than the proposed model due to the small filter size used in InceptionV3 model. Since the proposed model is lightweight, a web application has been developed by exporting the model into JavaScript. In this web application, users have to upload their CT scan or CXR image and will get results in a fraction of seconds. The benefits of the proposed model are less complex, more accu- racy, less memory requirements, computationally efficient (a) User Interface (b) Detection Results Fig. 19 Web application for the proposed deep learning model Network Modeling Analysis in Health Informatics and Bioinformatics (2022) 11:39 1 3 39 Page 12 of 13 and provides a single solution both for CXRs and CT scan images which makes it apt for mobile and laptops. However, the developed web application shows a decrease in accuracy if the images are not properly oriented in terms of the frontal part of the human lungs. The limitation of this study is the lack of a large dataset and computational resources as the open source Google Colab platform has been used for implementation. Fur- ther, COVID-19 lungs images look alike Pneumonia lungs images. This study can be extended for the 3-class clas- sification, i.e, COVID-19 Vs. Pneumonia Vs. Normal or multi-class classification considering other types of pneu- monia and pathogens. The proposed model can be made more accurate, robust and fast with the large dataset. 6 Conclusion and future scope The best and proven way of controlling the COVID-19 pandemic is social distancing and rigorous testing. There are no specific symptoms for the infected patient. Moreo- ver, it takes 4-10 days for getting specific symptoms such as flu, fever, headache, etc. Majorly, two types of tests are conducted worldwide, i.e, RT-PCR test and antibody test. The antibody test is too much slow to control pan- demic and RT-PCR test also has its own limitations and sometimes gives false positive results. CT scans and CXRs are the most fast and efficient diagnosis approach. How- ever, there are no specific quantified diagnosis criteria and dearth of experienced radiologists too. Therefore, the need arises for an automated decision-making tool based on artificial intelligence. In this study, a deep learning model is proposed which helps in detecting and classifying COVID-19 cases using the CXRs and CT scan images. The model is fully auto- mated and able to detect COVID-19 cases without human intervention. The developed model detects COVID-19 with an accuracy of 93% and 96% for CT scan and CXRs images respectively. Surely, this accuracy will increase with the increased number of samples. The model is also found to be more accurate, with less computing complex- ity than well-known deep learning model like VGG 16, ResNet50V2 and other existing deep learning models. The developed web application can detect COVID -19 within a fraction of seconds which will definitely help both pub- lic and radiologists. The web application of this model provides a single platform for both CXRs and CT scan images. In the future, we intend to make model more robust, accurate and fast with large set of images. Since it is dif- ficult to distinguish between CT manifestations of COVID- 19 pneumonia from the classic pneumonia due to overlap. Therefore, this work can be extended for the multi-class classification considering COVID-19 pneumonia, viral pneumonia, bacterial pneumonia and normal images. Further, the proposed model can be made more accurate, robust and fast with the large dataset. Declarations Conflict of interest We hereby confirm that there is no conflict of inter- est related to this manuscript and no financial funds has been received for this work from any organization which can influence the results. References Ahsan MM, Alam TE, Trafalis T, Huebner P (2020) Deep mlp-cnn model using mixed-data to distinguish between covid-19 and non- covid-19 patients. Symmetry 12(9):1526 Alzubaidi L, Zhang J, Humaidi AJ, Al-Dujaili A, Duan Y, Al-Shamma O, Santamar a J, Fadhel MA, Al-Amidie M, Farhan L (2021) Review of deep learning: Concepts, cnn architectures, challenges, applications, future directions. J Big Data 8(1):1 74 Araujo-Filho JA, Sawamura MV, Costa AN, Cerri GG, Nomura CH (2020) COVID-19 pneumonia: what is the role of imaging in diag- nosis? J Bras Pneumol 46(2):e20200114 AS R, Korsten M (2007) Application of summary receiver operat- ing characteristics (sroc) analysis to diagnostic clinical testing. 7 Reflect Fut Gastroenterol 52:76 Bernheim A, Mei X, Huang M, Yang Y, Fayad Z A, Zhang N, Diao K, Lin B, Zhu X, Li K et al. (2020) Chest ct findings in corona- virus disease-19 (covid-19): relationship to duration of infection. Radiology 200463 Bisong E (2019) Google colaboratory, in Building Machine Learning and Deep Learning Models on Google Cloud Platform. Springer, pp 59 64 Chen X, Yao L, Zhang Y (2020) Residual attention u-net for automated multi-class segmentation of covid-19 chest ct images. arXiv pre- print arXiv: 2004. 05645 Chest x-ray images (penumonia). https://www.kaggle.com/ paultimothymooney/chest-xray-pneumonia Cohen JP, Morrison P, Dao L, Roth K, Duong TQ, Ghassemi M (2020) Covid-19 image data collection: prospective predictions are the future. arXiv: 2006. 11988 Corman VM, Landt O, Kaiser M, Molenkamp R, Meijer A, Chu DK, Bleicker T, Br nink S, Schneider J, Schmidt ML et al (2020) Detection of 2019 novel coronavirus (2019-ncov) by real-time rt-pcr. Eurosurveillance 25(3):2000045 Faust O, Hagiwara Y, Hong TJ, Lih OS, Acharya UR (2018) Deep learning for healthcare applications based on physiological sig- nals: A review. Comput Methods Programs Biomed 161:1 13 Ghaderzadeh M, Asadi F (2021) Deep learning in the detection and diagnosis of covid-19 using radiology modalities: a systematic review. J Healthc Eng 2021 Green K, Winter A, Dickinson R, Graziadio S, Wolff R, Mallett S, Allen AJ (2020) What tests could potentially be used for the screening, diagnosis and monitoring of covid-19 and what are their advantages and disadvantages. CEBM 2020:13 Hafeez U, Umer M, Hameed A, Mustafa H, Sohaib A, Nappi M, Madni HA (2022) A CNN based coronavirus disease prediction system for chest X-rays. J Ambient Intell Humanized Comput https:// doi. org/ 10. 1007/ s12652- 022- 03775-3 Network Modeling Analysis in Health Informatics and Bioinformatics (2022) 11:39 1 3 Page 13 of 13 39 Hemdan EE-D, Shouman MA, Karar ME (2020) Covidx-net: a frame- work of deep learning classifiers to diagnose covid-19 in x-ray images. arXiv preprint arXiv: 2003. 11055 He K, Zhang X, Ren S, Sun J (2016) Deep residual learning for image recognition. In: Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770 778 Huang C, Wang Y, Li X, Ren L, Zhao J, Hu Y, Zhang L, Fan G, Xu J, Gu X et al (2020) Clinical features of patients infected with 2019 novel coronavirus in Wuhan, China. Lancet 395(10223):497 506 Kanne JP, Chest CT (2020) Findings in 2019 novel coronavirus (2019- nCoV) infections from Wuhan, China: key points for the radiolo- gist. Radiology 295(1):16 17 Khan AI, Shah JL, Bhat MM (2020) Coronet: A deep neural network for detection and diagnosis of covid-19 from chest x-ray images. Comput Methods Programs Biomed 196:105581 Krizhevsky A, Sutskever I, Hinton GE (2012) Imagenet classification with deep convolutional neural networks. Adv Neural Inf Process Syst 25:1097 1105 Lee EY, Ng M-Y, Khong P-L (2020) Covid-19 pneumonia: what has ct taught us? Lancet Infect Dis 20(4):384 385 Litjens G, Kooi T, Bejnordi BE, Setio AAA, Ciompi F, Ghafoorian M, Van Der Laak JA, Van Ginneken B, S nchez CI (2017) A survey on deep learning in medical image analysis. Med Image Anal 42:60 88 Luz E, Silva PL, Silva R, Silva L, Moreira G, Menotti D (2020) Towards an effective and efficient deep learning model for covid- 19 patterns detection in x-ray images. arXiv preprint arXiv: 2004. 05717 Nakada R, Imaizumi M (2019) Adaptive approximation and estima- tion of deep neural network with intrinsic dimensionality. arXiv preprint arXiv: 1907. 02177 Narin A, Kaya C, Pamuk Z (2020) Automatic detection of coronavirus disease (covid-19) using x-ray images and deep convolutional neural networks. arXiv preprint arXiv: 2003. 10849 Ni Q, Sun ZY, Qi L, Chen W, Yang Y, Wang L, Zhang X, Yang L, Fang Y, Xing Z et al (2020) A deep learning approach to character- ize 2019 coronavirus disease (covid-19) pneumonia in chest ct images. Eur Radiol 30(12):6517 6527 Ozturk T, Talo M, Yildirim EA, Baloglu UB, Yildirim O, Acharya UR (2020) Automated detection of covid-19 cases using deep neural networks with x-ray images. Comput Biol Med 121:103792 Panwar H, Gupta P, Siddiqui MK, Morales-Menendez R, Singh V (2020) Application of deep learning for fast detection of covid- 19 in x-rays using ncovnet. Chaos Solitons Fractals 138:109944 Pasa F, Golkov V, Pfeiffer F, Cremers D, Pfeiffer D (2019) Efficient deep network architectures for fast chest x-ray tuberculosis screen- ing and visualization. Sci Rep 9(1):1 9 Rahimzadeh M, Attar A, Sakhaei SM (2021) A fully automated deep learning-based network for detecting covid-19 from a new and large lung ct scan dataset. Biomed Signal Process Control 68:102588 Saad W, Shalaby WA, Shokair M, El-Samie FA, Dessouky M, Abdellatef E (2022) Covid-19 classification using deep feature concatenation technique. J Ambient Intell Humaniz Comput 13(4):2025 2043 Shah V, Keniya R, Shridharani A, Punjabi M, Shah J, Mehendale N (2021) Diagnosis of covid-19 using ct scan images and deep learn- ing techniques. Emerg Radiol 28(3):497 505 Shen D, Wu G, Suk H-I (2017) Deep learning in medical image analy- sis. Annu Rev Biomed Eng 19:221 248 Siddiqui MK, Morales-Menendez R, Ahmad S (2020) Application of receiver operating characteristics (roc) on the prediction of obe- sity. Braz Archives Biol Technol 63 Simonyan K, Zisserman A (2014) Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv: 1409. 1556 Singhal T (2020) A review of coronavirus disease-2019 (covid-19). Indian J Pediatrics 87(4):281 286 Smilkov D, Thorat N, Assogba Y, Yuan A, Kreeger N, Yu P, Zhang K, Cai S, Nielsen E, Soergel D et al. (2019) Tensorflow. js: machine learning for the web and beyond. arXiv preprint arXiv: 1901. 05350 Song Y, Zheng S, Li L, Zhang X, Zhang X, Huang Z, Chen J, Wang R, Zhao H, Chong Y, Shen J (2021) Deep learning enables accu- rate diagnosis of novel coronavirus (COVID-19) with CT images. IEEE/ACM Trans Comput Biol Bioinform 18(6):2775 2780 Sriwijitalai W, Wiwanitkit V (2020) Cost-utility analysis for chest ct versus rt-pcr for covid-19 detection. Int J Prev Med 11(6):11 67 Szegedy C, Wei L, Yangqing J, Pierre S, Scott R, Dragomir A, Dumitru E, Vincent V, Andrew R (2015) Going deeper with convolutions. In: Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 1 9 Szegedy C, Vanhoucke V, Ioffe S, Shlens J, Wojna Z (2016) Rethinking the inception architecture for computer vision. In: Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 2818 2826 Tartaglione E, Barbano CA, Berzovini C, Calandri M, Grangetto M (2020) Unveiling covid-19 from chest x-ray with deep learning: a hurdles race with small data. Int J Environ Res Public Health 17(18):6933 Who coronavirus (covid-19) dashboard (2021) Wu F, Zhao S, Yu B, Chen Y-M, Wang W, Song Z-G, Hu Y, Tao Z-W, Tian J-H, Pei Y-Y et al (2020a) A new coronavirus associated with human respiratory disease in China. Nature 579(7798):265 269 Wu X, Hui H, Niu M, Li L, Wang L, He B, Yang X, Li L, Li H, Tian J et al (2020b) Deep learning-based multi-view fusion model for screening 2019 novel coronavirus pneumonia: a multicentre study. Eur J Radiol 128:109041 Zhao W, Zhong Z, Xie X, Yu Q, Liu J (2020a) Relation between chest ct findings and clinical conditions of coronavirus disease (covid-19) pneumonia: a multicenter study. Am J Roentgenol 214(5):1072 1077 Zhao J, Zhang Y, He X, Xie P (2020b) Covid-ct-dataset: a ct scan dataset about covid-19. arXiv preprint arXiv: 2003. 13865 Zhou T, Lu H, Yang Z, Qiu S, Huo B, Dong Y (2021) The ensemble deep learning model for novel covid-19 on ct images. Appl Soft Comput 98:106885 Publisher's Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Springer Nature or its licensor holds exclusive rights to this article under a publishing agreement with the author(s) or other rightsholder(s); author self-archiving of the accepted manuscript version of this article is solely governed by the terms of such publishing agreement and applicable law.