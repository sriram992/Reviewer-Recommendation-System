Memetic Comp. (2013) 5:213 227 DOI 10.1007/s12293-012-0104-0 REGULAR RESEARCH PAPER Opposition based l vy ight arti cial bee colony Harish Sharma Jagdish Chand Bansal K. V. Arya Received: 20 July 2012 / Accepted: 30 November 2012 / Published online: 13 December 2012 Springer-Verlag Berlin Heidelberg 2012 Abstract Arti cial Bee Colony (ABC) is a well known optimization approach to solve nonlinear and complex prob- lems. It is relatively a simple and recent population based probabilistic approach for global optimization. Similar to other population based algorithms, ABC is also computa- tionally expensive due to its slow nature of search process. The solution search equation of ABC is signi cantly in u- enced by a random quantity which helps in exploration at the cost of exploitation of the search space. In the solution search equation of ABC due to the large step size the chance of skipping the true solution is high. Therefore, in this paper, to balance the diversity and convergence capability of the ABC, L vy Flight random walk based local search strategy is proposed and incorporated with ABC along with opposition based learning strategy. The proposed algorithm is named as Opposition Based L vy Flight ABC. The experiments over 14 un-biased test problems of different complexities and ve well known engineering optimization problems show that the proposed algorithm outperforms the basic ABC and its recent variants namely Gbest guided ABC, Best-So-Far ABC, and Modi ed ABC in most of the experiments. Keywords Swarm intelligence Evolutionary computation Memetic algorithm L vy ight local search H. Sharma (B) K. V. Arya ABV-Indian Institute of Information Technology and Management, Gwalior, India e-mail: harish.sharma0107@gmail.com K. V. Arya e-mail: kvarya@gmail.com J. C. Bansal South Asian University, New Delhi, India e-mail: jcbansal@sau.ac.in 1 Introduction Swarm Intelligence has become an emerging and interesting area in the eld of nature inspired techniques that is used to solve optimization problems during the past decade. It is based on the collective behavior of social creatures. Swarm based optimization algorithms nd solution by collaborative trial and error. Social creatures utilize their ability of social learning to solve complex tasks. Peer to peer learning behav- ior of social colonies is the main driving force behind the development of many ef cient swarm based optimization algorithms. Researchers have analyzed such behaviors and designed algorithms that can be used to solve nonlinear, non- convex or discrete optimization problems. Previous research [8,16,22,32] have shown that algorithms based on swarm intelligencehavegreatpotentialto ndsolutionsofrealworld optimization problems. The algorithms that have emerged in recent years include ant colony optimization (ACO) [8], particle swarm optimization (PSO) [16], bacterial foraging optimization (BFO) [20] etc. Arti cial bee colony (ABC) optimization algorithm intro- duced by Karaboga [13] is a recent addition in this category. This algorithm is inspired by the behavior of honey bees when seeking a quality food source. Like any other popula- tion based optimization algorithm, ABC consists of a popu- lation of potential solutions. The potential solutions are food sources of honey bees. The tness is determined in terms of the quality (nectar amount) of the food source. ABC is rela- tively a simple, fast and population based stochastic search technique in the eld of nature inspired algorithms. There are two fundamental processes which drive the swarm to update in ABC: the variation process, which enables exploring different areas of the search space, and the selection process, which ensures the exploitation of the pre- vious experience. However, it has been shown that the ABC 123 214 Memetic Comp. (2013) 5:213 227 mayoccasionallystopproceedingtowardtheglobaloptimum even though the population has not converged to a local opti- mum[14].Itcanbeobservedthatthesolutionsearchequation of ABC algorithm is good at exploration but poor at exploita- tion [38]. Therefore, to maintain the proper balance between exploration and exploitation behavior of ABC, it is highly required to develop a local search approach in the basic ABC to exploit the search region. In past, very few efforts have been done in this direction. Kang et al. [12] proposed a Hooke Jeeves Arti cial Bee Colony algorithm (HJABC) for numer- ical optimization. In HJABC, authors incorporated a local search technique which is based on Hooke Jeeves method (HJ) [11] with the basic ABC. Further, Mezura-Montes and Velez-Koeppel [18] introduced a variant of the basic ABC named Elitist Arti cial Bee Colony. In this work, the authors integrated two local search strategies. The rst local search strategy is used when 30, 40, 50, 60, 70, 80, 90, 95 and 97% of function evaluations have been completed. The purpose of this is to improve the best solution achieved so far by gen- erating a set of 1000 new food sources in its neighborhood. The other local search works when 45, 50, 55, 80, 82, 84, 86, 88, 90, 91,92, 93, 94, 95, 96, 97, 98, and 99% of function evaluations have been reached. In this paper, L vy Flight random walk based local search strategy is proposed. The proposed local search strategy is used for nding the global optima of a unimodal and/or multi- modelfunctionsbyiterativelyreducingthestepsizetoupdate the candidate solution in the search space inside which the optima is known to be exist. Further, to balance the diversity and convergence capability of ABC, the concept of opposi- tion based learning (OBL) [31] is taken into consideration. The same concept has been applied in Differential Evolution (DE) [22] optimization algorithm to improve its convergence speed [24]. The main concept behind OBL is the simultane- ousconsiderationofasolutionanditscorrespondingopposite counter part in order to nd out a better approximation for the current candidate solution. The quality of the solution is measures on the basis of its distance form the global optima. On the basis of probability theory, it can be easily state that there is 50% chance for an opposite counter part solution to be nearer to the global optima. Therefore, in this paper, the concept of OBL and the proposed local search strategy are integrated with the basic ABC. Further, the proposed algo- rithm is compared by experimenting on 14 un-biased test problems (i.e. the problems which solutions do not exist on origin, axes or diagonal) and ve popular engineering opti- mization problems to the basic ABC and its recent variants named, Gbest guided ABC (G ABC) [38], Best-So-Far ABC (BSF ABC) [3] and Modi ed ABC (M ABC) [1]. Rest of the paper is organized as follows: Sect. 2 describes brief overview of the basic ABC. L vy Flight local search strategy is proposed in Sect. 3. In Sect. 4, concept of oppo- sition based learning is described. Opposition Based L vy Flight ABC (OBLFABC) is proposed and tested in Sect. 5. In Sect. 6, a comprehensive set of experimental results are provided. Finally, in Sect. 7, paper is concluded. 2 Arti cial bee colony (ABC) algorithm The ABC algorithm is relatively recent swarm intelligence based algorithm. The algorithm is inspired by the intelli- gent food foraging behavior of honey bees. In ABC, each solution of the problem is called food source of honey bees. The tness is determined in terms of the quality of the food source. In ABC, honey bees are classi ed into three groups namely employed bees, onlooker bees and scout bees. The number of employed bees are equal to the onlooker bees. The employed bees are the bees which searches the food source and gather the information about the quality of the food source. Onlooker bees stay in the hive and search the food sources on the basis of the information gathered by the employed bees. The scout bee, searches new food sources randomly in places of the abandoned foods sources. Similar to the other population-based algorithms, ABC solu- tion search process is an iterative process. After, initialization of the ABC parameters and swarm, it requires the repetitive iterations of the three phases namely employed bee phase, onlooker bee phase and scout bee phase. Each of the phase is described as follows: 2.1 Initialization of the swarm The parameters for the ABC are, number of food sources, number trials after which a food source is considered to be abandoned and termination criteria. In the basic ABC, the number of food sources are equal to the employed bees or onlooker bees. Initially, a uniformly distributed ini- tial swarm of SN food sources where each food source xi(i = 1, 2, . . . , SN) is a D-dimensional vector, generated. Here D is a number of variables in the optimization problem and xi represent the ith food source in the swarm. Each food source is generated as follows: xi j = xminj + rand[0, 1](xmax j xminj) (1) where xminj and xmax j are bounds of xi in jth direction and rand[0, 1] is a uniformly distributed random number in the range [0, 1] 2.2 Employed bee phase In employed bee phase, employed bees modify the current solution (food source) based on the information of individual experience and the tness value of the new solution. If the tness value of the new solution is higher than that of the old solution, the bee updates her position with the new one 123 Memetic Comp. (2013) 5:213 227 215 and discards the old one. The position update equation for ith candidate in this phase is vi j = xi j + i j(xi j xkj) (2) where k {1, 2, . . . , SN} and j {1, 2, . . . , D} are ran- domly chosen indices. k must be different from i. i j is a random number between [ 1, 1]. 2.3 Onlooker bees phase After completion of the employed bees phase, the onlooker bees phase starts. In onlooker bees phase, all the employed bees share the new tness information (nectar) of the new solutions (food sources) and their position information with the onlooker bees in the hive. Onlooker bees analyze the available information and select a solution with a probability probi related to its tness. The probability probi may be calculated using following expression (there may be some other but must be a function of tness): probi = f itnessi SN i=1 f itnessi (3) where f itnessi is the tness value of the solution i. As in the case of the employed bee, it produces a modi cation on the position in its memory and checks the tness of the candidate source. If the tness is higher than that of the previous one, the bee memorizes the new position and forgets the old one. 2.4 Scout bees phase If the position of a food source is not updated up to a prede- termined number of cycles, then the food source is assumed to be abandoned and scout bees phase starts. In this phase the bee associated with the abandoned food source becomes scout bee and the food source is replaced by a randomly chosen food source within the search space. In ABC, pre- determined number of cycles is a crucial control parameter which is called limit for abandonment. Assume that the abandoned source is xi. The scout bee replaces this food source by a randomly chosen food source which is generated as follows xi j = xminj + rand[0, 1](xmax j xminj), for j {1, 2, . . . , D} (4) where xminj and xmax j are bounds of xi in jth direction. 2.5 Main steps of the ABC algorithm Based on the above explanation, it is clear that there are three control parameters in ABC search process: The number of food sources SN (equal to number of onlooker or employed bees), the value of limit and the maximum number of itera- tions. The pseudo-code of the ABC is shown in Algorithm 1 [14]: 3 L vy ight local search Local search algorithms can be seen as a population based stochastic algorithms, where main task is to exploit the avail- able knowledge about a problem. Generally, in local search algorithms some or all individuals in the population are improved by some local search method. Local search algo- rithms are basically designed to incorporate a local search strategy between iterations of a population based search algo- rithm. In this way, the population based global search algo- rithms are hybridized with local search algorithms and the hybridized algorithms named as memetic algorithms. In memetic algorithms, the global search capability of the main algorithm explore the search space, trying to identify the most promising search space regions while the local search part scrutinizes the surroundings of some initial solutions, exploiting it in this way. In this paper, we are proposing a local search strategy inspired by L vy Flight random walk and named L vy Flight local search (LFLS). In past, the ight behavior of many animals and insects has been analyzed in various stud- ies which exhibit the important properties of L vy ights [4,21,25,35]. Further, this ight behavior has been applied to optimization and search algorithms, and the reported results show its importance in the eld of solution search algo- rithms [21,25,27,28]. Recently, Xin-She Yang proposed a new metaheuristic algorithm by combining L vy ights with the search strategy via the Fire y Algorithm [36]. The L vy Flight is a random walk in which the steps are de ned in terms of the step-lengths, which have a certain probability distribution. The random step lengths are drawn from a L vy distribution which is de ned in Eq. (5): L(s) |s| 1 , where (0 < 2) is an index and s is the step length. (5) In this paper, a Mantegna algorithm [37] for a symmet- ric L vy stable distribution is used for generating random step sizes. Here symmetric means that the step size may be positive or negative. 123 216 Memetic Comp. (2013) 5:213 227 In Mantega s algorithm, the step length s can be calculated by s = u |v|1/ , (6) where, u and v are drawn from normal distributions. That is u N(0, u2), v N(0, v2) (7) where, u =  (1 + )sin( /2) [(1 + )/2]2( 1)/2 1/ , v = 1. (8) This distribution (for s) obeys the expected l vy distribution for |s| |s0|, where s0 is the smallest step length [37]. Here (.) is the Gamma function and calculated as follows: (1 + ) =  0 t e tdt. (9) In a special case when is an integer, then we have (1 + ) = !. In the proposed strategy, the step sizes are generated using l vy distribution to exploit the search area and calculated as follows: step_size(t) = 0.001 s(t) SLC, (10) here t is the iteration counter for local search strategy, s(t) is calculated using l vy distribution as shown in Eq. (6) and SLC is the social learning component of the global search algorithm. In Levy ights, the step sizes are too aggressive, that is, they may generate new solutions often outside the domain or on boundary. Since, the local search algorithms can be seen as a population based stochastic algorithms, where main task is to exploit the available knowledge about a problem and steps sizes play an important role in exploiting the identi ed region. Therefore, 0.001 multiplier is used in Eq. (10) to reduce the step size. The solution update equation of an ith individual, based on the proposed local search strategy is given in Eq. (11): x i j(t + 1) = xi j(t) + step_size(t) U(0, 1), (11) here xi j istheindividualwhichisgoingtomodifyitsposition, U(0, 1) is a uniformly distributed random number between 0 and 1 and step_size(t) U(0, 1) is the actual random walks or ights drawn from l vy distribution. The pseudo-code of the proposed LFLS is shown in Algorithm 2. In Algorithm 2, determines the termination of local search. 4 Opposition based learning (OBL) Nature inspired algorithms (NIAs) start searching of the global optima randomly and all the individual randomly ini- tialized in the given search space. Further, the individuals update their positions based on self intelligence and social learning and move towards the optimum solution or required solution. NIAs are iterative and stochastic in nature and solu- tion search process terminates when some prede ned criteria is satis ed. The performance of the algorithms are measured in terms of computational complexity which is directly pro- portionate to the number of objective function evaluations to be optimized. Researchers are continuously working to improve the performance of NIAs in terms of computa- tional complexity. Rahnamayan et al. [24] proposed oppo- sition based differential evolution (OBDE) to improve the convergence rate of DE which was based on the theory of opposite-based learning (OBL). The concept of OBL was introduced by Tizhoosh [31]. The same concept can also be applied in ABC to improve the convergence speed. If the ran- domized initialized solutions are near to the global optima then the required solution can be found in less computational efforts but if the solutions are very far form the optima then it takes high computational cost or may be some time infeasi- ble to track the required solution. As suggested by Tizhoosh [31] and further by Rahnamayan et al. [24], the computa- tional cost can be reduced by applying the concept of OBL. In OBL we consider the better solutions as well as their oppo- site counter part solutions and combined them, then we apply greedy approach to nd the ttest solutions among them. We judgethesolutiononthebasisofits tnessinrespecttoglobal optima. Let x be a solution and x is its opposite solution in the search space. On the basis of probability theory, we can say that there is 50% chance that the opposite solution may be tter. The concept of OBL can be de ned as follows [31]: De nition 1 (Opposite Number) Let x be a real number de ned on a certain interval: x [a, b]. The opposite number x is de ned as follows x = a + b x 123 Memetic Comp. (2013) 5:213 227 217 For the higher dimensions, the above de nition can be extended as follows [24,31]: De nition 2 (Opposite Point) Let P(x1, x2, . . . , xD) be a point in a D-dimensional coordinate system with x1, . . . , xD and xi [ai, bi]. The opposite point P is completely de ned by its coordinates x1, . . . , xD where xi = ai + bi xi, i = 1, . . . , D. On the basis of the De nition 2, an Opposition Based Optimization Method (O BOM) has been developed [24]. The pseudo code of the O BOM is shown in Algorithm 3: 5 Opposition based l vy ight ABC (OBLFABC) Exploration and exploitation are the two important char- acteristics of the population-based optimization algorithms such as GA [10], PSO [16], DE [29], BFO [20] and so on. In these optimization algorithms, the exploration refers to the ability to investigate the various unknown regions in the solution space to discover the global optimum. While, the exploitation refers to the ability to apply the knowledge of the previous good solutions to nd better solutions. In prac- tice, the exploration and exploitation contradict with each other, and in order to achieve better optimization perfor- mance, the two abilities should be well balanced. Dervis Karaboga and Bahriye Akay [14] tested different variants of ABC for global optimization and found that the ABC shows poor performance and remains inef cient in explor- ing the search space. In ABC, any potential solution updates itself using the information provided by a randomly selected potential solution within the current swarm. In this process, a step size which is a linear combination of a random num- ber i j [ 1, 1], current solution and a randomly selected solution are used. Now the quality of the updated solution highly depends upon this step size. If the step size is too large, which may occur if the difference of current solution and randomly selected solution is large with high absolute value of i j, then updated solution can surpass the true solu- tion and if this step size is too small then the convergence rate of ABC may signi cantly decrease. A proper balance of this step size can balance the exploration and exploitation capability of the ABC simultaneously. But, since this step size consists of random component so the balance can not be done manually. Therefore, in this paper, to balance the diver- sity and convergence ability of ABC, three modi cations are proposed: 1. To enhance the exploitation capability of ABC, L vy Flight Local Search (LFLS) is incorporated with the basic ABC. In this way, the situation of skipping true solution can be avoided while maintaining the speed of conver- gence. The LFLS strategy, in case of large step sizes, can search within the area that is jumped by the basic ABC. 2. Inspired by the O BDE [24], to balance the diversity and convergence capability of ABC, the O BL strategy is incorporated with the basic ABC. This modi cation avoids situation of stagnation of the algorithm and speed up the convergence to global optima. 3. In the basic ABC, the food sources are updated, as shown in Eq. (2), based on the random step size. Inspired by PSO [16] and Gbest-guided ABC (GABC) [38] algo- rithms which, in order to improve the exploitation, take advantage of the information of the global best solu- tion to guide the search of candidate solutions, the solu- tion search equation described by Eq. (2) is modi ed as follows [38]: vi j = xi j + i j(xi j xkj) + i j(xbest j xi j), here, i j is a uniform random number in [0, C], where C is a nonnegative constant. For details description refer to [38]. As described in the proposed rst modi cation, a L vy Flight random walk inspired local search is incorporated with the basic ABC to improve the exploitation capability. In the proposed local search strategy, step size is calculated as shown in Eq. (12). step_size(t) = 0.001 s(t) (xbest j(t) xkj(t)), (12) here, symbols have their usual meanings, SLC = (xbest j xkj) is the social learning component of the ABC algorithm in which xbest is the best solution in the current swarm and xk is the randomly selected solution within swarm and xk = xbest. The solution update equation of the best individual within the current swarm, based on the proposed local search strategy is given in Eq. (13): x best j(t + 1) = xbest j(t) + step_size(t) U(0, 1), (13) In LFLS, only the best particle of the current swarm updates itself in its neighborhood. The pseudo-code of the 123 218 Memetic Comp. (2013) 5:213 227 proposed L vy Flight search strategy with ABC is shown in Algorithm 4 and InAlgorithm4, istheterminationcriteriaoftheproposed local search, pr is a perturbation rate (a number between 0 and 1) which controls the amount of perturbation in the best solution, U(0, 1) is a uniform distributed random number between 0 and 1, D is the dimension of the problem and xk is a randomly selected solution within swarm. See Sect. 6.2 for details of these parameter settings. Further, the opposition based learning (OBL) strategy, explained in Sect. 4, is incorporated with the ABC to bal- ance the diversity and the convergence capability. The OBL is applied to the current swarm of the ABC after the scout bee phase in the solution search process on the basis of probability named as jumping rate ( jr) [24]. Unlike the opposition based optimization method (O BOM) explained in Algorithm 3, opposition based solutions are generated dynamically. In the O BOM, evolution of opposition based solutions are in the static range (solution search space). Therefore, there is a chance to jump outside of the already shrunken search space and the knowledge of the current reduced space (converged swarm) would be lost. Hence, Instead of using prede ned search range ([a j, b j]), the solu- tions are generated by using current interval in the swarm which is, as the search does progress, increasingly smaller than the corresponding initial range. Therefore, in OBOM, the opposition based solutions are generated using following equation: O Pi j = M I NJ P + M AX j P Pi j, here, [M I NJ P, M AX j P] is the current interval in the swarm. Therefore, LFLS and O BOM are incorporated with the basic ABC to speed up the evolutionary process (search process). The proposed algorithm is named as Opposition Based L vy Flight ABC (OBLFABC). Pseudo-code of the OBLFABC is shown in Algorithm 5: 6 Experimental results and discussion 6.1 Test problems under consideration In order to analyze the performance of OBLFABC, 14 un-biased different global optimization problems ( f1 to f14) are selected (listed in Table 1). These are continuous opti- mization problems and have different degrees of complex- ity and multimodality. Test problems f1 to f5 and f11 to f14 are taken from [2] while test problems f6 to f10 are taken from [30] with the associated offset values. Further, to see the robustness of the proposed strategy, ve well known engineering optimization problems ( f15 to f19) which are described as follows, have been solved. Compression Spring ( f15): The considered rst engineering optimization problem is compression spring problem [19, 26]. This problem minimizes the weight of a compression spring, subject to constraints of minimum de ection, shear stress, surge frequency, and limits on outside diameter and on design variables. There are three design variables: the wire diameter x1, the mean coil diameter x2, and the number of active coils x3. This is a simpli ed version of a more dif cult problem. The mathematical formulation of this problem is: x1 {1, . . . , 70} granularity 1 x2 [0.6; 3] x3 [0.207; 0.5] granularity 0.001 and four constraints g1 := 8C f Fmaxx2 x3 3 S 0 g2 := l f lmax 0 g3 := p pm 0 g4 := w Fmax Fp K 0 with C f = 1 + 0.75 x3 x2 x3 + 0.615x3 x2 Fmax = 1,000 S = 189,000 123 Memetic Comp. (2013) 5:213 227 219 Table 1 Test problems Test problem Objective function Search range Optimum value D Acceptable error Beale function f1(x) = [1.5 x1(1 x2)]2 + [2.25 x1(1 x2 2)]2 + [2.625 x1(1 x3 2)]2 [ 4.5, 4.5] f (3, 0.5) = 0 2 1.0E 05 Colville function f2(x) = 100[x2 x2 1]2 + (1 x1)2 + 90(x4 x2 3)2 + (1 x3)2 + 10.1[(x2 1)2 + (x4 1)2] + 19.8(x2 1)(x4 1) [ 10, 10] f (1) = 0 4 1.0E 05 Braninss function f3(x) = a(x2 bx2 1 +cx1 d)2 +e(1 f ) cos x1 +e x1 [ 5, 10], x2 [0, 15] f ( , 12.275) = 0.3979 2 1.0E 05 Kowalik function f4(x) = 11 i=1  ai x1(b2 i +bi x2) b2 i +bi x3+x4 2 [ 5, 5] f (0.1928, 0.1908, 0.1231, 0.1357) = 3.07E 04 4 1.0E 05 2D tripod f5(x) = p(x2)(1 + p(x1)) + |(x1 + 50p(x2)(1 2p(x1)))| + |(x2 + 50(1 2p(x2)))| [ 100, 100] f (0, 50) = 0 2 1.0E 04 Shifted rosenbrock f6(x) = D 1 i=1 (100(z2 i zi+1)2 + (zi 1)2) + fbias, z = x o + 1, x = [x1, x2, ....xD], o = [o1, o2, ...oD] [ 100, 100] f (o) = fbias = 390 10 1.0E 01 Shifted sphere f7(x) = D i=1 z2 i + fbias, z = x o, x = [x1, x2, ....xD], o = [o1, o2, ...oD] [ 100, 100] f (o) = fbias = 450 10 1.0E 05 Shifted rastrigin f8(x) = D i=1(z2 i 10 cos(2 zi) + 10) + fbias z = (x o), x = (x1, x2, ........xD), o = (o1, o2, ........oD) [ 5, 5] f (o) = fbias = 330 10 1.0E 02 Shifted griewank f9(x) = D i=1 z2 i 4000 D i=1 cos( zi i ) + 1 + fbias, z = (x o), x = [x1, x2, ....xD], o = [o1, o2, ...oD] [ 600, 600] f (o) = fbias = 180 10 1.0E 05 Shifted ackley f10(x) = 20 exp( 0.2 1 D D i=1 z2 i ) exp( 1 D D i=1 cos(2 zi)) + 20 + e + fbias, z = (x o), x = (x1, x2, ........xD), o = (o1, o2, ........oD) [ 32, 32] f (o) = fbias = 140 10 1.0E 05 Goldstein-price f11(x) = (1 + (x1 + x2 + 1)2 (19 14x1 + 3x2 1 14x2+6x1x2+3x2 2))(30+(2x1 3x2)2(18 32x1 + 12x2 1 + 48x2 36x1x2 + 27x2 2)) [ 2, 2] f (0, 1) = 3 2 1.0E 14 McCormick f12(x) = sin(x1 + x2) + (x1 x2)2 3 2 x1 + 5 2 x2 + 1 x1 [ 1.5, 4], x2 [ 3, 3] f ( 0.547, 1.547) = 1.9133 30 1.0E 04 Meyer and roth f13(x) = 5 i=1 x1x3ti 1+x1ti +x2vi yi 2 [ 10, 10] f (3.13, 15.16, 0.78) = 0.4E 04 3 1.0E 03 Shubert f14(x) = 5 i=1 i cos((i+1)x1+1) 5 i=1 i cos((i+ 1)x2 + 1) [ 10, 10] f (7.0835, 4.8580) = 186.7309 2 1.0E 05 123 220 Memetic Comp. (2013) 5:213 227 l f = Fmax K + 1.05(x1 + 2)x3 lmax = 14 p = Fp K pm = 6 Fp = 300 K = 11.5 106 x4 3 8x1x3 2 w = 1.25 and the function to be minimized is f15(x) = 2 x2x2 3(x1 + 2) 4 The best known solution is (7, 1.386599591, 0.292), which gives the tness value f = 2.6254214578. Here, minimum error is xed to be 10 10, i.e. a run is said to be successful if it nds a tness f so that | f f | 10 10 in the maximum number of function evaluations. Pressure Vessel design ( f16) The pressure vessel design is to minimize the total cost of the material, forming, and weld- ing of a cylindrical vessel [33]. There are four design vari- ables involved: x1, (Ts, shell thickness), x2 (Th, spherical head thickness), x3 (R, radius of cylindrical shell), and x4 (L, shell length). The mathematical formulation of this typ- ical constrained optimization problem is as follows: f16(x) = 0.6224x1x3x4+1.7781x2x2 3 +3.1611x2 1x4 + 19.84x2 1x3 subject to g1(x) = 0.0193x3 x1 g2(x) = 0.00954x3 x2 g3(x) = 750 1728 x2 3 x4 + 4 3x3 The search boundaries for the variables are 1.125 x1 12.5, 0.625 x2 12.5, 1.0 10 8 x3 240 and 1.0 10 8 x4 240. The best known global optimum solution is f (1.125, 0.625, 55.8592, 57.7315) = 7197.729 [33]. For a successful run, the minimum error criteria is xed to be 1.0E 05 i.e. an algorithm is considered successful if it nds the error less than acceptable error in a speci ed maximum function eval- uations. Lennard-Jones ( f17) The function to minimize is a kind of potential energy of a set of N atoms. The position xi of the atom i has three coordinates, and therefore the dimension of the search space is 3N. In practice, the coordinates of a point x are the concatenation of the ones of the xi. In short, we can write x = (x1, x2, . . . , xN), and we have then f17(x) = N 1  i=1 N  j=i+1  1 xi x j 2 1 xi x j  In this study N = 5, = 6, and the search space is [ 2, 2] [5]. Parameter Estimation for Frequency-Modulated (FM) [5] ( f18): Frequency-Modulated (FM) sound wave synthesis has an important role in several modern music systems. The parameter optimization of an FM synthesizer is a six dimen- sional optimization problem where the vector to be optimized is x = {a1, w1, a2, w2, a3, w3} of the sound wave given in Eq. (14). The problem is to generate a sound (1) similar to target (2). This problem is a highly complex multimodal one having strong epistasis, with minimum value f (x) = 0. This problem has been tackled using genetic algorithms (GAs) in [1], [2].The expressions for the estimated sound and the target sound waves are given as: y(t) = a1sin(w1t + a2sin(w2t + a3sin(w3t ))) (14) y0(t) = (1.0)sin((5.0)t (1.5)sin((4.8)t +(2.0)sin((4.9)t ))) (15) respectively where = 2 /100 and the parameters are de ned in the range [-6.4, 6.35]. The tness function is the summation of square errors between the estimated wave (1) and the target wave (2) as follows: f18(x) = 100  i=0 (y(t) y0(t))2 Acceptable error for this problem is 1.0E 05, i.e. an algo- rithm is considered successful if it nds the error less than acceptable error in a given number of generations. Welded beam design optimization problem ( f19) The problem is to design a welded beam for minimum cost, sub- ject to some constraints [17,23]. The objective is to nd the minimum fabricating cost of the welded beam subject to con- straints on shear stress , bending stress , buckling load Pc, end de ection , and side constraint. There are four design variables: x1, x2, x3 and x4. The mathematical formulation of the objective function is described as follows: f19(x) = 1.10471x2 1x2 + 0.04811x3x4(14.0 + x2) 123 Memetic Comp. (2013) 5:213 227 221 Subject to: g1(x) = (x) max 0 g2(x) = (x) max 0 g3(x) = x1 x4 0 g4(x) = (x) max 0 g5(x) = P Pc(x) 0 0.125 x1 5, 0.1 x2, x3 10 and 0.1 x4 5 where (x) =  2 x2 R + 2, = P 2x1x2 , = M R J , M = P L + x2 2 , R =  x22 4 + x1 + x3 2 2 , J = 2/  2x1x2  x22 4 + x1 + x3 2 2 , (x) = 6PL x4x32 , (x) = 6PL3 Ex4x32 , Pc(x) = 4.013Ex3x43 6L2  1 x3 2L  E 4G  , P = 6,000 lb, L = 14 in., max = 0.25 in., max = 30,000 psi, max = 13600 psi, E = 30 106 psi, G = 12 106 psi. The best known solution is (0.205730, 3.470489, 9.036624, 0.205729),whichgivesthefunctionvalue1.724852.Accept- able error for this problem is 1.0E 01. 6.2 Experimental setting To prove the ef ciency of O BLF ABC, it is compared with ABC and recent variants of ABC named Gbest-guided ABC (G ABC) [38], Best-So-Far ABC (BSF ABC) [3] and Modi- ed ABC (M ABC) [1]. To test O BLF ABC, ABC, G ABC, BSF ABC and M ABC over considered problems, following experimental setting is adopted: Colony size N P = 50 [7,9], i j = rand[ 1, 1], Number of food sources SN = N P/2, limit = 1,500 [1,15], The stopping criteria is either maximum number of func- tion evaluations (which is set to be 200000) is reached or the acceptable error (mentioned in Table 1) has been achieved, The number of simulations/run =100, C = 1.5 [38], The value of = 2 is to be set based on the empirical experiments. To set termination criteria of LFLS, the performance of OBLFABC is measured for considered test problems on different values of and results are analyzed in Fig. 1a. It is clear from Fig. 1a that = 15 gives better results. Therefore, termination criteria is set to be = 15. 5 10 15 20 25 1360 1380 1400 1420 1440 1460 1480 1500 1520 Local search iterations (termination criteria) Sum of success rate of (a) 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1150 1200 1250 1300 1350 1400 1450 1500 1550 pr (b) 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1200 1250 1300 1350 1400 1450 1500 1550 jr (c) considered problems Sum of success rate of considered problems Sum of success rate of considered problems Fig. 1 a Effect of LFLS termination criteria on success rate, b effect of parameter pr on success rate and c effect of parameter jr on success rate 123 222 Memetic Comp. (2013) 5:213 227 Table 2 Comparison of the results of test problems Test function Algorithm SD ME AFE SR f1 OBLFABC 2.87E 06 7.55E 06 7,465.64 100 ABC 1.66E 06 8.64E 06 16,520.09 100 GABC 3.05E 06 5.03E 06 9,314.71 100 BSFABC 5.64E 05 1.98E 05 47,522.01 95 MABC 2.68E 06 5.47E 06 10,350.53 100 f2 OBLFABC 1.23E 02 1.46E 02 115,073.86 68 ABC 1.03E 01 1.67E 01 199,254.48 1 GABC 1.71E 02 1.95E 02 151,300.35 46 BSFABC 1.61E 02 1.86E 02 153,393.46 47 MABC 8.26E 03 1.25E 02 147,787.15 52 f3 OBLFABC 6.67E 06 5.93E 06 988.51 100 ABC 6.83E 06 6.05E 06 1,925.52 100 GABC 6.54E 06 5.76E 06 1,204.65 100 BSFABC 6.99E 06 5.87E 06 25,770.82 88 MABC 6.49E 06 5.71E 06 28,716.34 87 f4 OBLFABC 1.21E 05 9.47E 05 56,381.43 100 ABC 7.33E 05 1.76E 04 180,578.91 18 GABC 2.15E 05 8.68E 05 90,834.53 97 BSFABC 7.57E 05 1.41E 04 147,931.24 50 MABC 8.02E 05 2.02E 04 187,320.13 13 f5 OBLFABC 2.53E 05 6.79E 05 5,184.77 100 ABC 2.69E 05 6.42E 05 8,771.65 100 GABC 2.58E 05 6.34E 05 7,305.93 100 BSFABC 1.55E 03 2.49E 04 8,453.82 97 MABC 1.49E 04 1.06E 04 67,336.12 88 f6 OBLFABC 7.15E+00 1.44E+00 75,645.49 85 ABC 1.05E+00 6.36E 01 176,098.02 23 GABC 1.60E 02 8.45E 02 99,219.48 99 BSFABC 3.79E+00 2.34E+00 179,970.99 19 MABC 9.19E 01 6.99E 01 180,961.73 23 f7 OBLFABC 2.64E 06 7.31E 06 6,693.71 100 ABC 2.42E 06 7.16E 06 9,013.5 100 GABC 2.08E 06 6.83E 06 5,585.5 100 BSFABC 2.18E 06 7.44E 06 18,122 100 MABC 1.61E 06 8.23E 06 8,702 100 f8 OBLFABC 1.07E+01 9.13E+01 200,034.54 0 ABC 1.21E+01 8.91E+01 200,011.71 0 GABC 9.24E+00 8.56E+01 200,006.8 0 BSFABC 1.77E+01 1.20E+02 200,036.53 0 MABC 1.15E+01 8.00E+01 200,015.14 0 f9 OBLFABC 3.73E 03 1.71E 03 81,595.29 82 ABC 2.21E 03 6.95E 04 61,650.9 90 GABC 7.35E 04 7.88E 05 38,328.96 99 BSFABC 6.34E 03 4.76E 03 115,441.96 58 MABC 2.21E 03 6.24E 04 85,853.52 92 f10 OBLFABC 1.63E 06 8.27E 06 11,675.15 100 ABC 1.80E 06 7.90E 06 16,767 100 GABC 1.37E 06 8.31E 06 9,366 100 123 Memetic Comp. (2013) 5:213 227 223 Table 2 continued Test function Algorithm SD ME AFE SR BSFABC 1.35E 06 8.39E 06 31,224 100 MABC 9.96E 07 8.93E 06 14,189.06 100 f11 OBLFABC 4.71E 15 5.68E 15 4,296.23 100 ABC 5.16E 06 1.04E 06 109,879.46 62 GABC 4.37E 15 4.87E 15 3,956.05 100 BSFABC 4.90E 15 6.62E 15 14,031.79 100 MABC 4.11E 15 4.73E 15 14,228.59 100 f12 OBLFABC 6.96E 06 8.91E 05 662.79 100 ABC 6.67E 06 8.92E 05 1,166.5 100 GABC 6.45E 06 8.79E 05 622 100 BSFABC 6.34E 06 8.91E 05 958.51 100 MABC 6.15E 06 8.95E 05 1,702.28 100 f13 OBLFABC 3.03E 06 1.95E 03 5,229.73 100 ABC 2.89E 06 1.94E 03 24,476.88 100 GABC 2.74E 06 1.95E 03 5,127.73 100 BSFABC 2.98E 06 1.94E 03 15,703.99 100 MABC 2.79E 06 1.95E 03 9,019.7 100 f14 OBLFABC 5.89E 06 5.27E 06 2,255.04 100 ABC 5.34E 06 4.86E 06 4,752.21 100 GABC 5.72E 06 5.07E 06 2,550.57 100 BSFABC 5.94E 06 5.27E 06 9,036.83 100 MABC 5.60E 06 4.83E 06 33,268.91 100 f15 OBLFABC 7.94E 03 5.21E 03 126,520.99 58 ABC 1.22E 02 1.42E 02 189,423.57 10 GABC 1.08E 02 1.09E 02 188,220.68 12 BSFABC 5.73E 03 2.93E 02 196,442.59 2 MABC 6.65E 03 4.98E 03 174,943.41 25 f16 OBLFABC 2.43E+00 1.51E+00 200,030.62 0 ABC 1.07E+01 1.69E+01 200,024.49 0 GABC 4.47E+00 6.84E+00 200,023.29 0 BSFABC 2.19E+01 2.66E+01 200,036.19 0 MABC 8.63E+00 1.51E+01 200,025.82 0 f17 OBLFABC 1.05E 04 8.91E 04 22,077.03 100 ABC 1.24E 04 8.77E 04 70,189.49 100 GABC 5.26E 04 1.11E 03 112,535.45 69 BSFABC 6.13E 04 9.46E 04 154,352.33 89 MABC 1.51E 01 4.66E 01 200,031.91 0 f18 OBLFABC 3.81E+00 1.68E+00 158,797.2 44 ABC 5.08E+00 6.01E+00 200,032.9 0 GABC 4.81E+00 3.10E+00 184,843.53 14 BSFABC 4.44E+00 1.01E+01 198,887.41 1 MABC 3.06E+00 2.85E+00 200,022.49 0 f19 OBLFABC 1.98E 02 1.06E 01 116,907.25 71 ABC 8.72E 02 2.47E 01 197,869.95 2 GABC 1.09E 02 9.95E 02 120,011.32 69 BSFABC 4.79E 03 9.57E 02 55,029.62 100 MABC 5.18E 03 9.37E 02 33,617.76 100 123 224 Memetic Comp. (2013) 5:213 227 Table 3 Summary of Table 2 outcome Test problems OBLFABC versus ABC OBLFABC versus GABC OBLFABC versus BSFABC OBLFABC versus MABC f1 + + + + f2 + + + + f3 + + + + f4 + + + + f5 + + + + f6 + + + f7 + + + f8 + + + f9 + f10 + + + f11 + + + + f12 + + + f13 + + + f14 + + + f15 + + + + f16 + + + + f17 + + + + f18 + + + + f19 + + Total number of + sign 18 11 18 17 In order to investigate the effect of the parameter pr, described by algorithm 4 on the performance of O BLF ABC, its sensitivity with respect to different val- ues of pr in the range [0.1, 1], is examined in the Fig. 1b. It can be observed from Fig. 1b that the test problems are very sensitive towards pr and value 0.2 gives compara- tively better results. Therefore pr = 0.2 is selected for the experiments. In order to nd out the optimal value of the jumping rate constant jr for all the considered test problems, O BLF ABC is executed for different values of jr in the range [0.1, 0.9]. The sensitivity analysis of jr is shown in Fig. 1c. It is clear from Fig. 1c that jr = 0.1 gives comparatively better results. Hence, for the experiments, jr = 0.1 is selected. Parameter settings for the algorithms GABC, BSFABC and MABC are similar to their original research papers. 6.3 Results comparison Numerical results with experimental setting of Subsect. 6.2 are given in Table 2. In Table 2, standard deviation (SD), mean error (M E), average function evaluations (AFE) and success rate (SR) are reported. Table 2 shows that most of the time OBLFABC outperforms in terms of reliability, ef - ciency and accuracy as compare to the basic ABC, GABC, BSFABC and MABC. Some more intensive analyses based on acceleration rate (AR), performance indices and boxplots have been carried out for results of ABC and its variants. O BLF ABC, ABC, G ABC, BSF ABC,and M ABC are compared through SR, M E and AFE in Table 2. First SR is compared for all these algorithms and if it is not possible to distinguish the algorithms based on SR then comparison is made on the basis of AFE. M E is used for compari- son if it is not possible on the basis of SR and AFE both. Outcome of this comparison is summarized in Table 3. In Table 3, + indicates that the O BLF ABC is better than the considered algorithms and indicates that the algorithm is not better or the difference is very small. The last row of Table 3, establishes the superiority of O BLF ABC over ABC, BSF ABC, M ABC. Further, we compare the convergence speed of the con- sidered algorithms by measuring the average function eval- uations (AFEs). A smaller AFEs means higher convergence speed. In order to minimize the effect of the stochastic nature of the algorithms, the reported function evaluations for each test problem is the average over 100 runs. In order to com- pare convergence speeds, we use the acceleration rate (AR) which is de ned as follows, based on the AFEs for the two algorithms ALGO and OBLFABC: AR = AFE ALGO AFEO BLFABC , (16) 123 Memetic Comp. (2013) 5:213 227 225 Table 4 Acceleration Rate (AR) of O BLFABC compare to the basic ABC, G ABC, BSFABC and M ABC Test problems ABC GABC BSFABC MABC f1 2.212816316 1.247677359 6.365430157 1.386422329 f2 1.731535555 1.314810766 1.33300004 1.284280809 f3 1.947901387 1.218652315 26.07036853 29.05012595 f4 3.202808265 1.611071766 2.623758213 3.32237281 f5 1.691810823 1.409113615 1.630510129 12.98729163 f6 2.327938123 1.311637746 2.379137077 2.392234223 f7 1.346562669 0.834440094 2.707317765 1.300026443 f8 0.99988587 0.999861324 1.000009948 0.999903017 f9 0.755569347 0.469744761 1.414811566 1.052187203 f10 1.436127159 0.802216674 2.674398188 1.215321431 f11 1.497171102 1.487663668 1.552648221 1.382722424 f12 25.57578621 0.920818951 3.266070485 3.311878088 f13 1.759984309 0.938457128 1.446174505 2.568354984 f14 4.680333402 0.980496125 3.002829974 1.724697068 f15 2.107372818 1.131053108 4.00739233 14.7531352 f16 0.999969355 0.999963356 1.000027846 0.999976004 f17 3.17929948 5.097399877 6.991535093 9.060634968 f18 1.259675234 1.164022602 1.252461693 1.259609678 f19 1.692537888 1.026551561 0.470711782 0.28755924 where, ALGO { ABC, GABC, BSFABC, MABC} and AR > 1 means OBLFABC is faster. In order to investigate the AR of the proposed algorithm compare to the basic ABC and its variants, results of Table 2 are analyzed and the value of AR is calculated using Eq. (16). Table 4 shows a clear comparison between O BLF ABC and ABC, OBLFABC and GABC, OBLFABC and BSFABC, and OBLFABC and MABCintermsofAR.ItisclearfromtheTable4thatconver- gence speed of OBLFABC is faster among all the considered algorithms. For the purpose of comparison in terms of consolidated performance, boxplot analyses have been carried out for all the considered algorithms. The empirical distribution of data is ef ciently represented graphically by the boxplot analy- sis tool [34]. The boxplots for ABC, OBLFABC, GABC, BSFABC and MABC are shown in Fig. 2. It is clear from this gure that OBLFABC is better than the considered algorithms as interquartile range and median are compar- atively low. Further, to compare the considered algorithms, by giv- ing weighted importance to the success rate, the mean error and the average number of function evaluations, performance indices (P I) are calculated [6]. The values of P I for the ABC, OBLFABC, GABC, BSFABC, and MABC are calcu- lated by using following equations: P I = 1 Np Np  i=1 (k1 i 1 + k2 i 2 + k3 i 3) OBLFABC ABC GABC BSFABC MABC 0 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8 2 x 10 5 Average Number of Function Evaluations Fig. 2 Boxplots graphs for average function evaluation where i 1 = Sri Tri ; i 2 =  M f i Af i , if Sri > 0. 0, if Sri = 0. ; and i 3 = Moi Aoi i = 1, 2, . . . , Np Sri = Successful simulations/runs of ith problem. Tri = Total simulations of ith problem. M f i = Minimum of average number of function eval- uations used for obtaining the required solution of ith problem. Af i = Average number of function evaluations used for obtaining the required solution of ith problem. Moi = Minimum of mean error obtained for the ith prob- lem. 123 226 Memetic Comp. (2013) 5:213 227 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.2 0.4 0.6 0.8 1 Weight (k1) Performance Index OBLFABC ABC GABC BSFABC MABC (a) 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.2 0.4 0.6 0.8 1 Weight (k2) Performance Index OBLFABC ABC GABC BSFABC MABC (b) 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.2 0.4 0.6 0.8 1 Weight (k3) Performance Index OBLFABC ABC GABC BSFABC MABC (c) Fig. 3 Performance index for test problems; a for case (1), b for case (2) and c for case (3) Aoi = Mean error obtained by an algorithm for the ith problem. Np = Total number of optimization problems evaluated. The weights assigned to the success rate, the average number of function evaluations and the mean error are represented by k1, k2 and k3 respectively where k1 + k2 + k3 = 1 and 0 k1, k2, k3 1. To calculate the P Is, equal weights are assigned to two variables while weight of the remaining variable vary from 0 to 1 as given in [6]. Following are the resultant cases: 1. k1 = W, k2 = k3 = 1 W 2 , 0 W 1; 2. k2 = W, k1 = k3 = 1 W 2 , 0 W 1; 3. k3 = W, k1 = k2 = 1 W 2 , 0 W 1 The graphs corresponding to each of the cases (1), (2) and (3) for ABC, OBLFABC, GABC, BSFABC, and MABC are shown in Figs. 3a c respectively. In these gures the weights k1, k2 and k3 are represented by horizontal axis while the P I is represented by the vertical axis. In case (1), average number of function evaluations and the mean error are given equal weights. P Is of the consid- ered algorithms are superimposed in Fig. 3a for comparison of the performance. It is observed that P I of OBLFABC are higher than the considered algorithms. In case (2), equal weights are assigned to the success rate and mean error and in case (3), equal weights are assigned to the success rate and average function evaluations. It is clear from Fig. 3b, c that, the algorithms perform same as in case (1). 7 Conclusion In this paper, a new local search strategy based on the L vy Flight random walk is proposed for nding the new solutions around the best solution. In this search strategy, new solu- tions are generated in the neighborhood of the best solution depending upon perturbation rate. The proposed local search strategy along with opposition based learning (OBL) has been employed to improve the convergence of ABC. The pro- posed L vy ight search strategy is used to exploit the search space whereas OBL is used to introduce opposition-based swarm generation to speed up the convergence. Further, inspiredbyPSOandGABC,amodi edpositionupdateequa- tion is used to generate the solutions in the search process. By embedding these three modi cations within ABC, a new variant of ABC is proposed and named as OBLFABC. Fur- ther, the proposed algorithm is compared with the basic ABC, GABC, BSFABC, and MABC through the help of exper- iments over test problems and shown that the OBLFABC outperforms to the considered algorithms in terms of relia- bility, ef ciency and accuracy. References 1. Akay B, Karaboga D (2010) A modi ed arti cial bee colony algo- rithm for real-parameter optimization. Inf Sci, doi:10.1016/j.ins. 2010.07.015 2. Ali MM, Khompatraporn C, Zabinsky ZB (2005) A numerical evaluation of several stochastic algorithms on selected continuous global optimization test problems. J Glob Optim 31(4):635 672 123 Memetic Comp. (2013) 5:213 227 227 3. Banharnsakun A, Achalakul T, Sirinaovakul B (2011) The best-so- far selection in arti cial bee colony algorithm. Appl Soft Comput 11(2):2888 2901 4. Brown CT, Liebovitch LS, Glendon R (2007) L vy ights in dobe ju/hoansi foraging patterns. Hum Ecol 35(1):129 138 5. Das S, Suganthan PN (2010) Problem de nitions and evaluation criteria for CEC 2011 competition on testing evolutionary algo- rithms on real world optimization problems. Jadavpur University, Kolkata, India, and Nangyang Technological University, Singa- pore, Tech. Rep 6. Thakur M, Deep K (2007) A new crossover operator for real coded genetic algorithms. Appl Math Comput 188(1):895 911 7. Diwold K, Aderhold A, Scheidler A, Middendorf M (2011) Per- formance evaluation of arti cial bee colony optimization and new selection schemes. Memet Comput, 1 14 8. Dorigo M, Di Caro G (1999) Ant colony optimization: a new meta- heuristic. In: Evolutionary computation, 1999. CEC 99. Proceed- ings of the 1999 congress on, 2. IEEE 9. El-Abd M (2011) Performance assessment of foraging algorithms vs. evolutionary algorithms. Inf Sci 182(1):243 263 10. Goldberg DE (1989) Genetic algorithms in search, optimization, and machine learning. Addison-Wesley, Reading 11. Hooke R, Jeeves TA (1961) Direct search solution of numerical and statistical problems. J ACM (JACM) 8(2):212 229 12. Kang F, Li J, Ma Z, Li H (2011) Arti cial bee colony algorithm with local search for numerical optimization. J Softw 6(3):490 497 13. Karaboga D (2005) An idea based on honey bee swarm for numer- ical optimization. Techn. Rep. TR06, Erciyes University Press, Erciyes 14. Karaboga D, Akay B (2009) A comparative study of arti cial bee colony algorithm. Appl Math Comput 214(1):108 132 15. Karaboga D, Akay B (2011) A modi ed arti cial bee colony (ABC) algorithm for constrained optimization problems. Appl Soft Comput 11(3):3021 3031 16. Kennedy J, Eberhart R (1995) Particle swarm optimization. In: Neural networks, 1995. Proceedings., IEEE international con- ference on, 4, pp 1942 1948. IEEE 17. Mahdavi M, Fesanghary M, Damangir E (2007) An improved har- mony search algorithm for solving optimization problems. Appl Math Comput 188(2):1567 1579 18. Mezura-Montes E, Velez-Koeppel RE, (2010) Elitist arti cial bee colony for constrained real-parameter optimization. In: (2010) Congress on evolutionary computation (CEC 2010). IEEE Service Center, Barcelona, Spain, pp 2068 2075 19. Onwubolu GC, Babu BV (2004) New optimization techniques in engineering. Springer, Berlin 20. Passino KM (2002) Biomimicry of bacterial foraging for distrib- uted optimization and control. IEEE Control Syst Mag 22(3):52 67 21. Pavlyukevich I (2007) L vy ights, non-local search and simulated annealing. J Comput Phys 226(2):1830 1844 22. Price KV, Storn RM, Lampinen JA (2005) Differential evolution: a practical approach to global optimization. Springer, Berlin 23. Ragsdell KM, Phillips DT (1976) Optimal design of a class of welded structures using geometric programming. ASME J Eng Ind 98(3):1021 1025 24. Rahnamayan S, Tizhoosh HR, Salama MMA (2008) Opposition- based differential evolution. IEEE Trans Evol Comput 12(1):64 79 25. Reynolds AM, Frye MA (2007) Free- ight odor tracking in drosophila is consistent with an optimal intermittent scale-free search. PLoS One 2(4):e354 26. Sandgren E (1990) Nonlinear integer and discrete programming in mechanical design optimization. J Mech Des 112:223 27. Shlesinger MF (2006) Mathematical physics: search research. Nature 443(7109):281 282 28. Shlesinger MF, Zaslavsky GM, Frisch U (1995) L vy ights and related topics in physics. In Levy ights and related topics in, Physics, vol 450 29. Storn R, Price K (1997) Differential evolution-a simple and ef - cient adaptive scheme for global optimization over continuous spaces. J Glob Optim 11:341 359 30. Suganthan PN, Hansen N, Liang JJ, Deb K, Chen YP, Auger A, Tiwari S (2005) Problem de nitions and evaluation criteria for the CEC 2005 special session on real-parameter optimization. In: CEC 2005 31. Tizhoosh HR (2005) Opposition-based learning: a new scheme for machine intelligence. In: Computational intelligence for mod- elling, control and automation, 2005 and international conference on intelligent agents, web technologies and internet commerce, international conference on, 1, pp 695 701. IEEE 32. Vesterstrom J, Thomsen R (2004) A comparative study of differen- tial evolution, particle swarm optimization, and evolutionary algo- rithms on numerical benchmark problems. In: Evolutionary com- putation, 2004. CEC2004. Congress on, 2, pp 1980 1987. IEEE 33. Wang X, Gao XZ, Ovaska SJ (2008) A simulated annealing-based immune optimization method. In: Proceedings of the international and interdisciplinary conference on adaptive knowledge represen- tation and reasoning, porvoo, Finland, pp 41 47 34. Williamson DF, Parker RA, Kendrick JS (1989) The box plot: a simplevisualmethodtointerpretdata.AnnInternMed110(11):916 35. Yang XS, Deb S (2010) Eagle strategy using l vy walk and re y algorithms for stochastic optimization. In: Nature inspired cooper- ative strategies for optimization (NICSO 2010), Springer, vol 284 of studies in, Computational Intelligence, pp 101 111 36. Yang XS (2010) Fire y algorithm, levy ights and global opti- mization. Research and Development in Intelligent Systems XXVI, pp 209 218 37. Yang XS (2010) Nature-inspired metaheuristic algorithms, 2nd edn. Luniver Press, Beckington 38. Zhu G, Kwong S (2010) Gbest-guided arti cial bee colony algo- rithm for numerical function optimization. Appl Math Comput 217(7):3166 3173 123