See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/350243345 VISTA: A teaching aid to enhance contextual teaching Article in Computer Applications in Engineering Education October 2021 DOI: 10.1002/cae.22407 CITATIONS 0 READS 127 6 authors, including: Some of the authors of this publication are also working on these related projects: Metaphor Processing View project Emotion based trust networks, recommender systems and NLP View project Kanika Kanika Netaji Subhas Institute of Technology 10 PUBLICATIONS 42 CITATIONS SEE PROFILE Aditya Aggarwal Jaypee Institute of Information Technology 2 PUBLICATIONS 1 CITATION SEE PROFILE All content following this page was uploaded by Kanika Kanika on 19 January 2022. The user has requested enhancement of the downloaded file. Comput Appl Eng Educ. 2021;29:1526 1541. wileyonlinelibrary.com/journal/cae 1526 | 2021 Wiley Periodicals LLC Received: 3 October 2020 | Revised: 22 February 2021 | Accepted: 27 February 2021 DOI: 10.1002/cae.22407 R E S E A R C H A R T I C L E VISTA: A teaching aid to enhance contextual teaching Kanika Kanika1 | Shampa Chakraverty1 | Pinaki Chakraborty1 | Manan Madan2 | Gaurav Gupta2 | Aditya Aggarwal3 1Computer Engineering Department, Netaji Subhas Institute of Technology, New Delhi, India 2Department of Instrumentation and Control Engineering, Netaji Subhas Institute of Technology, New Delhi, India 3Department of Computer Science Engineering, Jaypee Institute of Information Technology, Noida, India Correspondence Kanika Kanika, Computer Engineering Department, Netaji Subhas Institute of Technology, New Delhi, Delhi 110078, India. Email: kanikatehlan@gmail.com Abstract In this study, an innovative tool for enabling contextual teaching based on visual inputs, named Visual Stimuli based Teaching Aid (VISTA), was devel- oped. This system establishes the meaning and significance of concepts that are taught in the classroom within different environmental contexts. The idea of contextual teaching has been deliberated for more than a decade now. Nevertheless, using this in a classroom with limited time and resources has several challenges. VISTA leverages the ubiquitous mobile devices to boost conventional teaching methods with contextual teaching learning. With VISTA, contextual teaching does not require any specialized device, expensive sensors, or simulated environment. To assess the applicability of VISTA in computer science education, we gathered the responses and experiences from 42 computer science teachers teaching in various universities of India. The responses garnered indicate that contextualization through VISTA is relevant as well as interesting. In total, 86.31% of the teachers found the contextual information provided by VISTA to be significantly related to both the captured images and the concepts presented in the class. These results encourage the use of VISTA as a pedagogical tool for contextual teaching. K E Y W O R D S computer science education, contextual teaching and learning, mobile learning 1 | INTRODUCTION According to situated learning theory, learning is in- complete without context, culture, and activities that engage students. It states that learning occurs within a particular context. The basic idea behind the theory is making learning meaningful with everyday practices and real life situations [16]. For this, the theory advocates the use of contexts in which a concept is applied while teaching. Context is the environment or situation com- prising real world entities in which the concepts we learn in classroom are applied [22]. Several studies claim that context is crucial to understand the significance and meaning of the concepts [10,30], to motivate learners [6], and to help derive a coherent structural meaning of the learning material [9]. Educators believe that context is an integral part of teaching the theories and concepts of any subject, including computer science [5]. Contextual teaching also improves understanding of computer sci- ence concepts, as it helps in the directive construction of meaning by eliminating ambiguities [23]. These studies make it clear that context has an irreplaceable role in the teaching learning process. Situational learning, hence, revolves around creating a situational context for learning that resembles real life applications [27]. Contextual teaching is a pedagogical approach that helps in the creation of such contexts and bringing alive their role in applying the concepts taught. Contextual teaching tools are being developed and used to bring in proactive changes to the teaching learning process [6]. Researchers have used contextual teaching to help students learn a particular subject or a set of con- cepts in computer science education [1,2]. The benefits of contextual teaching are widely accepted for computer science as well as other subjects [11]. In this paper, we introduce Visual Stimuli based Teaching Aid (VISTA) a contextualizer with an aim to incorporate the context while teaching any computer science course. Here, we perceive contextual teaching as teaching fundamental theories, abstract concepts, and complicated principles of computer science with real life applications [4,5]. VISTA makes use of visual stimuli that the teacher takes from the dynamic environment. The aim is to find out applications of a specific concept in the stimuli. Using Natural Language Processing techniques and an e book, the system extracts important concepts. With the help of Wikipedia, the visual cues and various filters, and a ranking algorithm, the system finds out class concepts with image objects/themes. Finally, it recommends the relevant and interesting context of concepts to teachers. This enables the teachers as well as students to find ex- tensional knowledge that they would not have otherwise discovered. The salient features of using VISTA as a pedagogical tool for teaching are given next. According to Arnold et al., teaching is believed to be efficient only if the learner can connect the classroom studies to real life contexts [1]. The system we propose provides a real world context, hence benefiting the learning process. The argument that context is an in- extricable aspect of learning motivates us to think beyond content [6]. Contrary to this, challenges like lack of training and excessive content obligate a teacher to stick to textbooks [20]. VISTA attempts to remove the barriers and allow every teacher to adapt contextual teaching without going through any manpower training. In addi- tion to this, some of the approaches proposed in the lit- erature rely on the deployment of immersive sensors and specialized hardware to capture the context and inter- actions therein. However, the system proposed facilitates contextual teaching without additional expenses or a si- mulated environment. The users only need a mobile phone to improve the teaching learning process. As ad- dition of context helps the students understand the concepts better [9], VISTA can be used as a pedagogical tool to improve the understanding of different computer science concepts. The rest of the paper explores the existing methods for adopting context in teaching along with the analytical studies concentrating on the use of context. Then, the introduction to VISTA, a tool for teaching in context, is presented. In the end, the results and analysis of the outcomes are presented. 2 | BACKGROUND In the past, most novices found computer programming a challenging and even intimidating endeavor. However, in recent times, students have started enjoying learning new programming languages [12]. This remarkable shift in attitude and learning aptitude has been made possible due to programming environments like Alice [25] and Scratch [17] that enable teaching computer programming in con- text. With such programming environments, students can program in context that closely resembles the real life application of coding. There is a multitude of such simu- lated environments serving as context for novice pro- grammers, simulating real world environments [18,32]. However, there are a number of attempts made to teach some useful concepts of other computer science subjects through contextual teaching. For instance, in the study reported by Reference [3], teaching introductory courses in computer engineering and electrical engineering using context was attempted. The context used in this study is the simulation of an electronic system, a global position- ing system (GPS) and a programmable robot. Students are also taught some crucial concepts of computer science and mathematics in two different learning environments LogicTraffic and QueueTraffic [1]. On the one hand, we have sufficient proof of simu- lations helping in contextual teaching, thereby making learning interactive, interesting, and effective [24,28]. On the other hand, it is also a fact that designing and de- veloping a realistic dynamic environment for every sub- ject of computer science, ranging from simple to complex, is quite expensive and time consuming [11]. So, this definitely is not a feasible way to move to- ward contextual teaching from conventional teaching. One alternative that several teachers have used is to use context passively rather than teaching using simu- lated environments. A number of context extractors using some sensors are available to facilitate contextual teaching. Personalized Knowledge Awareness Map for Computer Supported Ubiquitous Learning (PERKAM) is one such context extractor. It detects the objects sur- rounding the learner, his/her location, and so on, using RFID ubiquities technology [8]. The system then utilizes this information to give personalized knowledge aware- ness maps that assist in learning. Using the same tech- nology for sensing, Derntl and Hummel [7] tried to establish a link between context and learning activities of the learner. Context here too is the time, location of the learner, and nearby people. KANIKA ET AL. | 1527 It is observed that in most of the scenarios of con- textual teaching, either it is through simulated environ- ments or using some sensors that sense the environmental context. As far as the studies involving games and puzzles are concerned, they limit concepts to a few topics of computer science [2,31]. However, using contextual teaching as a pedagogical tool is possible only if one can facilitate it in a way that is neither too expensive nor time consuming and can be used for teaching any computer science course. In this paper, we try to give a novel ap- proach to teaching computer science with context. Rather than taking help from expensive sensors, the system we propose gathers information from a mobile phone camera, making contextual teaching feasible. 3 | VISTA A PEDAGOGICAL TOOL There are three important considerations that play a significant role in determining the success of designing a system for contextual teaching [21]. The first con- sideration is as follows: Which context should be cap- tured? As the use of real life examples that a student can relate to serves as context [15] in developing VISTA, we take into account the physical context. The second sig- nificant consideration is as follows: How can this con- text be captured? In our system, the teacher captures images from the environment using a mobile phone camera. Although it may be any image captured, it can be expected that the teacher would capture a part of the environment in which the concepts taught may have been applied in some way. However, even if such de- liberate thought is not applied, VISTA tries to mine related information from any given picture to discover latent correlations and bring in an element of seren- dipity. The question How can the context be visua- lized? is the third determining factor. VISTA recommends information sources that depict some in- teresting aspects such as applications of concepts within an environmental context. Figure 1 shows the overall architecture of VISTA. As shown in this diagram, VISTA takes as input images of teacher's notes and an image of the physical en- vironment. In the following sections, we will explain its detailed working. For the sake of brevity, in this section, we retain a generic description of VISTA that illustrates its core concepts and mechanisms. To il- lustrate its working, we have included an example in the appendix. 3.1 | Preprocessing teacher's notes The system accepts images of the teacher's notes. To convert the notes into a form that can be processed conveniently, the system first converts notes into a tex- tual format using an optical character recognition (OCR) system. The system stores the set of words thus re- cognized in a set T. Figure A1 in the appendix is the image of teacher's notes given as input to the OCR. The corresponding text extracted is also available in the ap- pendix. As special symbols do not add a considerable value to information we aim to extract, VISTA eliminates all special symbols by replacing anything other than English alphabets with null characters. The class notes of computer science are usually a blend of general terms and subject specific terms. FIGURE 1 Architectural diagram of Visual Stimuli based Teaching Aid 1528 | KANIKA ET AL. To include the subject specific words, VISTA refers to the Oxford dictionary of computer science. Every word w from T is searched for in the dictionary and those matching exactly with any term in the dictionary are removed from T and added to a set T . Remaining words in T are checked for spelling mistakes using a spell checker [26]. If w is present in the English dictionary, it is added to T as it is. Else, after converting the word into closest match with a dictionary word, the system adds the word to T . After corrections, the system employs a POS tagger to annotate each word present in T as a noun, verb, and adjective. Words extracted from a part of notes along with the tags are included in appendix as example. 3.2 | Extracting core teaching concepts For a set of subjects in computer science, the system maintains an index of corresponding e books. What we get in T is a set of fragmented words. However, phrases carry a lot of information in class notes. So, there is a need to cull out phrases, and for this, VISTA uses the index of an e book. With the notes and index, the system extracts the fundamental concepts embedded within the notes by first selecting the informative words. The system selects and stores all nouns present in T in a set TN, as it is widely accepted that nouns convey most of the crucial information present in a text [14]. Apart from nouns, the system also stores all words marked as foreign words in FIGURE 2 Distribution of responses for recommendations on an artificial intelligence data set FIGURE 3 Distribution of responses for recommendations on software engineering I data set KANIKA ET AL. | 1529 FIGURE 4 Distribution of responses for recommendations on machine learning data set FIGURE 5 Distribution of responses for recommendations on software engineering II data set FIG. A1 Portion of teacher's notes FIG. A2 Image 1530 | KANIKA ET AL. the previous step in TN, as these words carry subject related information: T = {w | w T w (noun foreign word)} N VISTA now searches the entries in the index of the e book for every word w in TN to get the candidate teaching concepts from informative words. For this, it stores the set of index terms of a particular e book. It chooses all the single or multiword phrases present in the index that contain the words in TN. All such index entries represent the candidate fundamental teaching concepts stored in C. Let I be the index terms, then C would be represented as follows: C w w i I = { | ( )}, C gives us candidate teaching concepts. However, if there are generic terms, it will have a large number of index terms. There is a need to remove such anecdotal mentions. For this, VISTA creates clusters of all index entries in C on the basis of page numbers. A dense cluster having nearby pages indicates a core theme of the class, whereas a sparse cluster usually indicates anecdotal mention. To pick up the core concept, VISTA chooses the densest among all the clusters. Let this cluster be denoted as D. In case there are two or more clusters with exactly equal candidate concepts, all of them are taken as D to avoid loss of in- formation. The topics/index phrases appearing in the den- sest cluster represent core teaching concepts (TC): TC c c C c D = { | }. 3.3 | Acquiring the central theme of image Almost every course of computer science is applicable in a wide variety of real life objects and scenarios in many different ways. However, to keep the process of con- textualization directed and interesting, VISTA takes as input a particular scene/object/environment. As teachers have a better understanding of what would be interesting for the students [22], the system allows the teacher to select a particular scenario or object from the real world. The image uploaded by a teacher may be of a single object, multiple objects, or even an entire scene com- prising a real life situation. The system processes the image to detect its central theme using Google reverse image search. For example, if Figure A2 is given as an input, it leads to the theme game controller. The search engine stores a large number of images along with metadata. With the help of the metadata, every image search results in accurate labels along with other similar images. These labels are the theme of the image uploaded. Let IT be the image theme or ideas the system extracts from the image. To get theme of image, VISTA gives the image teacher submits as an input to Google image search. From the Search engine result page, it extracts the possible related search field ap- pearing on the search engine result page as it contains the label of the image. The label or labels thus obtained are stored in the set IT. FIG. A3 A sample graph depicting categories related to game controller KANIKA ET AL. | 1531 3.4 | Creating a cloud of terms related to image theme/object The terms in TC are subject specific terms and IT usually describes the image in generic terms. To increase the probability of digging out most meaningful connections from the web resources, VISTA widens the central theme of the image and tries to cull out the technical aspect of the image theme. With the use of IT, the system creates a cluster of related terms using Wikipedia categories. Wikipedia categories are terms directly related to the title of the Wikipedia page. To create a cloud of terms related to the image, we first extract the base level categories of Wikipedia. From the uniform resource locators (URLs) of Wikipedia pages corresponding to every idea in IT, VISTA extracts the category/categories. We call these categories base level categories. The set of base level ca- tegories represents the terms that are directly connected to the image idea. All such categories are stored in UIcat: U cat m I = {cat , cat cat }; here, is a Wikipedia category and . Icat T 1 2 m After collecting the base level categories, other re- lated terms are collected. To get all other terms, the system visits the Wikipedia page of the category for every category in UIcat and updates UIcat with the categories present on that page. As the process can end up col- lecting all the Wikipedia categories in UIcat, there is a need to define a termination condition. For demonstra- tion purposes, we stop the traversal once we have 500 categories in UIcat. A graph, Gcat, is created using the Wikipedia categories available in UIcat, such that G V E = { , }. cat Here, V is a set of Wikipedia categories from UIcat and E is the set of edges. Each directed edge represents that the target vertex is present as a category in the wiki page of the source vertex. If a category appears more than once, the one near to the base level category is stored. Figure A3 is a sample graph for one category of Wikipedia, which is given in the appendix. 3.5 | Correlating categories and concepts Searching for web resources using all the categories combined with core teaching concepts in TC is inefficient and may lead to diverse results. VISTA, hence, moves on with category concept pairs that show signs of related- ness through Wikipedia. If a concept from TC is present in Gcat, it is assumed that there is some relation between the two. Let TCR contain the core teaching concepts directly or indirectly related to the categories: TC c c TC c G = { : }. R r r r cat 3.6 | Initial mining of web resources VISTA is now left with concepts from TCR that are likely to have applications in direction given by the image idea, reducing information overload. The system now mines the web information to come out with meaningful connections. For this, search queries are generated. The system formulates a search for every combination of concept from TCR, categories in Gcat, and subject name: TC G S Search query = < concept from + category from + > . R cat (1) With the search queries thus generated, the system conducts preliminary search. It stores the top 10 results obtained from every search query on the search engine result page (SERP) in the list Initial Results (IR). 3.7 | Filtering most relevant results A combination of basic filtering and a secondary ranking algorithm based on semantic similarity en- ables VISTA to reach context that best represents the applications of classroom concepts. Basic filtering is applied to select best results from IR. It ensures there are no advertisements, products, and some other pro- motional websites in the results. The system filters out web pages with no occurrence of at least any two components of search query and applies a filter with a preset list of stop_words such as amazon, flipkart, and youtube. VISTA now has a list of websites that carry in- formation somehow relevant to the search query. How- ever, there may be results that are either focusing only on the classroom concepts or web pages with information confined only to the image. The system, hence, evaluates semantic closeness of every website in IR with the image idea as well as the core teaching concepts. It uses se- mantic similarity methods using the Global Vectors for Word Representation (GloVe) algorithm [13]. The overall semantic similarity score represents how much similar the content of a web page is to a given image category in Gcat and any core teaching concept in TCR. It is calcu- lated using the similarity metrics proposed by Reference [13]. A list of websites sorted according to similarity can be seen in the appendix. 1532 | KANIKA ET AL. 3.8 | Recommending the context of concepts VISTA sorts the list of websites in filtered IR in de- creasing order of overall similarity scores. The websites that are most similar to both the concepts the teacher wants to teach in class and categories adding context to the concepts are recommended as context to the teachers. 4 | MATERIALS AND METHODS VISTA is developed as an Android application that in- teracts with a Node.js server. On receiving the required inputs, the server spawns Python scripts and formulates appropriate search queries after digging out necessary search keywords. The system uses Google Cloud Vision OCR to convert notes of the teacher from Portable Document Format (PDF) to text format (https://cloud. google.com/vision/). It searches with the image as a search query on Google reverse image search. The software with the use of its huge metadata of images not only detects objects accurately, but also provides the overall theme as possible related search. To get all the specific concepts related to the image idea, VISTA uses Wikipedia. Wikipedia is a huge repository of informa- tion resulting from a continuous collaborative effort [19]. Apart from information about an entity or an event, Wikipedia provides entries on a vast number of named entities and very specialized concepts called categories [29]. The system extracts these categories using beautifulsoup (BS4), a web crawling tool. In the end, we used the Google search engine to mine the websites representing contextual information for re- commendations. The Selenium WebDriver was used to gather information from the Web. For filtering and re- moval of stop words, we use the definition given by the NLTK stop word corpus. 4.1 | Data sets We took the list of teachers from different universities and colleges in north India. For demonstration purpose, we took three popular subjects, namely Machine Learning (ML), Artificial Intelligence (AI), and Software Engineering (SE). It was observed that out of the total 110 teachers listed, 50 were associated with at least one of the three subjects. These teachers were requested to share notes on any topics from the three subjects mentioned above. Along with every class notes, they were asked to upload an image of either their sur- roundings or any specific object. With this, a total of 42 teachers responded and we collected 168 data sets consisting of notes and images. 4.2 | Survey response To assess the usefulness of VISTA in teaching, we con- ducted a feedback evaluation of the system with teachers who had contributed toward providing the data set. The survey questionnaire comprised four psychometric questions listed in Table 1. Question 1 3 had graded re- sponses on a 5 point Likert scale. Question 1 seeks to assess the relevance of the top recommended website to the class notes, whereas Question 2 assesses its relevance to the associated image. Question 3 gauges how inter- esting the recommendation is in terms of generating contextual information. Question 4 assesses the practical use of VISTA on a 3 point Likert scale. In addition to these, Question 5 was included to qualitatively analyze the experience of users with VISTA, in their own words. Every teacher first interacted with VISTA to judge the overall experience with the app. Rather than giving differ- ent recommendations to the participants, we input the same set of randomly selected class notes and an image for each subject to VISTA, as shown in Table 2. The TABLE 1 VISTA feedback questionnaire questions and their response options Q. No Question Responses Question 1 How closely is the information on the website related to the theme taught in the class? 1: Completely unrelated; 2: Hardly related; 3: Somewhat related; 4: Quite related; 5: Highly related Question 2 To what extent the information on the website is related to the image according to you? 1: Completely unrelated; 2: Hardly related; 3: Somewhat related; 4: Quite related; 5: Highly related Question 3 How interesting do you think the students would find the contextualization? 1: Completely uninteresting; 2: Hardly interesting; 3: Somewhat interesting; 4: Quite interesting; 5: Extremely interesting. Question 4 How likely are you to use VISTA in teaching? 1: Not at all; 2: May use it sometimes; 3: Will definitely use it Question 5 Describe your experiences of using VISTA in a few words Capture teachers own experiences with the VISTA. KANIKA ET AL. | 1533 corresponding recommendations that were generated by VISTA were made available to all respondents. We main- tained this uniformity to initially test VISTA with questions 1 and 2, without bias. One subject, SE, is taken twice purposely just to give an idea of how recommendations are dependent not only on subjects but on topics as well. However, for responding to the remaining questions, the teachers were encouraged to use VISTA freely with their own notes and images. All the teachers were requested to carefully go through each set of inputs and then browse the recommended websites for evaluation. 5 | RESULTS We analyze the relevance of the recommended links with the class notes as well as with the image input to the system. In addition, we gauge the usefulness of VISTA by way of enhancing contextual teaching learning and its applicability. We qualitatively assess users' satisfaction with regard to their experience with the system. 5.1 | Assessment on the relevance of recommendations Table 3 depicts the relatedness of recommended links with the associated class notes, as perceived by the teachers. We record the median and mode of the re- sponses as measures of central tendency, as mean does not have any real meaning for the ordinal Likert scale. For the AI and ML data sets, the median and mode are both 4. As many as 31 respondents (73.8%) for AI and 26 respondents (61.9%) for ML have expressed that the recommendations are quite or highly relevant to the class notes. For SE I, the mode class and median class are both 5, with 21 respondents (50%) finding the recommenda- tions highly relevant with class notes and a total 34 teachers (80.9%) finding it quite or highly relevant. For SE II data set, the median class is 4 and mode class 5 with 18 respondents (42%). There is a slight tilt to- ward class 5, but a majority of 32 respondents (76%) TABLE 2 The topic of notes, images, and topmost recommendations by VISTA Data set Subject (Theme of class) Image used Title of topmost recommendation (URL) AI Artificial Intelligence (Introduction to neural networks) Create your own board game with powerful AI from scratch (https:// towardsdatascience.com/create-your-own-board-game-with- powerful-ai-from-scratch-part-1-5dcb028002b8) SE I Software engineering (Prototype software development model) Improving the process of making rapid prototyping models from medical ultrasound images (https://www.researchgate.net/ publication/241500139_Improving_the_process_of_making_ rapid_prototyping_models_from_medical_ultrasound_images ML Machine learning (Ensemble learning) A stem based teaching platform (https://www.researchgate.net/ publication/337720543_FLUURMAT_-_A_STEM_BASED_ TEACHING_PLATFORM?sa=X%26ved=2ahUKEwiv_Pz_ 3fbmAhXULqYKHfNdDFwQFjAKegQIBBAB) SE II Software engineering (Introduction to software development lifecycle models) The fountain model and its impact on project schedule (https:// www.researchgate.net/publication/234800733_The_fountain_ model_and_its_impact_on_project_schedule) Abbreviations: AI, artificial intelligence; ML, machine learning; SE, software engineering. TABLE 3 Responses for relatedness of recommendations with class notes Relatedness classes Data set 1 2 3 4 5 Median class Mode class AI 0 1 10 22 9 4 4 SE I 1 3 4 13 21 5 5 ML 2 5 9 19 7 4 4 SE II 0 1 9 14 18 4 5 Abbreviations: AI, artificial intelligence; ML, machine learning; SE, software engineering. 1534 | KANIKA ET AL. found the recommendations either quite relevant or highly relevant to class notes. Table 4 shows the distribution of responses for the relatedness of the recommendations with the image. The mode and median for AI data set are 4, showing that the responses are focused toward the quite related cate- gory. A total of 26 respondents (61%) voted for the re- commended link to be quite related or highly related with the image. For the ML data set, 27 respondents (64%) found the recommended link to be quite related or highly related to the image. The mode and median for the responses to SE I data set are both 5, indicating a distinct tilt toward the highly relevant category. For SE II data set, 19 respondents (45%) responded to the question on relatedness with image by choosing highly re- lated. Its median is 4, but the mode is 5, indicating a slight left skew. However, a majority of 69% of re- spondents found the recommended link to be quite or highly related to the image. Table 5 summarizes the responses for relatedness in percentage, considering both class notes and images. Respondents who found recommendations irrelevant to both are those who chose Options 1(completely irrele- vant) or 2 (hardly relevant) for Questions 1 and 2. Those who chose Options 1 or 2 for Question 1 with ticked Options 3 (somewhat related) or 4 (quite related) or 5 (highly related) for Question 2 represent the number of participants who found the recommendation relevant to image but not to class notes. Similarly, a tilt toward class notes is also calculated. SE I data set received the highest responses in favor of relatedness with both the inputs. It is worth noting that 90.48% of respondents found the recommendations from VISTA at least somewhat related to both. Only 2.38% responses indicate that the information was only about class notes. Apart from the SE I data set, 88.1% of the teachers taking the survey felt that the AI data set was also appropriately related with both the elements. ML and SE II data sets received similar responses, as TABLE 4 Responses for relatedness of recommendations with image Relatedness classes Data set 1 2 3 4 5 Median class Mode class AI 1 3 12 17 9 4 4 SE I 0 1 6 13 22 5 5 ML 2 2 11 14 13 4 4 SE II 4 3 6 10 19 4 5 Abbreviations: AI, artificial intelligence; ML, machine learning; SE, software engineering. TABLE 5 Responses for relatedness with image and class notes Data set for Subjects Percentage of respondents who found recommendation irrelevant Percentage of respondents who found recommendation relevant to notes but not image Percentage of respondents who found recommendation relevant to image but not class notes Percentage of respondents who found recommendation relevant to both class notes and image AI 0.00 9.52 2.38 88.10 SE I 2.38 2.38 4.76 90.48 ML 9.52 0 7.14 83.34 SE II 2.38 14.28 0 83.34 Abbreviations: AI, artificial intelligence; ML, machine learning; SE, software engineering. KANIKA ET AL. | 1535 88.34% of the respondents found that the contextual information matched with the class theme and image in the data set. No one felt that the contextual informa- tion in the data set was inclined only toward the class notes in ML data set. SE II data set also received zero responses in favor of inclination only toward the image. 5.2 | Evaluation of contextualization and usefulness of VISTA We analyzed the responses to Question 3 to assess the interest factor of contextualization with VISTA. A majority 61.9% of the teachers found the con- textualization outcomes to be quite interesting and 11.9% respondents felt the system was somewhat in- teresting. However, a predominant majority, 97.6%, of the responses indicate varying levels of interest of the teachers, and only one of them found it completely uninteresting. 5.3 | Qualitative evaluation of users' experiences with VISTA With only one participant finding it not so useful, all others displayed the willingness to use VISTA as a teaching aid in future. The responses for overall ex- periences with VISTA indicate enthusiasm among tea- chers. The most frequent term seen in the description was educational. Teachers also found the entire idea useful, as we saw another frequently occurring phrase I found it useful. Apart from this, interest- ing, something different, and awesome were also seen as descriptions of the system. However, a few participants felt that the length of the text in the con- textual idea was too long. The results of the survey indicate clearly that the teachers are enthusiastic to use tools like VISTA. With an overall 86.31% respondents finding the contextual in- formation related to both the image as well as class notes, it can be said that VISTA recommends the context of concepts with a good degree of relevance. Apart from relevance, 97.6% of the teachers found the system inter- esting enough, as the level of contextual information is enhanced. 6 | CONCLUSION We developed a tool named VISTA to facilitate teachers by harnessing real world contextual information to add value to any concept that they want to teach in class. To the best of authors' knowledge, this is the first time that an automated system lends teachers the power of teaching with real life examples by correlating the latent information in a picture with class notes and re- commending relevant websites. Specifically, we demon- strated VISTA effectiveness in teaching computer science with an appropriate context. The results of offline feed- back evaluation indicate that 86.31% of the teachers found that the information recommended by VISTA was very relevant to both the notes of the teacher as well the real world images captured. It was observed that the teachers found the real world connections interesting and they felt it would raise the interest of students in class as well. The results of qualitative analysis are encouraging enough to work upon the idea on a larger scale. VISTA can be utilized as a suggestive tool outside the class- room also. Some teachers opined that real world con- nection, probably the most impactful form of contextual teaching, is also time consuming due to the length of text in the recommendations. This can be addressed by generating a summary of the re- commended websites. Although VISTA is currently attuned to computer science courses, it can be adapted to many disciplines with some modifications. We are working toward making it a generic tool that can be used in any subject. As some teachers stressed upon linking the concepts with recent developments, we shall also prioritize contextualization recommenda- tions that are recently added. CONFLICT OF INTERESTS The study was conducted in a technical university where there is no institutional ethics committee overseeing the study with human subjects. However, we have ensured that no subject is disadvantaged under any circumstance. We identified each teacher by a unique ad hoc identifier while conducting the experiment. Gathering of responses and analysis were done through these identifiers rather than actual identities. The data set used in the experi- ment is anonymous. The authors do not have any conflict of interest to declare. PEER REVIEW The peer review history for this article is available at https://publons.com/publon/10.1002/cae.22407 DATA AVAILABILITY STATEMENT The code for VISTA, the data sets used, and the evalua- tion details can be accessed at https://github.com/ VISTA-NSIT. The Github repository contains the code, graphs, and the contextualized results generated through VISTA that can be accessed by anyone. 1536 | KANIKA ET AL. ORCID Kanika kanika https://orcid.org/0000-0002-8352-9940 Pinaki Chakraborty http://orcid.org/0000-0002- 2010-8022 REFERENCES 1. R. Arnold, M. Langheinrich, and W. Hartmann, InfoTraffic: teaching important concepts of computer science and math through real world examples, Proceedings of the 38th SIGCSE Technical Symposium on Computer Science education, 2007, pp. 105 109. 2. M. Bishop, Teaching context in information security, J. Educ. Resources Comput. 6 (2006), no. 3, 3. 3. L. R. Carley, P. Khosla, and R. Unetich, Teaching Introduc- tion to electrical and computer engineering in context, Proc. IEEE. 88 (2000), no. 1, 8 22. 4. M. P. Chen, C. H. Chiu, and C. C. Wu, Instructional simula- tions for teaching high school computer science concepts: A technology acceptance perspective, 2010 Third IEEE Interna- tional Conference on Digital Game and Intelligent Toy En- hanced Learning, 2010, pp. 216 218. 5. S. Cooper and S. Cunningham, Teaching computer science in context, ACM Inroads. 1 (2010), 5 8. 6. T. DeClue, A theory of attrition in computer science edu- cation which explores the effect of learning theory, gender, and context, J. Comput. Sci. College. 24 (2009), no. 5, 115 121. 7. M. Derntl and K. A. Hummel, Modeling context aware e learning scenarios, Third IEEE International Conference on Pervasive Computing and Communications Workshops, 2005, pp. 337 342. 8. M. M. El Bishouty, H. Ogata, and Y. Yano, Personalized knowledge awareness map in computer supported ubiquitous learning, Sixth IEEE International Conference on Advanced Learning Technologies, 2006, pp. 817 821. 9. J. K. Gilbert, On the nature of context in chemical education, Int. J. Sci. Educ. 9 (2006), 957 976. 10. Y. Hendawati, S. Pratomo, S. Suhaedah, N. A. Lestari, T. Ridwan, and N. W. A. Majid, Contextual teaching and learning of physics at elementary school, Journal of Physics: Conference Series, vol. 1318, 2019. 11. J. W. Hu, C. Feng, Y. Liu, and R. Y. Zhu, UTSE: A game engine based simulation environment for agent, Appl. Mech. Mater. 496 (2014), 2142 2145. 12. Kanika, S. Chakraverty, and P. Chakraborty, Tools and tech- niques for teaching computer programming: A review, J. Educ. Technol. Syst. 49 (2020), 170 198. 13. Kanika, S. Chakraverty, P. Chakraborty, S. Agnihotri, S. Mohapatra, and P. Bansal, KELDEC: A Recommendation System for Extending Classroom Learning with Visual En- vironmental Cues, Proceedings of the 2019 3rd International Conference on Natural Language Processing and Information Retrieval, 2019, pp. 99 103. 14. J. Kaur and V. Gupta, Effective approaches for extraction of keywords, Int. J. Comput. Sci. Issues. 7 (2010), no. 6, 144. 15. M. Knobelsdorf and C. Schulte, Computer science in context: pathways to computer science, Proceedings of the Seventh Baltic Sea Conference on Computing Education Research, 2007, pp. 65 76. 16. J. Lave and E. Wenger, Situated learning: Legitimate periph- eral participation, Cambridge University Press, 1991. 17. J. Maloney, L. Burd, Y. Kafai, N. Rusk, B. Silverman, and M. Resnick, Scratch: a sneak preview [education], Proceed- ings of Second International Conference on Creating, Connecting and Collaborating through Computing, 2004, pp. 104 109. 18. A. Merkouris, K. Chorianopoulos, and A. Kameas, Teaching programming in secondary education through embodied com- puting platforms: Robotics and wearables, ACM Trans. Comput. Educ. 17 (2017), no. 2, 1 22. 19. R. Mihalcea, Using wikipedia for automatic word sense dis- ambiguation, Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Con- ference, 2007, pp. 196 203. 20. M. Mustafa and C. Cullingford, Teacher autonomy and cen- tralised control: The case of textbooks, Int. J. Educ. Dev. 28 (2008), no. 1, 81 88. 21. L. M ller, M. Divitini, S. Mora, V. Rivera Pelayo, and W. Stork, Context becomes content: Sensor data for computer supported reflective learning, IEEE Trans. Learn. Technol. 8 (2014), no. 1, 111 123. 22. J. Nijenhuis Voogt, P. C. Meijer, and E. Barendsen, Context based teaching and learning of fundamental computer science concepts: Exploring teachers' ideas, Proceedings of the 13th Workshop in Primary and Secondary Computing Education, 2018, pp. 1 4. 23. B. Van Oers, From context to contextualizing, Learn. instruct. 8 (1998), no. 6, 473 488. 24. A. Parush, H. Hamm, and A. Shtub, Learning histories in simulation based teaching: the effects on self learning and transfer, Comput. Educ. 39 (2002), no. 4, 319 332. 25. R. Pausch, T. Burnette, A. C. Capeheart, M. Conway, D. Cosgrove, R. DeLine, and J. White, Alice: Rapid prototyping system for virtual reality, IEEE. Comput. Graph. Appl. 15 (1995), no. 3, 8 11. 26. J. Perkins, Python Text Processing With NLTK 2.0 Cookbook, Packt Publishing Ltd, 2010. 27. A. Renkl, Situated learning, out of school and in the classroom, International Encyclopedia of the Social & Behavioral Sci- ences (P. B. Baltes, and N. J. Smelser, eds.), vol. 21, Pergamon, Amsterdam, 2001, pp. 14133 14137. 28. N. Rutten, W. R. Van Joolingen, and J. T. Van Der Veen, The learning effects of computer simulations in science education, Comput. Educ. 58 (2012), no. 1, 136 145. 29. M. Strube and S. P. Ponzetto, WikiRelate! Computing semantic relatedness using Wikipedia, AAAI 6 (2006), 1419 1424. 30. R. Taconis, and P. den Brok, (eds.) Teachers creating context based learning environments in science, Springer, Rotter- dam, 2016. 31. A. E. Tew, B. Dorn, W. D. Leahy, Jr, and M. Guzdial, Context as support for learning computer organization, J. Educ. Resources Comput. 8 (2008), no. 3, 1 18. 32. M. S. Zuhrie, M. Munoto, L. Anifah, and N. Hasanah, Learning tool for robotics basic programming based on KANIKA ET AL. | 1537 contextual teaching and learning to improve problem solving skills, Jurnal Pendidikan Teknologi dan Kejuruan 26 (2020), no. 1, 76 82. AUTHOR BIOGRAPHIES Kanika is a Senior Research Fellow at Netaji Subhas Institute of Technology (NSIT). She is working on developing educational tools, e learning models, and improving the quality of learning utiliz- ing different environments. Shampa Chakraverty is a professor at Netaji Subhas University of Technology. Her research areas include analysis of sentiment, emotion and human lan- guage, and e learning, information re- trieval, and engineering pedagogy. Pinaki Chakraborty received his B.Tech degree from Indraprastha Uni- versity and his M. Tech and PhD degrees from Jawaharlal Nehru University. He is an assistant professor at Netaji Subhas University of Technology. His area of research includes systems software and educational software. Manan Madan is a B.Tech student studying Instrumentation and Control Engineering at Netaji Subhas Institute of Technology. He is actively exploring the different areas of educational software, artificial intelligence, Natural Language Processing and Computer Vision. Gaurav Gupta is a B.Tech student studying Instrumentation and Control Engineering at Netaji Subhas Institute of Technology. He is currently explor- ing the areas of educational software, artificial intelligence, and information retrieval. Aditya Aggarwal is an integrated M.Tech student studying Computer Science Engineering at Jaypee Institute of Information Technology. He is ac- tively engaged in the areas of educational software, artificial intelligence, and in- formation retrieval. How to cite this article: K. Kanika, S. Chakraverty, P. Chakraborty, M. Madan, G. Gupta, and A. Agarwal, VISTA: A teaching aid to enhance contextual teaching. Comput Appl Eng Educ. 2021; 29:1526 1541. https://doi.org/10.1002/cae.22407 APPENDIX EXAMPLE ILLUSTRATING THE WORKING OF VISTA INPUTS: Input: As described in the paper, VISTA takes class notes and an image as input; a snippet of a portion of class notes on artificial intelligence is given below. To relate with these notes, the adjacent image was given as input. 1538 | KANIKA ET AL. Preprocessing teacher's notes The OCR extracts the following text from the image of notes: Artificial the machihes like The to associated as ideal intelligenc simlation that humans term any with learning character- istic A of are and ma machihe a and of I human programmed minic also that human problem artificial refers intelligence to their be exhibits mind solving intellighce to in think actions applied traits such The is Its ability to rationalize and take action that have The best chancc of achieving a specific goal a VISTA corrects all the spelling errors present in the extracted text and gives the following corrected words: Artificial the machines like The to associated as ideal intelligence simulation that humans term any with learning character- istic A of are and ma machine a and of I human programmed mimic also that human problem artificial refers intelligence to their be exhibits mind solving intelligence to in think actions applied traits such The is Its ability to rationalize and take action that have The best chance of achieving a specific goal a Every word in the list is identified as one part of speech: [('Artificial', 'JJ'), ('intelligence', 'NN'), ('(', '('), ('AI', 'NNP'), (')', ')'), ('refers', 'NNS'), ('to', 'TO'), ('the', 'DT'), ('simulation', 'NN'), ('of', 'IN'), ('human', 'JJ'), ('in- telligence', 'NN'), ('in', 'IN'), ('machines', 'NNS'), ('that', 'WDT'), ('are', 'VBP'), ('programmed', 'VBN'), ('to', 'TO'), ('think', 'VB'), ('like', 'IN'), ('humans', 'NNS'), ('and', 'CC'), ('mimic', 'VB'), ('their', 'PRP$'), ('actions', 'NNS'), ('.', '.')] [('The', 'DT'), ('term', 'NN'), ('may', 'MD'), ('also', 'RB'), ('be', 'VB'), ('applied', 'VBN'), ('to', 'TO'), ('any', 'DT'), ('machine', 'NN'), ('that', 'IN'), ('exhibits', 'VBZ'), ('traits', 'NNS'), ('associated', 'VBN'), ('with', 'IN'), ('a', 'DT'), ('hu- man', 'JJ'), ('mind', 'NN'), ('such', 'JJ'), ('as', 'IN'), ('learn- ing', 'NN'), ('and', 'CC'), ('problem solving', 'NN'), ('.', '.')] [('The', 'DT'), ('ideal', 'JJ'), ('characteristic', 'NN'), ('of', 'IN'), ('artificial', 'JJ'), ('intelligence', 'NN'), ('is', 'VBZ'), ('its', 'PRP$'), ('ability', 'NN'), ('to', 'TO'), ('rationalize', 'VB'), ('and', 'CC'), ('take', 'VB'), ('actions', 'NNS'), ('that', 'WDT'), ('have', 'VBP'), ('the', 'DT'), ('best', 'JJS'), ('chance', 'NN'), ('of', 'IN'), ('achieving', 'VBG'), ('a', 'DT'), ('specific', 'JJ'), ('goal', 'NN'), ('.', '.')] Selecting core teaching concepts The system gets informative words by selecting nouns and adjectives. From the text, we get the following in- formative words: ('artificial', 'JJ') ('intelligence', 'NN') ('simulation', 'NN') ('human', 'JJ') ('intelligence', 'NN') ('human', 'JJ'), ('mind', 'NN') ('learning', 'NN') ('problem', NN ) ('solving', 'NN') ('ideal', 'JJ'), ('characteristic', 'NN') ('ability', 'NN') ('best', 'JJ'), ('chance', 'NN') ('specific', 'JJ'), ('goal', 'NN') KANIKA ET AL. | 1539 All the words and phrases containing the words listed above are picked up as candidate teaching concepts. As this gives us a huge list of words, the candidate teaching concepts are filtered to get core teaching concepts through clustering based on page numbers. Following are the core teaching concepts ex- tracted from the notes: Society for Artificial Intelligence and Simulation of Behavior (AISB), 985, 986 artificial intelligence (AI), 985, 986, 999 artificial intelligence, 982 AI4People, 1002 AI for Humanitarian Action, 986 AI for Social Good, 986 AI Habitat (simulated environment), 981 Simulation, 981, 982 AI Index, 27 Machine learning techniques, 42, 161, 999 augmented finite state machine (AFSM),979 Boltzmann machine, 988 brain machine interface, 11, 971 Center for Human Compatible AI, 998 Center for Humane Technology, 1007 Acquiring the central theme of image By searching on the google image search with the image submitted by the teacher as a query, we reach the central theme of the image, Game controller. Creating a cloud of related terms Base level categories: Game controller American inven- tions, Videogame controllers. Categories present on the wiki pages of base level categories. Videogame controller: Computing input devices, Videogame accessories, Videogame control methods. American inventions: Science and technology in the United States; North American inventions. Correlating graph nodes and core teaching concepts Every core teaching concept is searched for in the graph and a path is extracted between core teaching concepts and image theme. For example, in this case, game controller and artificial intelligence are connected through the following nodes: [ game controller, input device, BIOS, firm- ware, software, computer program, expert sys- tem, artificial intelligence ] Similarly, for game controller and human in- telligence, the following is the path: [ human intelligence, intelligence, cogni- tion, learning or memory, memory, knowl- edge, sign, tab key, human interface device, input output device, input device, game controller ] Similarly, a list of the terms that are related is pre- pared for initial web search. Initial mining of web resources Search queries are formed using the terms that are some- how related to the image theme. In this particular example, < Game Controller + Artificial intelligence + Artificial intelligence > and < Game Controller + human intelligence + Artificial intelligence > Filtering of most relevant results The list of stop words is available on GitHub repository of VISTA. Following is the list of websites along with the si- milarity scores: 1540 | KANIKA ET AL. URL Similarity score https://towardsdatascience.com/create-your-own-board-game-with-powerful-ai-from-scratch-part-1-5dcb028002b8 0.53501 https://www.sheffield.ac.uk/news/nr/how-to-tackle-deal-online-abuse-social-media-gaming-video-games-new- research-tech-1.882350 0.53022 https://www.researchgate.net/publication/333695951_Assistive_game_controller_for_artificial_intelligence- enhanced_telerehabilitation_post-stroke 0.53013 https://medium.com/@shield_ai/a-conversation-with-alex-rozgo-dynamical-systems-engineer-ac76e7c39592 0.41042 https://www.researchgate.net/publication/267636559_Competing_and_Collaborating_Brains_Multi-Brain_ Computer_Interfacing 0.37191 https://www.unite.ai/ai-model-might-let-game-developers-generate-lifelike-animations/ 0.37004 https://spiral.imperial.ac.uk/bitstream/10044/1/80381/1/Admiraal-M-2020-PhD-Thesis.pdf 0.34340 https://read.hyperight.com/where-are-we-with-ai-and-ml-so-far-a-silicon-valley-perspective/ 0.32949 https://www.computer.org/csdl/journal/ci/2017/01/07307180/13rRUwInvno 0.31048 https://link.springer.com/chapter/10.1007/978-3-030-25540-4_36 0.24593 https://blogs.microsoft.com/on-the-issues/2013/02/18/how-computing-research-and-education-drives-positive- impact/ 0.24980 https://link.springer.com/chapter/10.1007/978-3-319-03680-9_29 0.21832 https://www.gamedev.net/tutorials/programming/artificial-intelligence/the-total-beginners-guide-to-game-ai- r4942/ 0.21803 https://ag.stinguide.site/4520.html 0.20989 https://www.unite.ai/deepminds-new-ai-is-able-to-learn-the-rules-of-a-game-as-it-plays/ 0.20640 https://www.hindawi.com/journals/ijcgt/2015/839721/ 0.20344 https://builtin.com/artificial-intelligence/ai-games 0.20310 https://www.gamedev.net/tutorials/programming/artificial-intelligence/the-total-beginners-guide-to-game-ai- r4942/ 0.20045 https://developer.ibm.com/technologies/artificial-intelligence/articles/machine-learning-and-gaming/ 0.20013 Recommended link Create your own board game with powerful AI from scratch https://towardsdatascience.com/create-your-own-board-game-with-powerful-ai-from-scratch KANIKA ET AL. | 1541 View publication stats