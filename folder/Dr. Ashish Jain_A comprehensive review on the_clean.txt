XXX-X-XXXX-XXXX-X/XX/$XX.00 20XX IEEE A comprehensive review on the significance and impact of deep learning in medical image analysis Mr. Shubhajit Panda Dept. of Computer Science and Engg. Manipal University Jaipur Jaipur, India shubhajitpnd11@gmail.com Dr. Mahesh Jangid Dept. of Computer Science and Engg Manipal University Jaipur Jaipur, India mahesh.jangid@jaipur.manipal.edu Dr. Ashish Jain Dept. of Information Technology Manipal University Jaipur Jaipur, India ashish.jain@jaipur.manipal.edu Abstract Healthcare sectors have evolved over the years to remain as one of the most demanding and important aspect of human lives requiring immediate services and attention in difficult times but the entire process is quite tedious and time-consuming when performed by the medical experts. However, with the advent of AI based machine learning or deep learning techniques, the medical image analysis task became quite smoother, faster and efficient delivering more optimized performances. This manuscript briefs us about the various deep learning techniques and methodologies being applied till date in the domain of medical image processing besides laying emphasis on the overview of recent advances and overall contributions being made in this field along with its associated challenges. It also throws light on the future perspective to overcome those challenges specifically using better and innovative approaches. Keywords Medical image analysis, Deep learning, Image processing, Network architecture, Modalities, Application areas. I. INTRODUCTION A. Medical Image Analysis Medical image analysis [1] is the thorough processing and analysis of the medical related images belonging to a patient s body for its diagnosis and effective treatment of any diseases or abnormalities. With the rise of AI based Deep learning, the complex process has become smoother and effective as now the images are being fed directly into the digital system and systematic scanning and analysis are being done for the extraction of relevant features in order to detect and localize the abnormalities inside patient s body which is achieved through a specialized algorithms and trained models. This has made the job of healthcare experts easier and efficient. Figure 1 shows some of the applications of Deep Learning in the field of Medical Image Processing [2]. Figure 1 Medical Image Analysis B. Deep Learning Deep learning is an advanced version of machine learning that has taken the popularity and productivity of AI to the next level. In recent times, deep learning has played a significant role in the area of medical image analysis pertinent to the task of image classification, segmentation, pattern recognition, object detection, etc., proving nearby optimum results. Deep learning algorithms like Auto-encoders, RBMs, Recurrent neural networks (RNNs), Convolutional neural networks (CNNs) and Generative Adversial networks (GANs) are some of the most widely used architectures being applied in medical analysis job. CNNs are undoubtedly the most preferred choice for performing the image classification tasks, which was first introduced in the year 1989 by LeCun. C. Content layout Section two of this manuscript briefs us about the various operations being performed on medical imaging data like segmentation, detection, registration and classifications, along with their sub-types. Section three provides us with a general description of neural network architectures for both supervised and unsupervised learning algorithms along with their significance, importance and contributions in medical imaging domain. The next section deals with the applications of deep learning in various application areas like Eyes, Brain, Lungs, Cardiac, Breasts, Digital pathology, Abdomen and Muscoskeletal. Sec 5 highlights the major challenges and issues in implementing medical analysis task using deep learning. The final section concluded the manuscript along with proving some future perspectives. II. OPERATIONS IN MEDICAL IMAGE ANALYSIS A. Segmentation: Image segmentation [9] a technique where a medical image is being partitioned into multiple segments through the creation of a visual representation of an image pixel-wise so as to extract some relevant information from it and using only those portions of the information for further processing, that would not only increase the overall efficiency of the algorithm but also save computational time and cost. There are two types of image segmentation: - 1) Organ Segmentation: - The segmentation of entire organ or substructure where a segmented mask is obtained for the region of interest using volume or shape as important parameters. U-net is one of the most recognized CNN architectures in medical image analysis [3] for segmentation purpose and has produced promising results for different applications over the past. H.Kim et. al.[4] has implemented an U-Net 3-D patch based CNN network for the purpose of segmentation of multi-organ abdominal. Similar operation was performed by Y.Chen et. al.[5] using 2-D U-Net for MR images. Left ventricle segmentation was done by [6] using fCNN. [7] has used an unsupervised approach, using task-driven GAN for X-ray images. [8] has made use of both deep CNN as well as RNN to stage the non-small cell lung cancer in an automated fashion. [9] has implemented a 3-D approach for the annotation and segmentation of the medical CT images through bidirectional RNN. [10] has performed multi-organ nuclei segmentation for histopathology images using c-GANs and obtained better results than the state- of-the-art approach. 2) Tissue Segmentation: - Tissue or Lesion segmentation works on the principle of object detection where only a small portion of the entire organ, called tissues are considered for segmentation, by drawing a boundary boxes around those tissues or region of interest. Multi-stream networks have been more popular and successful for this type of segmentation as it provides information on both local as well as global contexts as shown by [11]. U-Net can also be applied for optimized performances. Most recently, [12] performed Brain tumor segmentation using U-Net based 3D CNN for MRI images. [13] proposed a Hybrid based U-Net architecture (also called H-DenseUNet) to accurately diagnose liver tumor segmentation for CT images to overcome the limitations of both 2D and 3D fCNNS. To mitigate the issues of color or stain variations due to the presence of artefacts in H&E stained images, Error! Reference source not found. proposed a cascading approach of segmentation of tumor epithelium for the automated diagnosis of colon cancer using fuzzy c-means technique. B. Classifications: Image classification is a technique, where the images are being classified into either two categories (binary classification) or multiple categories (multi-class classification) based on the feature extractions being performed by the deep learning network architecture and algorithms. This is one of the most crucial task in medical image analysis where a decision is made if a patient s image belongs to a normal class or abnormal class/ Benign or Malignant (for binary) and grading of their disease (for multiclass), based on classification results. There are two types of image classification: - 1) Image classification: - This type of classification takes input samples and produces an output belonging to certain probability classes. Some of the common examples include detection of patient s abnormalities, classification of cancer as benign or malignant, cancer grading, etc. Variety of supervised and unsupervised algorithms using different network architectures have been implemented for the classification purpose. In one of the most recent paper, Dilbag et. al. [15] has combined multi- objective differential evolution algorithm along with CNN architecture for classifying COVID-19 patients using chest CT images. To overcome non-availability of data issues, [16] in 2019 has pro- posed a TOP-GAN network that combines the pre-trained network and GAN to classify stain-free cancer cell. [17] used end-to-end CNN network to classify skin cancer where the performance was compared on a dermatologists level. 2) Tissue classification: - Here, classification is performed on a previously identified small section of an image called lesions, which are being put into multiple categories. Some of the examples include classification of nodule in chest CT, identification and classification of breast mass contours or classification of tumors in MRI images or histopathological tissues. Multi- stream networks are best suited for this purpose that captures both local and global contextual information. In 2018, [20] used deep convolutional GANs (DCGANs), WGANs, and boundary equilibrium GANs (BEGANs) for the recognition and classification of medical imaging tissues in order to synthesize its process. In 2019, [19] implemented an OCT- NET (an enhanced version of CNN) to classify diabetes related retinal tissues. In 2020, [18] classified the brain tumors using CNN network. C. Detection: This technique primarily focuses on detecting the required portion in an image space, called region of interest where diseased cells are found, and drawing a bounding box around it. This approach is an essential step in any segmentation task where the cancerous or abnormal region of patient s body is segmented after projection. These are of two types: - 1) Landmark detection:- Also being called as organ or region detection. Till date, number of methods and techniques have been proposed for the geographical decomposition of 3D spaces into 2D orthogonal planes. In one of the most recent paper, Error! Reference source not found. performed the detection of Colorectal cancer on H & E stained histopathology images using deep learning approach. Ahuja (2020) Error! Reference source not found. worked on the detection of COVID-19 using deep transfer based learning for the lungs CT images. X Xu (2019) [23] implemented the 3D region proposal network to localize multiple organs for CT images. 2) Object detection: - Instead of complete image, only a small portion of an image space (also called lesions) is identified and processed. [25] explored the uncertainty measures in deep neural network for the lesion detection and segmentation of sclerosis. [26] performed the automated mining of annotating large- scale lesions that includes lung nodules, liver tumors, lymph nodes, etc. as well as detection of the same using deep CNN. Image patches can be used to find and localize the infections as shown by [27] in the detection of retinal lesion using CNN technique. D. Registration: Registration is a process where one image is superimposed upon another in a spatial alignment [28] involving coordinate transformation from one image to another and is one of the common medical imaging tasks especially in a clinical and complex task like monitoring of tumor growth, creation of organ atlas and image fusion. Recently, [29] laid down various research areas and challenges involved in the field of image registration. In another paper [30], demonstrated seven different methods suitable for the registration technique as well as performed a comparative analysis for the brain and lung registration. [31] performed the registration for the deformable 3D images in an unsupervised manner using CNN and spatial transformer. [32] used GANs for the multi- modal cardiac and retinal images. III. NETWORK ARCHITECTURES FOR MEDICAL IMAGE ANALYSIS Network architectures are the backbone of any deep neural network model that are implemented using an efficient algorithm (both supervised and unsupervised) for an optimized performance. In case of small datasets, some pre- trained models also play an important role like Alexnet, Res- NET, Google- NET, Mobile-Net and Inception-V3, etc. Network architectures like Multi-stream or Multilayer perceptron, CNN and RNN falls under supervised based learning algorithms whereas RBM, DBN, GANs and Auto encoders (AEs) follows unsupervised learning approach. These network architectures have been widely used for patient diagnosis in medical imaging domain and are mentioned below: - A. Multi-layer perceptron network (MLPN): This network uses the supervised learning approach in a feed-forward fashion with a maximum of two hidden layers between the input and the output layers and the output vector computation is performed based on the given input and the random weight selection (the layers being arranged in the form of directed graph). [11], [33], [34], [35] and [36] have all implemented this technique on various medical imaging applications. The activation function represents a linear combination of the input X to the neuron along with the parameters i.e. Weights (W) and Bias (B) followed by an element-wise non-linear transfer function, as denoted in Eq1. = . + (1) B. Convolutional neural network (CNN): CNN is the most preferred choice for performing an image classification tasks and has been immensely popular in medical image analysis as well. This particular network takes an input images of suitable format like RGB or Grayscale, extracts the relevant features through feature learning and finally classifying the images (in the form of feature vectors) into certain categories belonging to some probability classes based on the probability distributions graph. AlexNet was the first successful CNN architecture being designed for the purpose of ImageNet large scale visual recognition competition (ILSVRC) followed by many efficient CNN models like VGG-16, ResNet50, Inception V3, MobileNet, GoogleNet, etc. CNN architecture consists of Conv layers that used RELU as an activation function to introduce non-linearity. Pooling layers are cascaded with the conv layers for down sampling purpose. After the low level feature extractions, the fully-connected layers (which takes feature vector as input) performs high level feature extraction and finally the output layer provides the classification output using sigmoid (for binary classification) or Softmax activation function (for multi-class classification). CNN has been widely used for the Brain tumor classifications or abnormality detection especially for MRI images as shown by [18] and [56]. CNN has also been implemented for the tuberculosis analysis for CT pulmonary images [40]. CNN has proved to be very beneficial in dealing with the most recent global issue by helping the researchers in early detection of COVID-19 [22][65]. In one of the recent work, xu et.al [42] has shown the effectiveness of using multi- stream architecture in medical analysis by implementing it on various modalities like CT, MRI, PET, etc. CNN architectures are also useful for the segmentation purpose. C. Recurrent neural network (RNN): The RNN is a supervised learning technique being used to treat sequential data by predicting the next data value or likely scenario in the sequence, based on the previous input or scenarios. Time series data, audio/video or handwritten natural language can be best implemented using RNN techniques. Any RNN network suffers from a common problem called vanishing gradient problem taking place during the backpropagation phase of training [43]. One of the most popular technique to overcome this issue is the use of LSTM (Long Short Term Memory). Class imbalance is another common issue being faced in medical data analysis. In order to mitigate this particular issue, Rezai et. al. [44] recently proposed a unified version of RNN and GAN network called RNN-GAN and implemented it on ACDC-2017, HVSMR- 2016, and LiTS-2017 benchmarks dataset challenge for resolving medical image semantic segmentation problems. D. Moitra [8] used a combination of RNN & CNN for performing an automated AJCC staging of non-small cell lung cancer (NSCLC). RNN can also be used to deal with 3D images as shown by [9] who implemented a bidirectional RNN along with U-Net architecture. D. Restricted Boltzmann machine (RBM): The Restricted Boltzmann Machine (RBM) is a kind of stochastic artificial neural network based on probabilistic graphical model (which can learn probability distribution of input sets) where the neurons form a bipartite graph (which exhibits symmetric connections) with a restricted communi- cation between the layers or the nodes in a group. An RBM architecture comprises of visible unit s layer, hidden units layer and a bias which is connected to all visible and hidden units where the hidden units are independent in nature to generate unbiased samples. The energy function for a particular state (x,h), x as input units and h as hidden units, with Weights W and Bias C & B for input and hidden units respectively is represented in Eq2. as: ( , ) = (2) The RBM model has been widely used in medical image analysis tasks as shown by [45] who classified tissues based on representational learning features. RBMs models can be either standard RBM or classification RBM. Standard RBM follows unsupervised approach as shown by Pereira et. al. [46], where random forest technique was used to extract the interpretability of the extracted ML features on Brain Lesion segmentation. And the classification RBM is an extension of a standard RBM which is entirely used for classification as shown by [47] in which a combination of Deep Belief Network, Random Forest and SVM were used for the classification of skin melanoma. E. Deep belief network (DBN): The unsupervised algorithmic model acts as a generator i.e. to create new data examples from an existing one, based on probabilistic learning approach. The top layer acts similar to an undirected RBM whereas the lower layers are directed ones which goes downwards. This combination allows for the pre-training of the network as well as fine-tuning it using simple feed-forward approach. In recent paper [48], DBM was used for the purpose of the fusions of medical images (in combination with fuzzy logic technique), where DBM was used specifically for the feature extraction purpose to make a distinguishing between non-informative and informative blocks. In another work by [49], DBM was used along with CAD system in digital mammograms for the breast cancer detection. F. Auto-Encoders (AEs): Auto-encoders are a type of unsupervised learning algorithms based on ANN, that learns to reconstruct the original input data and output the reconstructed input by ignoring the noise present in the data, thus performing dimensional reduction. When the layers of the auto-encoders are stacked i.e. placing each layer at the top of another, it becomes a stacked auto-encoders (SAEs). In healthcare sectors, the auto-encoder layers follow greedy approach of learning where pre-training is done initially and then the network is fine-tuned using super- vised approach for making predictions. Convolutional auto-encoders were used widely in recent times to combine both the supervised as well as unsupervised approach for the purpose of classifications, as shown by [50], where an auto-encoder was used along with a CNN for feature extractions before classification for lung nodule images. There are many variations of auto-encoders being used by various researchers to perform the medical imaging tasks. In 2019, [51] used adversarial auto-encoders for the detection of Robust Anomaly in medical images. Another researcher [52] made use of the denoising auto- encoder for the post-processing task in order to improve the segmentation process for X-ray images. In 2020, [53] used zero-bias convolutional AE along with context-based feature augmentation technique on three public datasets for the classification of the medical images. G. Generative Adversial networks (GANs): This is a type of unsupervised learning where the network tries to learn the patterns in an input data through self- learning technique in order to generate new data or information. GANs comprises of two sub-parts: Generator and the Discriminator. The generator creates new or unseen data examples and the discriminator differentiates between the real and the fake examples being generated by the generator. GAN found its wide range of applications in medical domain which are being mostly used in combination with supervised technique like CNN to produce optimized model performances assisting in better diagnosis. GANs have also been applied in the recognition of medical image tissues in CAD systems for the MRI, CT, PET, Ultrasonic and OCT images [55]. In one of the recent work by Singh et. al. [54], several benefits of GANs have been shown in medical image generations for the analysis and diagnosis of diseases. Various frameworks of GANs have been implemented with improved efficiency for the interpretation and analysis of medical images like Cycle-GAN, Laplacian GAN (LAPGAN), Deep Convolutional GAN (DCGAN), and unsupervised UNIT. IV. APPLICATION AREAS IN MEDICAL IMAGE ANALYSIS Since its inception, deep learning based algorithms and architectures have been widely applied to various application organ areas in medical imaging like Brain, Eyes, Cardiac, Breasts, Lungs, Liver, Kidney, Muscoskeletal, etc. and have produced significantly efficient results for different modalities like MRI, CT, X-rays, US, H & E, etc. TABLE 1, TABLE 2, TABLE 3, TABLE 4, TABLE 5, TABLE 6, TABLE 7, TABLE 8 and TABLE 9 highlights the key application areas. A. Brain: TABLE 1 FEW RECENT CONTRIBUTIONS FOR BRAIN ANALYSIS Ref. Year Network Work done [74] 2020 CNN Classification of Brain tumor on MR images. [38] 2020 Any Diagnosis of Alzheimer s disease based on neuroimaging technique: Review [55] 2020 GAN Subsampled Brain MR reconstruction [56] 2020 CNN Medical image segmentation for brain tumor diagnosis: Review [75] 2019 CNN Classification of automated Brain MR images using ResNet34 [11] 2017 CNN Brain lesion segmentation using 3D multi-scaled layers. [57] 2016 CNN Diagnosis of Alzheimer s disease using deep ensemble sparse regression network B. Eyes: TABLE 2 FEW RECENT CONTRIBUTIONS FOR EYE ANALYSIS Ref. Year Network Work done [58] 2020 CNN Ophthalmic diagnosis with fundus images A critical review [59] 2020 Any Medical image analysis in diabetic retinopathy: A survey. [19] 2019 OCT-NET Classification of diabetes-related retinal diseases in optical coherence tomography [39] 2017 CNN Automated segmentation of exudates, hemorrhages, micro aneurysm [60] 2017 CNN Diabetic retinopathy detection using end-to-end CNN C. Chest: TABLE 3 FEW RECENT CONTRIBUTIONS FOR CHEST ANALYSIS Ref. Year Network Work done [76] 2020 CNN Early Lung Cancer detection through cross-validation method. [7] 2020 GAN Image segmentation for X-ray images in an unsupervised manner [40] 2020 CNN Analysis of tuberculosis severity levels from CT pulmonary images based on enhanced residual deep learning architecture [61] 2019 LR Detection of Pneumonia in Chest X-Rays [62] 2017 CNN Tuberculosis detection using MIL framework that produces heat map of suspicious regions via deconvolution from X-ray images. [63] 2016 CNN Detection of nodules using 2D CNN that processes small patches of CT images around a nodule TABLE 4 FEW RECENT CONTRIBUTIONS FOR COVID-19 Ref. Year Network Modality Work done [15] 2020 CNN CT Classification of COVID- 19 patients using multi- objective differential evolution-based CNN [77] 2021 CNN CT & XR A Comprehensive survey on COVID-19 detection using CT and X-ray images [64] 2020 CVR- NET CT & XR CVR-Net: Recognition of novel coronavirus from chest radiography images [65] 2020 CNN CT Classification of the COVID-19 using DenseNet201 architecture. D. Digital Pathology: TABLE 5 FEW RECENT CONTRIBUTIONS FOR DIGITAL PATHOLOGY ANALYSIS Ref. Year Network Modality Work done [66] 2021 C-GANs H&E Semi-supervised approach for stain normalization [67] 2020 CNN H&E Context-Aware CNN for grading of Colorectal Cancer Histopathology images [78] 2019 CNN WSI Whole slide imaging in digital pathology using CNN approach [68] 2018 Any Any Challenges and opportunities of AI in Digital Pathology [79] 2019 CNN various Challenges of explainable - AI in digital pathology using augmented method [3] 2015 U-NET EM Segmentation of cell using U- NET E. Breasts: TABLE 6 FEW RECENT CONTRIBUTIONS FOR BREAST ANALYSIS Ref. Year Network Modality Work done [69] 2020 CNN various Image analysis for breast cancer: An extensive survey [69] 2020 CNN WSI Prediction of breast tumor proliferation; TUPAC16 [70] 2018 CNN H&E Breast cancer histology image analysis [80] 2017 CNN MG Classification of malignant masses from the benign cysts for mass/normal patches using pre-trained CNN [81] 2016 SAE MG Classification of breast density using unsupervised based CNN with SAE for feature extractions. F. Cardiac: TABLE 7 FEW RECENT CONTRIBUTIONS FOR CARDIAC ANALYSIS Ref. Year Network Modality Work done [82] 2020 CNN & RBM CT & MRI A promising challenge on the diagnosis of cardiovascular images [83] 2019 SD-NET CT & MRI Analysis of cardiac images using Disentangled representation learning. [6] 2018 CNN MRI Left ventricle segmentation [71] 2017 CNN & RBM MRI Segmentation using semi- supervised learning [84] 2017 DBN MRI Left ventricle segmentation by initializing a level set framework G. Abdomen: TABLE 8 FEW RECENT CONTRIBUTIONS FOR ABDOMEN ANALYSIS Ref. Year Network Modality Work done [72] 2020 CNN Any A review on abdominal images using deep learning approach. [4] 2020 U-NET CT Abdominal multi-organ auto-segmentation using 3D-patch-based deep CNN [73] 2019 CNN CT Automated segmentation of abdominal multiple organs using fCNN. [87] 2018 CNN CT Kidney segmentation [86] 2017 CNN CT 3D CNN based approach for classification; SIVER07 H. Muscoskeletal: TABLE 9 FEW RECENT CONTRIBUTIONS FOR MUSCOSKELETAL Ref. Year Network Modality Work done [89] 2021 CNN SGH Analysis of microscopic images for Bone tissues [24] 2019 CNN XR Abnormality Detection in Musculoskeletal Radio- graphs using Capsule Network [88] 2017 CNN XR MURA: A large dataset for abnormality detection in musculoskeletal radio- graphs V. LIMITATIONS IN MEDICAL ANALYSIS USING DEEP LEARNING A. Overfitting: The situation in which a deep learning model shows overly better results in training set but poor results in the test or validation set is called overfitting , which is a common issue that occurs while training in medical image analysis [261]. In short, the network fails to generalize the data examples. Data scarcity and complex network architecture are the basic reasons for this issue. Use of dropout layers and suitable augmentation techniques can resolve this issue. B. Class Imbalance: In this scenario the proportion of negative or normal class is relatively much higher as compared to the positive or diseased class, which results in the un- balancing of data. The end result is the variations in loss for both set of class data that gives poor network performance. Re-sampling of the data can also be an effective solution for handling class imbalance issues [263] along with patch sampling approach [264]. C. Image Labelling: Another common issue in medical analysis tasks being the incorrect or incomplete assignment of labels for sample images, which reduces the performance complexities. Structured labelling approach like PACS has been used for efficient training and categorization by some authors [196] [145]. D. Validating Ground truth labels: Availability of ground truth labels is a major challenge these days, where the user expects major boost in accuracy with limited dataset. The difficulties level for the generations of these annotations varies from task to task. The process becomes more time-consuming when dealing with complex multiple anatomical structures. One of the most important approach that has brought success in recent years is using the combination of supervised and unsupervised approach, using small dataset with detailed annotations with large data-sets with weak annotations as well as exploiting the image properties to extend the GT database. VI. CONCLUSIONS AND FUTURE SCOPE Deep learning has undoubtedly played an immense role in the field of medical image processing and is yet to benefit more in the particular domain. The particular manuscript provides us with a clear idea about various deep learning operations for medical analysis like segmentation, detection, classification and registration along with some of the recent contributions using the same for specific applications. Various deep learning based architecture have also been highlighted like MLPNN, CNN, RNN, GAN, DBM, RBM and AEs/ SAEs for both supervised and unsupervised learning algorithms which has proven to be the basic framework for the image analysis task. The manuscript briefs us with the various application areas of medical imaging like Brain, Eyes, Chest, Abdomen, Cardiac, Breasts, Digital pathology and Muscoskeletal along with the list of some recent contributions. Finally, various challenges in the analysis work have been highlighted along with possible future measures. Despite its immense popularity and success, there always remains certain loopholes in the area of medical image analysis which opens up a great deal of scopes and opportunities in future to examine, analyze and identify the same for providing enhance and optimized solutions with improved accuracies. REFERENCES [1] Geert Litjens, Thijs Kooi, Babak Ehteshami Bejnordi, Arnaud Arindra Adiyoso Setio Francesco Ciompi, Mohsen Ghafoorian, Jeroen Awm Van Der Laak, Bram Van Ginneken, and Clara I Sa nchez. A survey on deep learning in medical image analysis. Medical image analysis, 42:60 88, 2017. [2] Tongxue Zhou, Su Ruan, and St e phane Canu. A review: Deep learning for medical image segmentation using multi-modality fusion. Array, 3:100004, 2019. [3] Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks for biomedical image segmentation. In International Conference on Medical image computing and computer-assisted intervention, pages 234 241. Springer, 2015. [4] Hojin Kim, Jinhong Jung, Jieun Kim, Byungchul Cho, Jungwon Kwak, Jeong Yun Jang,Sang-wook Lee, June-Goo Lee, and Sang Min Yoon. Abdominal multi-organ auto- segmentation using 3d- patch-based deep convolutional neural network. Scientific Reports, 10(1):1 9, 2020. [5] Yuhua Chen, Dan Ruan, Jiayu Xiao, Lixia Wang, Bin Sun, Rola Saouaf, Wensha Yang, De-biao Li, and Zhaoyang Fan. Fully automated multi-organ segmentation in abdominal magnetic resonance imaging with deep neural networks. arXiv preprint arXiv:1912.11000, 2019. [6] Mina Nasr-Esfahani, Majid Mohrekesh, Mojtaba Akbari, SM Reza Soroushmehr, Ebrahim Nasr-Esfahani, Nader Karimi, Shadrokh Samavi, and Kayvan Najarian. Left ventricle segmentation in cardiac mr images using fully convolutional network. In 2018 40th Annual In- ternational Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), pages 1275 1278. IEEE, 2018. [7] Yue Zhang, Shun Miao, Tommaso Mansi, and Rui Liao. Unsupervised x-ray image segmentation with task driven generative adversarial networks. Medical Image Analysis, 62:101664, 2020. [8] Dipanjan Moitra and Rakesh Kr Mandal. Automated ajcc staging of non-small cell lung cancer (nsclc) using deep convolutional neural network (cnn) and recurrent neural network (rnn). Health information science and systems, 7(1):14, 2019. [9] Soopil Kim, Sion An, Philip Chikontwe, and Sang Hyun Park. Bidirectional rnn-based few shot learning for 3d medical image segmentation. arXiv preprint arXiv:2011.09608, 2020. [10] Faisal Mahmood, Daniel Borders, Richard J Chen, Gregory N McKay, Kevan J Salimian, Alexander Baras, and Nicholas J Durr. Deep adversarial training for multi-organ nuclei segmentation in histopathology images. IEEE transactions on medical imaging, 39(11):3257 3267, 2019. [11] Konstantinos Kamnitsas, Christian Ledig, Virginia FJ Newcombe, Joanna P Simpson, Andrew D Kane, David K Menon, Daniel Rueckert, and Ben Glocker. Efficient multi-scale 3d cnn with fully connected crf for accurate brain lesion segmentation. Medical image analysis, 36:61 78, 2017. [12] MS Abirami, M Uma, R Gurumoorthy, Shobhit Narayan, and Jassim Hameed. Brain tumor segmentation in mri images using unet based 3d cnn. Annals of the Romanian Society for Cell Biology, pages 325 335, 2021. [13] Xiaomeng Li, Hao Chen, Xiaojuan Qi, Qi Dou, Chi-Wing Fu, and Pheng-Ann Heng. H-denseunet: hybrid densely connected unet for liver and tumor segmentation from ct volumes.IEEE transactions on medical imaging, 37(12):2663 2674, 2018. [14] Arvydas Laurinavicius, and Mohammad Ilyas. A cascade-learning approach for automated segmentation of tumour epithelium in colorectal cancer. Expert Systems with Applications, 118:539 552, 2019. [15] Dilbag Singh, Vijay Kumar, and Manjit Kaur. Classification of covid- 19 patients from chest ct images using multi-objective differential evolution based convolutional neural networks.European Journal of Clinical Microbiology & Infectious Diseases, pages 1 11, 2020. [16] Moran Rubin, Omer Stein, Nir A Turko, Yoav Nygate, Darina Roitshtain, Lidor Karako, Itay Barnea, Raja Giryes, and Natan T Shaked. Top-gan: Stain-free cancer cell classification using deep learning with a small training set. Medical image analysis, 57:176 185, 2019. [17] Andre Esteva, Brett Kuprel, Roberto A Novoa, Justin Ko, Susan M Swetter, Helen M Blau,and Sebastian Thrun. Dermatologist-level classification of skin cancer with deep neural networks. nature, 542(7639):115 118, 2017. [18] Sarah Ali Abdelaziz Ismael, Ammar Mohammed, and Hesham Hefny. An enhanced deeplearning approach for brain cancer mri images classification using residual networks. Artifi- cial Intelligence in Medicine, 102:101779, 2020. [19] Oscar Perdomo, Hern a n Rios, Francisco J Rodr guez, Sebastia n Ota lora, Fabrice Meriaudeau, Henning Mu ller, and Fabio A Gonza lez. Classification of diabetes-related retinal diseases using a deep learning approach in optical coherence tomography. Computer methods and programs in biomedicine, 178:181 189, 2019. [20] Qianqian Zhang, Haifeng Wang, Hongya Lu, Daehan Won, and Sang Won Yoon. Medical image synthesis with generative adversarial networks for tissue recognition. In 2018 IEEE International Conference on Healthcare Informatics (ICHI), pages 199 207. IEEE, 2018. [21] Lin Xu, Blair Walker, Peir-In Liang, Yi Tong, Cheng Xu, Yu Chun Su, and Aly Karsan. Colorectal cancer detection based on deep learning. Journal of Pathology Informatics, 11, 2020. [22] Sakshi Ahuja, Bijaya Ketan Panigrahi, Nilanjan Dey, Venkatesan Rajinikanth, and Tapan Ku- mar Gandhi. Deep transfer learning-based automated detection of covid-19 from lung ct scan slices. 2020. [23] Xuanang Xu, Fugen Zhou, Bo Liu, Dongshan Fu, and Xiangzhi Bai. Efficient multiple organ localization in ct images using 3d region proposal network. IEEE transactions on medical imaging, 38(8):1885 1898, 2019. [24] AFM Saif, Celia Shahnaz, Wei-Ping Zhu, and M Omair Ahmad. Abnormality detection in musculoskeletal radiographs using capsule network. IEEE Access, 7:81494 81503, 2019. [25] Tanya Nair, Doina Precup, Douglas L Arnold, and Tal Arbel. Exploring uncertainty measures in deep networks for multiple sclerosis lesion detection and segmentation. Medical image analysis, 59:101557, 2020. [26] Ke Yan, Xiaosong Wang, Le Lu, and Ronald M Summers. Deeplesion: automated mining of large-scale lesion annotations and universal lesion detection with deep learning. Journal of Medical Imaging, 5(3):036501, 2018. [27] Carson Lam, Caroline Yu, Laura Huang, and Daniel Rubin. Retinal lesion detection with deep learning using image patches. Investigative ophthalmology & visual science, 59(1):590 596, 2018. [28] Derek LG Hill, Philipp G Batchelor, Mark Holden, and David J Hawkes. Medical image registration. Physics in medicine & biology, 46(3):R1, 2001. [29] Grant Haskins, Uwe Kruger, and Pingkun Yan. Deep learning in medical image registration: a survey. Machine Vision and Applications, 31(1):8, 2020. [30] Yabo Fu, Yang Lei, Tonghe Wang, Walter J Curran, Tian Liu, and Xiaofeng Yang. Deep learning in medical image registration: a review. Physics in Medicine & Biology, 2020. [31] Guha Balakrishnan, Amy Zhao, Mert R Sabuncu, John Guttag, and Adrian V Dalca. An unsupervised learning model for deformable medical image registration. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 9252 9260, 2018. [32] Dwarikanath Mahapatra, Bhavna Antony, Suman Sedai, and Rahil Garnavi. Deformable medical image registration using generative adversarial networks. In 2018 IEEE 15th Inter- national Symposium on Biomedical Imaging (ISBI 2018), pages 1449 1453. IEEE, 2018. [33] Pim Moeskops, Jelmer M Wolterink, Bas HM van der Velden, Kenneth GA Gilhuijs, Tim Leiner, Max A Viergever, and Ivana Is gum. Deep learning for multi-task medical image segmentation in multiple modalities. In International Conference on Medical Image Computing and Computer-Assisted Intervention, pages 478 486. Springer, 2016. [34] Youyi Song, Ling Zhang, Siping Chen, Dong Ni, Baiying Lei, and Tianfu Wang. Accurate segmentation of cervical cytoplasm and nuclei based on multiscale convolutional network and graph partitioning. IEEE Transactions on Biomedical Engineering, 62(10):2421 2433, 2015 [35] Kinam Kwon, Dongchan Kim, and HyunWook Park. A parallel mr imaging method using multilayer perceptron. Medical physics, 44(12):6209 6224, 2017. [36] ZhiFei Lai and HuiFang Deng. Medical image classification based on deep features extracted by deep model and statistic feature fusion with multilayer perceptron. Computational intelligence and neuroscience, 2018, 2018. [37] Moloud Abdar, Neil Yuwen Yen, and Jason Chi-Shun Hung. Improving the diagnosis of liver disease using multilayer perceptron neural network and boosted decision trees. Journal of Medical and Biological Engineering, 38(6):953 965, 2018. [38] Mr Amir Ebrahimighahnavieh, Suhuai Luo, and Raymond Chiong. Deep learning to detect alzheimer s disease from neuroimaging: A systematic literature review. Computer Methods and Programs in Biomedicine, 187:105242, 2020. [39] Jen Hong Tan, Hamido Fujita, Sobha Sivaprasad, Sulatha V Bhandary, A Krishna Rao, Kuang Chua Chua, and U Rajendra Acharya. Automated segmentation of exudates, haem- orrhages, microaneurysms using single convolutional neural network. Information sciences, 420:66 76, 2017. [40] Xiaohong W Gao, Carl James-Reynolds, and Edward Currie. Analysis of tuberculosis severity levels from ct pulmonary images based on enhanced residual deep learning architecture.Neurocomputing, 392:233 244, 2020. [41] Suzan Omar, Abdelghany Mohammed Motawea, and Rabab Yasin. High-resolution ct features of covid-19 pneumonia in confirmed cases. Egyptian Journal of Radiology and Nuclear Medicine, 51(1):1 9, 2020. [42] Yan Xu. Deep learning in multimodal medical image analysis. In International Conference on Health Information Science, pages 193 200. Springer, 2019. [43] Yoshua Bengio, Patrice Simard, and Paolo Frasconi. Learning long- term dependencies with gradient descent is difficult. IEEE transactions on neural networks, 5(2):157 166, 1994. [44] Mina Rezaei, Haojin Yang, and Christoph Meinel. Recurrent generative adversarial network for learning imbalanced medical image semantic segmentation. Multimedia Tools and Ap- plications, pages 1 20, 2019. [45] Gijs van Tulder and Marleen de Bruijne. Learning features for tissue classification with the classification restricted boltzmann machine. In International MICCAI workshop on medical computer vision, pages 47 58. Springer, 2014. [46] S e rgio Pereira, Raphael Meier, Richard McKinley, Roland Wiest, Victor Alves, Carlos ASilva, and Mauricio Reyes. Enhancing interpretability of automatically extracted machine learning features: application to a rbm-random forest system on brain lesion segmentation. Medical image analysis, 44:228 244, 2018 [47] A Sherly Alphonse and MS Starvin. A novel and efficient approach for the classification of skin melanoma. Journal of Ambient Intelligence and Humanized Computing, pages 1 25, 2020. [48] Manjit Kaur and Dilbag Singh. Fusion of medical images using deep belief networks.Cluste Computing, pages 1 15, 2019. [49] Mugahed A Al-antari, Mohammed A Al-masni, Sung-Un Park, JunHyeok Park, Mohamed K Metwally, Yasser M Kadah, Seung-Moo Han, and Tae-Seong Kim. An automatic computer- aided diagnosis system for breast cancer in digital mammograms via deep belief network. Journal of Medical and Biological Engineering, 38(3):443 456, 2018. [50] Min Chen, Xiaobo Shi, Yin Zhang, Di Wu, and Mohsen Guizani. Deep features learning for medical image analysis with convolutional autoencoder neural network. IEEE Transactions on Big Data, 2017. [51] Laura Beggel, Michael Pfeiffer, and Bernd Bischl. Robust anomaly detection in images using adversarial autoencoders. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pages 206 222. Springer, 2019. [52] Agostina J Larrazabal, Cesar Martinez, and Enzo Ferrante. Anatomical priors for image segmentation via post-processing with denoising autoencoders. In International Conference on Medical Image Computing and Computer-Assisted Intervention, pages 585 593. Springer, 2019. [53] Mohammed Abdul Wajeed and Vallamchetty Sreenivasulu. Image based tumor cells identification using convolutional neural network and auto encoders. Traitement du Signal, 36(5):445 453, 2019. [54] Nripendra Kumar Singh and Khalid Raza. Medical image generation using generative adversarial networks. arXiv preprint arXiv:2005.10687, 2020. [55] Roy Shaul, Itamar David, Ohad Shitrit, and Tammy Riklin Raviv. Subsampled brain mri reconstruction by generative adversarial neural networks. Medical Image Analysis, page 101747, 2020. [56] Sindhu Devunooru, Abeer Alsadoon, PWC Chandana, and Azam Beg. Deep learning neural networks for medical image segmentation of brain tumours for diagnosis: a recent review and taxonomy. J Ambient Intell Human Comput, 2020. [57] Heung-Il Suk and Dinggang Shen. Deep ensemble sparse regression network for alzheimer s disease diagnosis. In International Workshop on Machine Learning in Medical Imaging, pages 113 121. Springer, 2016. [58] Sourya Sengupta, Amitojdeep Singh, Henry A Leopold, Tanmay Gulati, and Vasudevan Lak- shminarayanan. Ophthalmic diagnosis using deep learning with fundus images a critical review. Artificial Intelligence in Medicine, 102:101758, 2020. [59] Skylar Stolte and Ruogu Fang. A survey on medical image analysis in diabetic retinopathy.Medical Image Analysis, page 101742, 2020. [60] Kevis-Kokitsi Maninis, Jordi Pont-Tuset, Pablo Arbel a ez, and Luc Van Gool. Deep retinal image understanding. In International conference on medical image computing and computer-assisted intervention, pages 140 148. Springer, 2016. [61] Benjamin Antin, Joshua Kravitz, and Emil Martayan. Detecting pneumonia in chest x-rays with supervised learning. Semanticscholar. org, 2017. [62] H Kim and Sangheum Hwang. Scale-invariant feature learning using deconvolutional neural networks for weakly-supervised semantic segmentation. arXiv preprint arXiv:1602.04984, 2016. [63] Wei Li, Peng Cao, Dazhe Zhao, and Junbo Wang. Pulmonary nodule classification with deep convolutional neural networks on computed tomography images. Computational and mathematical methods in medicine, 2016. [64] Md Hasan, Md Alam, Md Elahi, E Toufick, Shidhartho Roy, Sifat Redwan Wahid, et al. Cvr- net: A deep convolutional neural network for coronavirus recognition from chest radiography images. arXiv preprint arXiv:2007.11993, 2020. [65] Aayush Jaiswal, Neha Gianchandani, Dilbag Singh, Vijay Kumar, and Manjit Kaur. Classification of the covid-19 infected patients using densenet201 based deep transfer learning. Journal of Biomolecular Structure and Dynamics, pages 1 8, 2020. [66] Cong Cong, Sidong Liu, Antonio Di Ieva, Maurice Pagnucco, Shlomo Berkovsky, and Yang Song. Semi-supervised adversarial learning for stain normalisation in histopathology images. In International Conference on Medical Image Computing and Computer-Assisted Intervention, pages 581 591. Springer, 2021. [67] Muhammad Shaban, Ruqayya Awan, Muhammad Moazam Fraz, Ayesha Azam, Yee-Wah Tsang, David Snead, and Nasir M Rajpoot. Context-aware convolutional neural network for grading of colorectal cancer histology images. IEEE transactions on medical imaging, 39(7):2395 2405, 2020. [68] Hamid Reza Tizhoosh and Liron Pantanowitz. Artificial intelligence and digital pathology: challenges and opportunities. Journal of pathology informatics, 9, 2018. [69] Taye Girma Debelee, Friedhelm Schwenker, Achim Ibenthal, and Dereje Yohannes. Survey of deep learning in breast cancer image analysis. Evolving Systems, 11(1):143 163, 2020 [70] Alexander Rakhlin, Alexey Shvets, Vladimir Iglovikov, and Alexandr A Kalinin. Deep convolutional neural networks for breast cancer histology image analysis. In International Con- ference Image Analysis and Recognition, pages 737 744. Springer, 2018. [71] Wenjia Bai, Ozan Oktay, Matthew Sinclair, Hideaki Suzuki, Martin Rajchl, Giacomo Tar-roni, Ben Glocker, Andrew King, Paul M Matthews, and Daniel Rueckert. Semi-supervised learning for network-based cardiac mr image segmentation. In International Conference on Medical Image Computing and Computer-Assisted Intervention, pages 253 260. Springer, 2017. [72] Arshia Rehman and Fiaz Gul Khan. A deep learning based review on abdominal images. Multimedia Tools and Applications, pages 1 32, 2020. [73] Jieun Kim and June-Goo Lee. Deep-learning-based fast and fully automated segmentation on abdominal multiple organs from ct. In International Forum on Medical Imaging in Asia 2019, volume 11050, page 110500K. International Society for Optics and Photonics, 2019. [74] Sarah Ali Abdelaziz Ismael, Ammar Mohammed, and Hesham Hefny. An enhanced deep learning approach for brain cancer mri images classification using residual networks. Artifi- cial Intelligence in Medicine, 102:101779, 2020. [75] Muhammed Talo, Ulas Baran Baloglu,O zal Y ld r m, and U Rajendra Acharya. Application of deep transfer learning for automated brain abnormality classification using mr images.Cognitive Systems Research, 54:176 188, 2019 [76] Samir Bandyopadhyay and Shawni Dutta. Early lung cancer prediction using neural network with cross-validation. 2020. [77] Sajib Kumar Saha Joy, Farzad Ahmed, Mayeesha Humaira, Amit Saha Ami, Shimul Paul, Md Abidur Rahman Khan Jim, et al. A comprehensive survey of covid-19 detection using medical images. [78] Mark D Zarella, Douglas Bowman, Famke Aeffner, Navid Farahani, Albert Xthona,Syeda Fatima Absar, Anil Parwani, Marilyn Bui, and Douglas J Hartman. A practical guide to whole slide imaging: a white paper from the digital pathology association. Archives of pathology & laboratory medicine, 143(2):222 234, 2019. [79] Andreas Holzinger, Bernd Malle, Peter Kieseberg, Peter M Roth, Heimo M u ller, RobertReihs, and Kurt Zatloukal. Towards the augmented pathologist: Challenges of explainable-ai in digital pathology. arXiv preprint arXiv:1712.06657, 2017. [80] Thijs Kooi, Bram van Ginneken, Nico Karssemeijer, and Ard den Heeten. Discriminating solitary cysts from soft tissue lesions in mammography using a pretrained deep convolutional neural network. Medical physics, 44(3):1017 1027, 2017. [81] Michiel Kallenberg, Kersten Petersen, Mads Nielsen, Andrew Y Ng, Pengfei Diao, Christian Igel, Celine M Vachon, Katharina Holland, Rikke Rass Winkel, Nico Karssemeijer, et al. Unsupervised deep learning applied to breast density segmentation and mammographic risk scoring. IEEE transactions on medical imaging, 35(5):1322 1331, 2016. [82] Kelvin KL Wong, Giancarlo Fortino, and Derek Abbott. Deep learning- based cardiovascularimage diagnosis: A promising challenge. Future Generation Computer Systems, 110:802 811, 2020. [83] Agisilaos Chartsias, Thomas Joyce, Giorgos Papanastasiou, Scott Semple, Michelle Williams, David E Newby, Rohan Dharmakumar, and Sotirios A Tsaftaris. Disentangled representation learning in cardiac image analysis. Medical image analysis, 58:101535, 2019. [84] Tuan Anh Ngo, Zhi Lu, and Gustavo Carneiro. Combining deep learning and level set for the automated segmentation of the left ventricle of the heart from cardiac cine magnetic resonance. Medical image analysis, 35:159 171, 2017. [85] Meg F Bobo, Shunxing Bao, Yuankai Huo, Yuang Yao, Jack Virostko, Andrew J PlassardIlwoo Lyu, Albert Assad, Richard G Abramson, Melissa A Hilmes, et al. Fully convolutional neural networks improve abdominal organ segmentation. In Medical Imaging 2018: Image Processing, volume 10574, page 105742V. International Society for Optics and Photonics, 2018. [86] Fang Lu, Fa Wu, Peijun Hu, Zhiyi Peng, and Dexing Kong. Automatic 3d liver location and segmentation via convolutional neural network and graph cut. International journal of computer assisted radiology and surgery, 12(2):171 182, 2017. [87] William Thong, Samuel Kadoury, Nicolas Pich e , and Christopher J Pal. Convolutional net- works for kidney segmentation in contrast- enhanced ct scans. Computer Methods in Biome- chanics and Biomedical Engineering: Imaging & Visualization, 6(3):277 282, 2018. [88] Pranav Rajpurkar, Jeremy Irvin, Aarti Bagul, Daisy Ding, Tony Duan, Hershel Mehta, Bran- don Yang, Kaylie Zhu, Dillon Laird, Robyn L Ball, et al. MURA: Large dataset for abnormality detection in musculoskeletal radiographs. arXiv preprint arXiv:1712.06957, 2017. [89] Forouhesh Tehrani, Kayvan, Emily G. Pendleton, W. Michael Southern, Jarrod A. Call, and Luke J. Mortensen. "Spatial frequency metrics for analysis of microscopic images of musculoskeletal tissues." Connective Tissue Research 62, no. 1: 4-14 (2021).