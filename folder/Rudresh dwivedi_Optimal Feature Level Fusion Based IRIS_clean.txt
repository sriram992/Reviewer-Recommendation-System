See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/349055114 Optimal Feature Level Fusion Based IRIS and Fingerprint Multimodal Biometric System using Improved Multi Kernel SVM Research February 2021 CITATION 1 READS 138 1 author: Some of the authors of this publication are also working on these related projects: Machine Learning View project Technology Implementation for Water Management System in Gurugram . A DST sponsored project, File No. DST/TM/WTI/DD/2K17/57 View project Mamta Dahiya SGT University, Gurgaon 35 PUBLICATIONS 10 CITATIONS SEE PROFILE All content following this page was uploaded by Mamta Dahiya on 05 February 2021. The user has requested enhancement of the downloaded file. International Journal of Innovative Technology and Exploring Engineering (IJITEE) ISSN: 2278-3075, Volume-8 Issue-6S, April 2019 660 Published By: Blue Eyes Intelligence Engineering & Sciences Publication Retrieval Number: F61480486S19\19 BEIESP Abstract: The modern society attained secured mechanism to lead their processes in different applications such as airports, hospitals, banks, autonomous and non-autonomous institutions, etc with the improvement of biometric system. Nowadays, biometric technique is employed for human identification process based iris, fingerprint, ear and palm etc. In order to render the effective biometric system we have improved multi-model biometric recognition established on iris and fingerprint. Our work is established on three modules such as recognition module, pre-processing module, and feature extraction module. Then, in the feature extraction module, we processed feature extraction established on changed Local Binary Pattern (MLBP) feature and GLCM features. Fish Swarm optimization algorithm is applied for processing feature level fusion. For recognition, developed Multi Kernel Support vector machine (IMKSVM is inaugurated. In the document, several kernels are integrated to give shape to an innovative hybrid kernel which incredibly improves the classification task of segregating the training data. By way of offering the hybrid kernel, the SVMs gainfully achieve the flexibility to pick the appropriate shape of the threshold, for which it is not essential that it is linear and possesses the identical functional shape for the entire data, in view of its non-parametric function and local operation. We estimated our suggested technique with existing technique therefore; we get better recognition accuracy and successfully implemented our technique in MATLAB platform. Index Terms: Biometric System, Preprocessing, feature extraction, Reorganization, Local Binary Pattern, GLCM Feature, Fish Swarm Optimization. I. INTRODUCTION Biometrics is a currently emerged method which helps to estimate the individual attributes like the iris, face, fingerprints, retina, hand geometry, voice or signatures [4] [11]. Nowadays, it gets a considerable in attention in the present security technologies currently due to its applications in routine procedures such as, surveillance, and forensic processes like criminal identification [2]. The Biometrics has emerged as the hot topic of discussion. It assumes zooming significance in the modern world on account of its extensive applications, projecting the utmost accuracy as it ultimate motive. Revised Manuscript Received on December 22, 2018. Rinky Ahuja, Research Scholar, Ansal University, India Ms. Mamta Dahiya, Asst. Professor, Ansal University, India Of late, the face and iris biometrics have emerged as the ideal modalities with widest appeal vis- -vis the parallel ones like the fingerprint, retina, hand geometry, voice or signature. The problems in the biometric real world applications habitually include those arising from the noise, sub-standard quality of acquisition data, intra-class inconsistency, non-universality, hacking trouble, etc. In uni-modal biometric, these problems can able to handle with an individual matcher. In order to handle the corresponding phenomenon, the inquisitive investigators have turned no stone unturned by giving special emphasize to the launching of multimodal-biometric techniques which are well-endowed with the skills of successfully tackling the related hassles by means of offering multiple pieces of information of the identical user [3] [12]. Endowed with the uni-modal biometric system, these techniques find their waterloo in giving a helping hand to achieve a superior, consistent and safe system. In the arena of the surveillance and forensic science also, it is the need of the hour that a consistent and vastly safe system is put in place which shows ample strength to ward off any threats and thereby survive in the backdrop of even free scenarios. Therefore, in order to deal with these issues, require for the improvement of multi-model system is enhanced in all the fields. In this regard, the multimodal biometric technique emerges as the ray of hope as it is competent to overwhelm the related hassles by means of integrating or inducing two or more biometric modalities. There is no second opinion among the investigators that a multimodal biometric technique founded on several biometric traits is capable of ushering in superior performance, thereby meeting with the harsher real-world requisites. The deft blend of two or more biometrics of minute uniqueness paves the way for an ultimate solution which endears itself as the ideal one to be applied by a huge group of users [13]. In addition, with the help of multi-model biometric most of the security issues can be solved and the level of security is also enhanced. In the arena of the multi-model biometrics, five distinct kinds of multi-biometric system hold the sway and they are the multi-sample, multi-instance, multi-sensor, multi-algorithm and multi-modal biometrics. When equating with uni-model, the multi-model biometric system demonstrate better recognition and it has some characteristics such as higher reliability to develop fault tolerance and minimize noise, broader applicability to the complex environment, Optimal Feature Level Fusion Based IRIS and Fingerprint Multimodal Biometric System using Improved Multi Kernel SVM Rinky Ahuja, Mamta Dahiya International Journal of Innovative Technology and Exploring Engineering (IJITEE) ISSN: 2278-3075, Volume-X, Issue-X 661 Published By: Blue Eyes Intelligence Engineering & Sciences Publication Retrieval Number: F61480486S19\19 BEIESP Where uni-modal biometric identification has been ineffective, stronger security that raises recognition security by equating with multimodal biometric features. The multi-modal biometrics recognition system generally admits two steps such as the feature extraction and feature recognition. Several techniques employ the conventional biometric systems like the Gaussian Mixture Models (GMMs), Artificial Neural Networks (ANNs), Fuzzy Expert Systems (FESs), and Support Vector Machines (SVMs) [1]. Moreover, several researchers are admitted nowadays to render an effective multi-model biometric system. II. LITERATURE REVIEW Madasu Hanmandlu et al. [16] magnificently presented a novel method which was based on the multimodal biometric system. Their multimodal biometric system was an improved method which lessened the constraints of the uni-modal biometric systems by means of injecting fruitful data from the relevant biometric sources. Further, they recommended a regular technique for the fusion at score level by equating the scores from the multiple biometrics by applying the triangular norms (t-norms) attributable to Hamacher, Yager, Frank, Schweizer and Sklar, and Einstein product. The ultimate motive of the current investigation was concentrated on tapping the potential of t-norms for the multimodal biometrics. Their novel technique projected a par-excellence performance as it was rather computationally rapid and hence overwhelmed the score level fusion applying the combination technique (min, mean, and sum) and several classification approaches such as the SVM, logistic linear regression, MLP and so on. The test appraisal conducted on three different databases illustrated the supreme efficiency of the score level fusion applying t-norms. Rudresh Dwivedi and Somnath Dey et al. [17] were instrumental in introducing a novel approach to the modern word by means of the combination of scores from multiple biometric modalities which gave a ray of hope to successfully overwhelm the constraints of the uni-biometric systems like the sensitivity to the outliers, invalid validation triggered by the inter-class and intra-class inconsistency and the sub-standard authentication efficiency on account of meager quality. In their document, they put forward a two-level score level fusion technique for the purpose of combing the scores obtained from the cancelable templates of several biometric modalities. Because of this, in respect of a flood of applications, they were able to realize an incredible augmentation in the total recognition efficiency, leading to a further safe validation. In the initial stage, they equated the scores from multiple matchers and introduced a novel mean-closure weighting (MCW) method to achieve the preferred score for a specific biometric modality. Their anticipated solution was based on the area of ambiguity between the real and fraud distribution. In the second phase, the derived scores from several modalities were combined by means of an innovative rectangular area weighting (RAW) approach technique to effectively achieve the overall fused score. On the whole, the proposed two-level cancelable score fusion technique was able to score a clear edge by way of superior performance over the uni-modal cancelable techniques and was highly robust to the inconsistency of the scores and outliers. The appraisal of their technique was carried out on two virtual databases, by equating with the modern weighting, density and classification based score fusion approaches. Test outcomes revealed the unambiguous fact that their novel two-level cancelable score fusion showcased a par-excellence performance over uni-the biometric system, effectively satisfying the constraints of safe validation. Credit goes to Quang DucTran and PanosLiatsis et al. [18] for launching an innovative method which took due care of the problems faced by the earlier approaches and addressed them successfully. In this regard, the class imbalance put several roadblocks in the pathway of a host of typical two-class classifiers, while being deployed in the course of classification in the backdrop of the multimodal biometric validation. A lion s share of the traditional classifiers assumed equally balanced classes and they failed miserably when the fake samples incredibly exceed the samples of the authentic user class. In their document, they envisioned a novel technique termed as the RABOC, which integrated the innate skills of one-class classification and the Real AdaBoost technique to pilot the class imbalance issue in the biometric systems. Predominantly, they effectively customized a classifier, encompassing the one-class classifiers and it was trained by means of the data from both the classes. Subsequently, they employed the Real AdaBoost to equate the multiple weak classifiers so as to augment their performance without, in any way, leading to over-fitting. Quite different from the traditional Real AdaBoost, the weak classifiers in the projected technique were trained on the identical data set, thought by means of several constraint selections. With the result, the diversity needed to help the RABOC work was created in addition to scaling down the number of user-specified constraints. They conducted far-reaching tests on the BioSecure DS2 and XM2VTS benchmark databases, which entertained the data with enormously imbalanced class distribution. Further, they could illustrate that their masterpiece technique viz. the RABOC algorithm was able to usher in a superlative efficiency in performance with improvement to the tune of 28%, 24%, and 22% in comparison with the parallel hi-tech methods, in particular in various parameters like the sum of scores, likelihood ratio based score fusion, and Support Vector Machines. As far as the multi-biometric systems are concerned, the accuracy and usability emerged as the two most important problems. Many a multi-biometric system was invariably founded on matching the scores or features of multiple biometric traits. Nevertheless, in the course of achieving a superior level, lots of fruitful identity data was lost while extracting the scores or features from captured multimodal biometric data, thereby leading to adverse impact on the accuracy and usability of the multi-biometric system. It was also taken for granted that matching scores was capable of regaining certain identity data, which was not applied in the earlier fusion work. International Journal of Innovative Technology and Exploring Engineering (IJITEE) ISSN: 2278-3075, Volume-8 Issue-6S, April 2019 662 Published By: Blue Eyes Intelligence Engineering & Sciences Publication Retrieval Number: F61480486S19\19 BEIESP Di Miao et al. [19] diligently designed a novel framework of bin-based classifier technique for the synthesis of multi-biometrics, so as to successfully address the related issues. They implanted the matching scores into a higher-dimensional space by means of the bin-based classifier, and rich identity data, which was concealed in matching scores, was regained in this novel space from the authentic users further accurately, which was enough to differentiate the impostors. Hence, the multi-biometric techniques founded on the corresponding rich data were able to realize further accurate and consistent outcomes. The ensemble learning technique was thereafter performed to pick the most dominant embedding spaces. The test outcomes on the CASIA-Iris-Distance propped up the dominance of their anticipated fusion. R. Raghavendra et al. [20] remarkably addressed the issue of designing proficient fusion techniques of harmonizing biometric modalities like the face and palm print, which were efficiently coded by means of the Log-Gabor conversions, leading to superior dimensional feature spaces. They effectively put forward several fusion techniques at match score level and feature level, which were compared on a database of 250 virtual people derived from the face FRGC and the palm print PolyU databases. In addition, with an eye on scaling down the intricacy of the fusion technique, they envisaged a novel particle swarm optimization (PSO) technique which entailed the significant reduction of the number of features representing a dominant subspace of the huge dimension feature space, simultaneously maintaining an identical level of performance. The glamorous outcomes in the closed identification as well as the verification rates project an incredible improvement of 6% in performance while initiating the feature fusion in the Log-Gabor space vis- -vis the traditional maximized match score level fusion approach. Hunny Mehrotra et al. [21] delved deeply into the question of widening the skills of relevance vector machine which represented a probabilistic, sparse, and linearly parameterized classifier. They illustrated that the relevance vector machine as well as the support vector machine yielded more or less identical generalization performance, though the RVM needed critically lesser relevance vectors. Nevertheless, the RVM was plagued by several constraints which put several roadblocks in its applications in a host of pattern recognition issues including biometrics like the sluggish training procedure, complexity in training with huge training samples, and the probable unsuitability to successfully address the big class imbalance. With the intention of overwhelming the related constrains, they smartly suggested the iGRVM duly integrating the incremental and granular learning in the RVM. Their novel classifier was estimated in context to the multimodal biometrics score classification by employing the NIST BSSR1, CASIA-Iris-Distance V4, and Biosecure DS2 databases. With quicker testing time, the test appraisal established the fact that the suggested classifier emerged as a highly viable substitute for the biometric score classification. Ricardo N. Rodrigues et al. [22] remarkably researched on the safety of the multimodal biometric systems in case one of the modes was effectively spoofed. They elegantly launched two innovative fusion techniques which were capable of incredibly enhancing the safety of the multimodal biometric systems. While one method represented an expansion of the probability ratio based fusion technique the other effectively employed the fuzzy logic. In addition to the e matching score and sample quality score, their novel fusion techniques duly considered the inherent safety of each biometric system being merged. Test outcomes proved without an iota of doubt that the proposed techniques were able to exhibit added robustness when faced with spoof attacks, in comparison with the rival fusion techniques. III. PROBLEM DEFINITION The biometric systems are applied in various applications. The some of the limitations in biometric systems are listed below. In the multi model based biometric recognition, lots of works are done at several fusion levels likes the sensor level, matching score level, and decision level and so on. The Multimodal fusion operation at this level habitually is very hard to produce the wanted outcomes largely on account of the potential incongruity of the feature spaces generated by several modalities. The canonical correlation analysis approach fails miserably to divulge the complex and nonlinear correlation bond between the two features sets. In the case of the multi model biometric system, it is very hard to integrate the feature sets, especially when the feature sets of multiple modalities are haunted by the disadvantages such as the incompatibility, anonymous liaison among the feature space of multiple modalities and the hassles of dimensionality issues. The inherent defects of the feature level fusion are evidenced by the fact that feature sets from the multi modalities are either inaccessible or incompatible. In the feature level fusion, the concatenation is likely to result in a colossal dimensional feature vector thanks to incidence of noisy or superfluous data, thereby causing incredible reduction in the efficiency of performance. These are the major drawbacks of different existing biometric systems, which motivate us to do this research on multi model biometric system. We are intended to suggest a suitable method to achieve better performance. IV. PROPOSED METHODOLOGY In this machine age, a lion s share of sophisticated security system invariably extensively employs the biometric all through the cosmos, with red carpet welcome in the domains of corporate offices, criminal investigation, identification, border control, security zones, airports, hospitals, banks, autonomous and non-autonomous institutions, to mention a few. Of late, the biometric based systems have emerged as ideal candidates, contributing their due share in the field of human recognition, largely on account of the fact among the host of biometric traits iris continues to be the consistent and inimitable organ. Moreover, it is significantly sheltered from International Journal of Innovative Technology and Exploring Engineering (IJITEE) ISSN: 2278-3075, Volume-X, Issue-X 663 Published By: Blue Eyes Intelligence Engineering & Sciences Publication Retrieval Number: F61480486S19\19 BEIESP the ecological and physical damage by the eyelid and the eyelashes. Likewise in fingerprint trait, even identical twins also have unique fingerprint patterns. No one can forge the iris and fingerprint biometric traits. We have intended to improve an efficient approach for multimodal biometric recognition using Iris and Fingerprint by this research. The recognition processes will consist of three modules, namely pre-processing module, feature extraction module and recognition module. In the pre-processing module, different techniques would be utilized such as grey image conversion, histogram equalization, contrast enhancement and filters so as to develop the image quality and make image fit for further processing. The images are then feature extracted applying modified Local Binary Pattern (MLBP) feature and GLCM features in the feature extraction module. After feature extraction, the feature level fusion process will be carried applying Fish Swarm optimization algorithm. Finally, recognition will be done applying the Improved Multi Kernel Support vector machine (IMKSVM). In the paper, multiple kernels are assessed and compared so as to give shape an innovative hybrid kernel which is well-endowed with the requisite skills of significantly scaling up the classification task of segregating the training data. With the introduction of the hybrid kernel, the SVMs are highly benefited by attaining flexibility in the picking of the shape of the threshold, thereby doing away with the necessity of it being either linear or possessing the identical functional shape for the entire data, because of the fact that its function is predominantly non-parametric and it functions locally. The performance of suggested method is estimated in terms of recognizing accuracy. The suggested method is implemented in MATLAB platform. Fig. 1 Proposed Iris and Fingerprint Multimodal Biometric system Pre-processing module In the pre-processing module, various techniques would be utilized such as grey image conversion, histogram equalization, contrast enhancement and filters so as to develop the image quality and make image fit for further processing. Histogram equalization Incidentally, the histogram equalization has appeared on the stage as a universal method, duly extending the histogram across the entire range of pixels (0 255). It effectively enhances the contrast of images for the finality of human inspection, in addition to acting as a catalyst in normalizing the illumination fluctuations encountered in the image comprehension challenges. The process gleams with the quality of simplicity. For each brightness level j in the original image, the new pixel level value (k) is effectively estimated by means of the following Equation (1). j i i T N K 0 (1) Where the sum counts the number of pixels in the image with brightness either equal to or within j and T represents the total number of pixels. Moreover, H.E (histogram equalization) proves its mettle as one of the unique techniques which is competent to employ novel images based on histogram specification or modification. Contrast Enhancement In the acquisition sensor device, the level of contrast in an image is likely to fluctuate on account of insufficient illumination or inappropriate setting. Hence, it is highly essential to manipulate the contrast of an image with a view to successfully tackle the hassles faced in the course of the image acquisition. The underlying concept is to duly adapt the dynamic range of the grey-levels in the image. An efficient method which is viable in this regard is appropriately called the linear mapping and Equation (2) extends the pixel values of a low-contrast image or high-contrast image by enlarging the dynamic range across the entire image spectrum from 0 (L-1). 1 1 2 1 2 1 ) , ( ) , ( I y x I I I o o o y x o (2) Where O1 characterizes 0 and O2 represents the number of preferred levels in the range (L-1= 255). I1 and I2 correspond to the minimum and maximum values of the input grey-level range. The easiest way to process is by adapting the brightness of an image by adding a bias value, b, to the entire pixel values of an image; where b> 0 may enhance the brightness of an image and b< 0 is likely to darken the image. Further let us employ the gain factor a , rather than a bias, in which the product of a with the input pixel values cause a variation in the brightness of the output image. Let the values in the range of 0 < a< 1 generate a darker image and values in the range of a> 1 create a brighter image. When the bias and gain are equated, it results in Equation (3). Feature extraction module Thereafter, the images are subjected to feature-extraction by means of the customized LBP feature and GLCM features in the feature extraction module. When the process of the feature extraction is over, the feature level fusion procedure is initiated with the assistance of the Fish Swarm optimization technique. In the long run, the recognition is performed by effectively employing the Improved Multi Kernel Support vector machine (IMKSVM). International Journal of Innovative Technology and Exploring Engineering (IJITEE) ISSN: 2278-3075, Volume-8 Issue-6S, April 2019 664 Published By: Blue Eyes Intelligence Engineering & Sciences Publication Retrieval Number: F61480486S19\19 BEIESP Gray Level Co-occurrence Matrix The Gray Level Co-occurrence Matrix is symbolized as GLCM. At this juncture, the aspects of images are extracted and stored in a matrix. In this regard, GLCM stands out as the simplest matrix techniques devoted to the extraction of the texture aspect. The GLCM aspects are applied to extract for all the images in the database and the input image are saved for processing affine situation. The four usual properties of Energy, Entropy, Contrast and Inverse different situation are applied to reduce the computational critical. The co-occurrence matrix, in essence, represents the arithmetical model, which is extensively employed to effectively evaluate a host of image applications like the biomedical, remote sensing, industrial defect detection techniques, to mention a few. Largely based on the gray level value of pixel, the gray level matrix is elegantly executed to efficiently extract the image aspects. The aspects are very significant for all classification algorithms. Here texture aspects are extracted. The GLCM aspect is saved in a matrix for to evaluate the number of GLCM. By the inconsistency and comparison of entropy information, the GLCM aspects are extracted. The aspects of eyes, eyebrow, nose and lips are extracted by applying of the affine situated invariants method. The facial identification method is used to extract the facial emotions of angry, fear, sad, happy, surprise and normal. By applying of these facial expressions, the images are transferred into binary image for extracting the aspects. Let {I (x, y), 0 x Nx 1, 0 y Ny 1} represent an image with G gray levels. The G*G gray level concurrence matrix d p for a displacement vector d = (dx, dy) and direction is effectively estimated as detailed below. The element (i, j) of d p represents the number of concurrence of the pair of gray levels i and j in which the distance among i and j in the direction of is signified by d. } ) , ( , ) , ( : )) , ( ), , {(( # ), , ( j v t I i s r I v t s r j i p (4) Where ) , ( ) , (; ) , ( ), , ( dy s dx r v t N N v t s r y x represents the co-occurrence matrix d p with distance d = 1 and the direction is characterized by the horizontal ( = 0). The corresponding relationship viz. (d = 1, = 0) corresponds to the nearest horizontal neighbor. There exists )1 ( x N representing the adjacent resolution cell pairs for each and every row and Ny represents the number of rows present, offering y x N N R )1 ( nearest horizontal pairs. It is easily possible to standardize the co-occurrence matrix by dividing each of its entry by R. Modified LBP The LBP code efficiently evaluates by way of equating the pixel of an image with its adjacent pixels, as illustrated in Equation (5). x x x r g g LBP p p p c p r p ,0 0 ,1 ) ( , 2 ) ( 1 0 , (5) Where gc represents the gray level value of the center pixel, corresponding to the value of the adjacent pixels of the center, P denotes the total number of adjacent pixels and R characterizes the radius of the neighborhood. Let us consider an image of size I*J. The LBP pattern is effectively estimated for each and every pixel of an image and the histogram is adapted to characterize the face texture [5]. 1 0 , 0 ,0 0 ,1 ) ( , 2 ) ( p p p c p R P x x x r g g LBP (6) Though it is essential to spell out the gain as well as bias values, it becomes a Herculean Task in actual practice. Hence, a feasible solution can be achieved by way of mapping the input image range (I1, I2) to the output image range (O1, O2) where O1 signifies 0 (zero) and O2 signifies the number of preferred levels, hence linear mapping is effectively defined in Equation (6) by this case. I i J j R P k k j i LBP f k Hist 1 1 , ] ,0 [ ) ), , ( ( ) ( (7) otherwise y x y x f ,0 ,1 ) , ( (8) Where K represents the maximal LBP pattern value. At this juncture, we calculate the local difference, Dist p among the center pixel gc and the evenly spaced neighboring pixels, gp, p=0, 1, 2,...,p-1 as Dist p=gp-gc. In this manner, we achieve the image local structure at gc with the local difference vector [Dist 0... Dist p-1]. In view of the fact that the center intensity value, gc is eliminated the local difference vector elegantly showcases superior performance in the face of the illumination fluctuations. Now, the Dist p is duly divided into two modules as illustrated in Equation (9). p p p p p p p Dist M Dist sign S and M S Dist ) ( (9) Where 0 ,1 0 ,1 p p p Dist Dist S and m represent the sign and magnitude of respectively. In the document, p Dist the complementary strengths of the sign and magnitude modules of I are applied so as to increase the efficiency of the texture classification performance. The equation duly depicts the local difference Sign Magnitude Transform (SMT). At the outset, we split the fingerprint and iris image into several patches and initiate the MLBP on each and every patch so as to extract the finger print and iris texture feature. Each and every patch is referred by 256 sign and 256 magnitude modules. The MLBP is initiated on each and every patch of a cropped image. Based on the number of patches generated, the overall feature achieved can be significantly huge. As for instance, a subject image divided into 4*6 patches invariably produces 24 patches, each of which encompasses 512 features resulting in 12,288 features to characterize the fingerprint and iris image. International Journal of Innovative Technology and Exploring Engineering (IJITEE) ISSN: 2278-3075, Volume-X, Issue-X 665 Published By: Blue Eyes Intelligence Engineering & Sciences Publication Retrieval Number: F61480486S19\19 BEIESP The ensuing section, offers a bird s eye-view on the feature selection method employing the RF. Fish swarm Optimization (AFSO) The fish is competent to make an effective assessment of an incredibly beneficial nutritious area by means of carrying out either an individual probe or stepping into the shoes of the other fish. In this regard, the region in which the fish abound is deemed as the highly nutritious in nature. The underlying concept behind the FSO is concentrated on the effective replication of the tendencies of the fish such as the praying, swarming, and following with local search of fish individual for effectively attaining the global optimum. The environs in which the FS exists is deemed predominantly to be the solution space and it also represents the environment of the other FS. Another tendency of the FS is largely dependent on its present circumstance and its local ecological state encompassing the quality of the question solutions at the moment and the states of adjacent companions. It is only natural that the FS tends to manipulate the surroundings by means of actions carried out by itself and also its companions. In the AF comprehension of the external awareness by the present state of the AF, the Visual corresponds to the visual distance, and Zv signifies the visual position at a specified time. If the circumstance at the visual position appears to be superior to the existing scenario, it moves forward in this direction to arrive at the Znext state. Otherwise, it extends a probing tour in the vicinity. If the AF carries out a large number of inspecting tours, it gathers significant knowledge about the overall circumstances of the vision. It is certain that it is not essential to travel all through the complex or infinite environs and this goes a long way in ascertaining the global optimum by duly allowing certain local optimum with a little bit of vacillation. Initialization At the outset, the input parameters like the weight and are initialized. Let the i , i represent a primary solution of fish and i signifies the number of solutions. In addition, and also initialize the parameters like the step are initialized. This procedure is duly called the initialization process. ) ...... , ( 1 0 nj j j i Z Z Z Z (10) Where, represents an initial solution, i [1, 2, 10] and j [1, 2, 140]. Here, the ith value is deemed as the number of solution and jth value is considered as length of solution. neuron hidden of No data input of No neuron hidden of No Zi ) ( (11) Fitness function Here, the fitness value of each fish solution is effectively estimated as illustrated in the following Equation (12) and the best solution values calculated. h j N i ij i N i ij i i i Z Z F 1 1 1 1 ) ( exp ) ( cosh 1 2 (12) Here 2 ) exp( ) exp( ) cosh( ij i ij i Z Z Z (13) Where, and represent the weights, Z corresponds the input parameter, i signifies the number of inputs, j denotes the number of weights, N corresponds a number of the input data and h indicates the number of hidden neurons. Now, arrive at the novel solutions for the process update the novel fishes based on the prey, follow and swarm behavior. Prey behavior The prey behavior invariably constitutes the basic biological conduct with the tendency to search for food. Let the condition of artificial fish is represented by i Z picking a state j Z within its sensing range randomly. In the event of j Z being better than i Z , proceed to j Z and if otherwise, pick the random condition i Z and ascertain the probability of satisfying the forward conditions. Even after repetition a number of times, the forward conditions are not met with, then proceed with one step arbitrarily. The food concentration in the current situation of the fish is defined as the objective function value. The distance among the artificial fish is represented by || || , j i j i Z Z d where i and j signify the arbitrary fish. () .rand visual Z Z i j (14) rand step Z Z Z Z Z Z t i j t i j t i t i . . || || ) ( ) ( ) ( )1 ( (15) Here, the arbitrary numbers between 0 and 1 are generated and the step illustrates the maximum step size of the artificial fish. The visual corresponds to the visual distance, the artificial fish exists only in the inner radius of the circle to the length of the field of vision of diverse actions. Swarm behavior Let the present state of the artificial fish is represented by ) ( , Visual d Z j i i and the number of artificial fish by ) ( f f n if n It shows that the partners possess more than sufficient food and are less crowded. In case c F is superior to iF move ahead towards the centre of the direction of the partnership. Or else, repeat the prey behavior. rand step Z Z Z Z Z Z t i c t i c t i t i . . || || ) ( ) ( ) ( )1 ( (16) Follow Behavior Let the state of artificial fish is represented by i Z Now, discover its optimal state max Z from the Visual neighbors, the number of partner of max Z International Journal of Innovative Technology and Exploring Engineering (IJITEE) ISSN: 2278-3075, Volume-8 Issue-6S, April 2019 666 Published By: Blue Eyes Intelligence Engineering & Sciences Publication Retrieval Number: F61480486S19\19 BEIESP is ) ( fn if illustrates that in the near vicinity, there is abundance of food and it is also not significantly crowded. Now proceed towards the front of max Z position. Or else, initiate the foraging behavior by means of applying Equation (14). Optimal solution Based on the process detailed above, the optimal weights are realized. Moreover, the optimal fitness is found out as optimal F and depending on this, the output is ascertained. The optimal equation is established which calculate the output such as the CS (compressive strength), STS (split tensile strength) and deflection on left, right and middle of the concrete. h j N i ij optimal i N i ij optimal i i optimal optimal i Z Z F 1 1 ) ( 1 ) ( ) ( ) ( 1 ) ( exp ) ( cosh 1 2 (17) Where, and represent the weights in the range of ( -500 to 500), X signifies the input parameters, i corresponds to the number of inputs, j indicates the number of weights and h reveals the number of hidden neurons. Thereafter, the error value is efficiently estimated by means of the following Equation (18). ND P D E ND i i i i 1 2) ( (18) Where N represents the number of the data, D indicates the desired value and P corresponds to the predicted value, i= 1,2, .n. By effectively employing the above formula, the error value is estimated as the difference between the desired value and predicted value. Recognition module using MKSVM At this point, the multiple kernels are compared with the intention of bringing to limelight an innovative hybrid kernel which is competent to significantly scale up the classification task of segregating training data. By means of launching the hybrid kernel, the SVMs attain utmost flexibility in the selection of the shape of the threshold, obviating the need for being either linear or having identical functional shape for the entire data, as its function is found to be non-parametric with local operation. For the purpose of effective categorization, the optimum attributes are offered to the fusion kernel support vector machine. At the moment, for the segregation of the two modules, the chosen attribute from the earlier progression is proficiently employed. In the SVM classification, with the intention of processing the non-linear process, the kernel functions are initiated. The SVM process flows through two significant phases like the preparation phase and the easy stage. At present, the output of attribute selection is offered as the input of the preparation stage. The input utility furnishes the cluster of values which cannot be separated. More or less, each and every one of the possible isolation of the position places are figured out by a hectic plane. In the Lagrange pattern, it is possible to place the partition of the hectic plane standard vector in the course of the different kernel task. In the related connection, a kernel represents certain tasks, which is conveyed to a dot product for certain type of attribute recording. Yet, recording a position into a better-quality dimensional gap is capable of directing redundant evaluation period and huge storage needs. With the result, in real performance, an original kernel task is initiated which is able to effectively evaluate the dot product in the better-quality dimensional gap. The frequent edition of the kernel task is appropriately offered as illustrated in the following Equation (19). V U V U K T , (19) In this backdrop, a large chunk of the extensively employed kernel tasks encompass the linear kernel, Polynomial kernel, Quadratic kernel, Sigmoid and the Radial Basis task. Given below are the related terms for the several kernel tasks. For Linear Kernel: c v u V U linear T k ) , ( (20) Where v u, represents the inner products in the linear kernel and c signifies a constant. For Quadratic Kernel: Where, v u, - characterize the vectors of the polynomial kernel function in the input space For Polynomial Kernel: 0 , ) , ( e T k c v u V U poly (21) For Sigmoid Kernel: 0 , tanh ) , ( c v u V U sig T k (23) The efficiency of the SVM is habitually oriented on the diversity of the kernel. If the attribute gap is found to be linearly indivisible, it is necessary to record into a better-quality dimensional gap by means of the Radial basis task kernel, so as to ensure that it is linearly detachable. In addition, the combination of any two kernel task is capable of rescheduling the excellent accuracy in relation to that achieved by employing a single kernel task. An innovative MKSVM is suggested, which is devoted for significant enhancement in the categorization system in the original method. The two kernel tasks like the linear and the quadratic kernel task are shared for the purpose of rescheduling the excellent presentation ratios by this point. In the original method, by the combination of the Equations 24 and 25 the standard is forecast as suggested. The shared kernel task is fruitfully employed in the HMKSVM and the standard of the kernel task, ) , ( V U avg k is illustrated by means of the following Equation (24) and (25). ) 24 ( ) , ( ) , ( 2 1 ) , ( V U quad V U lin V U avg k k k ) 25 ( 1 2 1 ) , ( 2 2 c v u v u c v u V U avg T k In the kernel Support Vector Machine, two kernels like the linear and quadratic are initiated into description for the purpose of effectively categorizing the search links. International Journal of Innovative Technology and Exploring Engineering (IJITEE) ISSN: 2278-3075, Volume-X, Issue-X 667 Published By: Blue Eyes Intelligence Engineering & Sciences Publication Retrieval Number: F61480486S19\19 BEIESP By means of the integration of two results, the standard result is achieved and enhanced for the classification. The SVMs, in fact, are closely linked to the basic linear classifier s family and are deemed as the distinctive example of the Tikhonov regularization. Moreover, they have, of late, been widely accepted as the most efficient devices for many an application, thanks to their superlative efficiency in the generalization performance. In the document, it is merely employed for the purpose of breast cancer recognition. One of their key qualities is the ability to significantly scale down the errors in the practical classification error and simultaneously perk up the geometric margin. With the result, they are appropriately called the maximum margin classifiers. Equation (26) appearing below illustrates the objective function of the SVMs objective function, which is likely to identify the support vector for the classification. i i i i b PR SV K OF ) , ( * (26) Where, weight i function kernel K ctors support ve S iV tion classifica for vectors P R The captioned Equation(26) represents the objective function which executes an optimization technique so as to arrive at the support vectors, weights and bias for classifying the vector, where K represents a kernel function. In the case of a linear kernel, whether it characterizes a dot product, Now, the threshold set in the SVM is labeled as the hyper plane. The Support Vector Machine invariably encompasses the errors. Equation (27) furnished below illustrates error minimization function which is carried out for the purpose of significant reduction of the relative error. . 5.0 min arg 1 0 ' T n x x s PC (27) It is subject to the restraints shown in Equations (28) and (29). x x T x c PR K CL 1 ) ) ( ( n (28) 0 x (29) In the case of Equation (12), PC represents the penalty constant, symbolizes a parameter which directs the image and corresponds to a matrix of coefficients. In the restraints furnished in Equations (12) and (13), x CL indicates the class label of the th x image, c remains a constant and K signifies the kernel which converts the input image to the feature space. Thus, by way of achieving significant reduction in the error function, the SVMs are capable of gaining better awareness of the training images x PR thereby duly identifying the biometric images. At this juncture, the multiple kernels area associated so as design an innovative hybrid kernel which significantly improves the classification function segregating the training data. By way of launching the hybrid kernel, the SVMs achieve sufficient flexibility in the selection of the shape of the threshold, dispensing with the stipulation that it is either linear or possesses the identical functional shape for the entire data, on account of its non-parametric function and operation in the local domain. V. RESULT AND DISCUSSION We have accomplished a multi model biometric system established on IRIS and Finger print in this suggested work. Here, we applied an Improved Multi Kernel SVM. In order to analyze the effectiveness of suggested technique we have utilized some evaluation metrics such as sensitivity, specificity and accuracy. Here, we depicted that in below. Sensitivity The measure of the sensitivity is correctly recognizing the proportion of actual positives. It is applied to recognize the positive results by the ability of test. Specificity The measure of the specificity is correctly evaluated by the proportion of negative. It is applied to recognize negative results by the ability of test. 100 negatives false of Number positives true of Number positives true of Number y Sensitivit Accuracy We can estimate the measure of accuracy from the measure of sensitivity and specificity as afforded below. 100 FN FP TN TP TN TP Accuracy Table. 1 Suggested Sensitivity, Specificity And Accuracy Measures Evaluation Metrics Measures Sensitivity 0.928571429 Specificity 1 Accuracy 0.964285714 Fig. 2 Graphical representation of our proposed sensitivity, specificity and accuracy measures In this section, we are discussing about the result of our current work established on sensitivity, specificity and accuracy. International Journal of Innovative Technology and Exploring Engineering (IJITEE) ISSN: 2278-3075, Volume-8 Issue-6S, April 2019 668 Published By: Blue Eyes Intelligence Engineering & Sciences Publication Retrieval Number: F61480486S19\19 BEIESP For sensitivity we get the result as 0.928571429. For specificity we get the result as 1. For accuracy we get result as 0.964285714. Moreover, we have drawn chart to demonstrate the results in a geometric representation is afforded below. Comparative Analysis In this section, we have rendered the different comparative results of our work established on TP, TF, FP, FF, specificity, sensitivity, and accuracy. In order to prove the efficiency of work these results demonstrates good outcomes. We have tabulated our work result below for understanding our work easily. Methods True Positive True Negativ e False Positive False Negativ e AFSO+LQ 26 28 0 2 AFSO+L 21 25 3 7 AFSO+Q 25 24 4 3 GWO+LQ 25 28 0 3 GWO+L 19 25 3 9 GWO+Q 20 25 3 8 In this section, we have mentioned the different comparative results of our work. For comparative analysis we applied different algorithm established on some metrics such as true positive, true negative, false positive and false negative. For AFSO+LQ, we get the true positive as 26, true negative as 28, false positive as 0 and false negative as 2. For AFSO+L, we get the result for true positive as 21, true negative as 25, false positive as 3 and false negative as 7. For AFSO+Q, we get the result as 25 for true positive, 24 for true negative, 4 for false positive and 3 for false negative. For GWO+LQ, we get 25 for true positive, 28 for true negative, 0 for false positive and 3 for false negative. We get the result for GWO+L is for true positive is 19, 25 for true negative, 3 for false positive and 9 for false negative. Result for GWO+1, we 20 for true positive, 25 for true negative, 3 for false positive and 8 for false negative. In addition, we have also come our technique established on sensitivity, specificity and accuracy. We have tabulated that in below. Table. 2 Comparison of proposed and existing measures Methods Sensitivity Specificity Accuracy AFSO+LQ 0.928571 1 964286 AFSO+L 0.75 0.892857 0.821429 AFSO+Q 0.892857 0.857143 0.875 GWO+LQ 0.892857 1 0.946429 GWO+L 0.678571 0.892857 0.785714 GWO+Q 0.714286 0.892857 0.803571 Fig. 3 Graphical representation of proposed and existing sensitivity, specificity and accuracy measures We have estimated our suggested work established on sensitivity, specificity and accuracy therefore; we get different results. We compare our technique with AFSO+LQ, we get sensitivity result as 0.928571, specificity result as 1, accuracy result as 964286. We get the result for AFSO+L established on sensitivity we get 0.75, for specificity we get 0.892857, accuracy is 0.821429. We get the result established on AFSO+Q, sensitivity is 0.892857, specificity is 0.857143 and accuracy is 0.875. GWO+LQ result based on sensitivity is 0.892857, specificity is 1, and accuracy is 0.946429. For GWO+L, the result based sensitivity is 0.678571, specificity is 0.892857 and 0.785714. For GWO+Q, we get the result for sensitivity is 0.714286, specificity is 0.892857, and accuracy result is 0.803571. VI. CONCLUSION Biometric is nowadays important in all domain for recognizing individual s identity established on iris, palm and finger print etc. In addition, it is for preventing unauthorized accessing. It has been applied in different domains including airport, hospital and banking etc. In order to provide the effective biometric system we have developed multi-model biometric recognition based on iris and fingerprint. We utilized three modules in our work such as pre-processing module, feature extraction module and recognition module. Feature extraction is established on modified Local Binary Pattern (MLBP) feature and GLCM features in the feature extraction module and Fish Swarm optimization algorithm is applied for processing feature level fusion. Improved Multi Kernel Support vector machine (IMKSVM) is inaugurated for recognition. Here, we incorporate multiple kernels to propose a new hybrid kernel that develops the classification task of separating training data. By providing the hybrid kernel, SVMs provides adaptability in the decision of the type of the threshold, which n not need be linear and even not have the same practical frame for all data, since its function is non-parametric and works locally. International Journal of Innovative Technology and Exploring Engineering (IJITEE) ISSN: 2278-3075, Volume-X, Issue-X 669 Published By: Blue Eyes Intelligence Engineering & Sciences Publication Retrieval Number: F61480486S19\19 BEIESP In order to prove the effectiveness of our suggested work we have analyzed suggested technique based some evaluation metrics such as sensitivity, specificity and accuracy therefore; we get good result and we implemented in the MATLAB platform successfully. REFERENCES 1. I. G. Damousis and S. Argyropoulos,"Four Machine Learning Algorithms for Biometrics Fusion: A Comparative Study, Applied Computational Intelligence and Soft Computing, Vol.1, pp.1-7, 2012. 2. D. Jagadiswary and D. Saraswady, "Biometric Authentication using Fused Multimodal Biometric", In the Procedia Computer Science, Vol. 85, pp.109-116, 2016. 3. Ma Xin and Jing Xiaojun,"Correlation-based identification approach for multimodal biometric fusion", The Journal of China Universities of Posts and Telecommunications, Vol. 24, No. 4, pp.34-50, August 2017. 4. Marta Gomez-Barrero, Javier Galbally and Julian Fierrez, "Efficient software attack to multimodal biometric systems and its application to face and iris fusion", Pattern Recognition Letters, Vol. 36, pp. 243-253, 15 January 2014. 5. Brian O Connor and Kaushik Roy, "Facial Recognition using Modified Local Binary Pattern and Random Forest", In Proceedings of International Journal of Artificial Intelligence & Applications (IJAIA), pp. 25-33Vol.4, No.6, Nov 2013. 6. Neyire Deniz Sarier, "Multimodal biometric Identity Based Encryption" , Future Generation Computer Systems, Vol. 80, pp. 112-125, March 2018. 7. Marcin D. Bugdol, Andrzej W. Mitas,"Multimodal biometric system combining ECG and sound signals", Pattern Recognition Letters, Vol. 38,pp. 107-112 1 March 2014. 8. Mamta and Madasu Hanmandlu ,"Multimodal biometric system built on the new entropy function for feature extraction and the Refined Scores as a classifier", Expert Systems with Applications, Vol. 42, No. 7, pp.3702-3723, 1 May 2015. 9. Yarui Chen, Jucheng Yang, Chao Wang and Na Liu,"Multimodal biometrics recognition based on local fusion visual features and variational bayesian extreme learning machine", Expert Systems with Applications, Volume 64, 93-103, 1 December 2016. 10. Miao Qi, Yinghua Lu, Ning Du, Yinan Zhang and Jun Kong, "A novel image hiding approach based on correlation analysis for secure multimodal biometrics", Journal of Network and Computer Applications, Vol. 33, No. 3, pp. 247-25, May 2010. 11. Wencheng Yang, Song Wang, Jiankun Hu, Guanglou Zheng and Craig Valli, A fingerprint and finger-vein based cancelable multi-biometric system, Pattern Recognition, Vol. 78, pp. 242-251, June 2018. 12. Mohd Shahrimie Mohd Asaari, Shahrel A. Suandi and Bakhtiar Affendi Rosdi, "Fusion of Band Limited Phase Only Correlation and Width Centroid Contour Distance for finger based biometrics", Expert Systems with Applications, Vol. 41, No. 7, pp. 3367-3382, 1 June 2014. 13. Di Miao, Man Zhang, Zhenan Sun, Tieniu Tan and Zhaofeng He, "Bin-based classifier fusion of iris and face biometrics", Neurocomputing, Vol. 224, pp.105-118, 8 February 2017. 14. Heng Fui Liau and Dino Isa, "Feature selection for support vector machine-based face-iris multimodal biometric system", Expert Systems with Applications, Vol. 38, No. 9, pp.11105-11111, September 2011. 15. Dilara Akdogan, Duygu Karaoglan Altop, Laleh Eskandarian and Albert Levi, "Secure key agreement protocols: Pure biometrics and cancelable biometrics", Computer Networks, Vol. 142, pp. 33-48, 4 September 2018. 16. Madasu Hanmandlu, Jyotsana Grover, Ankit Gureja and H. M. Gupta, "Score level fusion of multimodal biometrics using triangular norms", Pattern Recognition Letters, Vol. 32, No. 14, pp.1843-1850, 15 October 2011. 17. Rudresh Dwivedi and Somnath Dey, "Score-level fusion for cancelable multi-biometric verification", Pattern Recognition Letters, In press, corrected proof, Available online 16 April 2018. 18. Quang DucTran and PanosLiatsis,"RABOC: An approach to handle class imbalance in multimodal biometric authentication", Neurocomputing, Vol. 188, pp.167-177,5 May 2016. 19. Di Miao, Man Zhang, Zhenan Sun, Tieniu Tan and Zhaofeng He, "Bin-based classifier fusion of iris and face biometrics", Neurocomputing, Vol. 224, pp.105-118, 8 February 2017. 20. R. Raghavendra , BernadetteDorizzi, AshokRao, G.HemanthaKumar ,"Designing efficient fusion schemes for multimodal biometric systems using face and palmprint", Pattern Recognitionm, Vol. 44, No. 5, May 2011. 21. Hunny Mehrotra, Richa Singh, Mayank Vatsa and Banshidhar Majhi, "Incremental Granular Relevance Vector Machine: A Case Study in Multimodal Biometrics", Pattern Recognition, Vol. 56, pp. 63-76, August 2016. 22. Ricardo N. Rodrigues, Lee Luan Ling, Venu Govindaraju,"Robustness of multimodal biometric fusion methods against spoof attacks", Journal of Visual Languages & Computing, Vol. 20, No. 3, pp.169-179, June 2009. View publication stats