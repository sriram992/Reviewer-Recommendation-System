HAL Id: hal-01098931 https://hal.science/hal-01098931 Submitted on 17 Jan 2015 HAL is a multi-disciplinary open access archive for the deposit and dissemination of sci- entific research documents, whether they are pub- lished or not. The documents may come from teaching and research institutions in France or abroad, or from public or private research centers. L archive ouverte pluridisciplinaire HAL, est destin e au d p t et la diffusion de documents scientifiques de niveau recherche, publi s ou non, manant des tablissements d enseignement et de recherche fran ais ou trangers, des laboratoires publics ou priv s. Physical limits of point-to-point communication systems Bhanukiran Perabathini, Vineeth S. Varma, M rouane Debbah, Marios Kountouris, Alberto Conte To cite this version: Bhanukiran Perabathini, Vineeth S. Varma, M rouane Debbah, Marios Kountouris, Alberto Conte. Physical limits of point-to-point communication systems. Workshop on Physics-Inspired Paradigms in Wireless Communications and Networks, co-located with WiOpt 2014, May 2014, Hammamet, Tunisia. pp.604 - 610, 10.1109/WIOPT.2014.6850354 . hal-01098931 Physical Limits of point-to-point communication systems Bhanukiran Perabathini1,2, Vineeth S Varma2, M erouane Debbah2, Marios Kountouris3 and Alberto Conte1 1 Alcatel Lucent Bell Labs 91620 Nozay France 2Alcatel Lucent Chair SUP ELEC 91192 Gif sur Yvette France 3Department of Telecommunications SUP ELEC 91192 Gif sur Yvette France Abstract In this paper, we explore the physical limits of suc- cessful information transfer in a point-to-point communication system. In interest of studying the fundamental limits imposed by physics on communication systems in general, we model a simple generic system that enables us to make some basic inquiries about the energy ef ciency in information transfer and processing. We use ideas from thermodynamics such as Szilard engine to represent information bits. We further use ideas from electromagnetic theory for transfer of information, and information theory to de ne the energy ef ciency metric. We nd the upper limit of this ef ciency and conditions at which it can be achieved. I. INTRODUCTION For a long time, it has been known that the process of communication has a cost in terms of energy [1], [2], [4]. In 1948, Shannon published his revolutionary paper [3], in which the conditions under which information can be communicated reliably are mathematically quanti ed. We intend to address this speci c point but from the perspective of energy expendi- ture, taking information creation and processing into account. In its colloquial sense, information may be an abstract and subjective concept. However, in its objective sense information precisely means an ensemble of suitable physical systems prepared in desired states. The physical nature of information is discussed in [6]. To give examples: A text message written on a piece of paper with a pencil is but one among several possible arrangements of an ensemble of carbon molecules in the two dimensional plane of a paper. An audio le inscribed on a compact disk is essentially a collection of pits and bumps engraved on it in a unique order. If a chosen physical system has distinct binary states (represented by a Bernoulli random variable), the information represented by such a system is called a bit. A large amount of information may be represented in terms of necessary number of such bits [3]. Preparing a physical system in a state or to change its state from one to another requires energy. While there may be countless possible physical systems that can be used in preparing, changing and storing a given information, the choice of the system decides how much energy is needed to perform all these operations. Our rst inquiry lies in this point. In an attempt to explore the answer to the question: What is the most energy ef cient choice of physical systems to represent and process information? , we choose to begin with a simple thermodynamic system (section II-A) to represent an information bit. We discuss energy expenditure in preparing and processing (operations on) such bits. The process in which physical systems prepared in desired states are transported from the transmission point to the reception point in space and time through a communication channel is called information transfer. This is a physical process too and requires energy. The correlation between the states sent and the states received is what determines the quality of information transfer. This correlation may be distorted due to interference from the physical world (noise), and such a distortion is quanti ed as error. There exists a trade off between the amount of energy spent at the transmission point and the mutual information (between the received states and the transmitted states) that can be achieved. Our second inquiry lies in this point. In an attempt to explore the answer to the question: What is the limit on the ef ciency of a communi- cation system taking information creation into account? , we convert the information represented by the above mentioned thermodynamic bits into electromagnetic waves to reach the reception, and evaluate the energy ef ciency of the system. We are particularly interested in evaluating energy ef ciency in communicating one bit of information as a limiting case (section III-D). Contrary to the intuitive notion that ef ciency can be maximized arbitrarily by increasing energy investment, our result shows that excess expenditure of energy does not necessarily have to be an ef cient solution in point-to-point communication. Our paper organization is as follows. In Section II, we elaborate on the communication system that we intend to study. In Section III, we discuss the energy ef ciency of the proposed system that uses binary phase-shift keying (BPSK). In Section IV, we extend our analysis to higher constellations by comparing the present case with that of QPSK. In Section V, we make plots of energy ef ciency of the proposed system and comment on its behavior for cases of BPSK and QPSK signaling. II. PROPOSED POINT-TO-POINT COMMUNICATION SYSTEM In order to model a communication system at its most basic physical form, we rst look at how information itself Fig. 1. Point-to-Point communication scheme. can be physically represented. Secondly, we look at how this information can be extracted from the physical system and converted to electromagnetic waves. Finally, this signal is received by a physical antenna and stored as thermodynamic information at the receiver. What we call information here is the source coded form of raw information. We do not take into account the in uence of source coding on the ef ciency. A. Thermodynamic representation of information Imagine an isolated cylindrical container of gas molecules in equilibrium. Now imagine that an insulating wall with a small door is introduced in the middle. Maxwell postulated that a small demon that can operate this door can cause a violation of second law of thermodynamics by allowing gas molecules with high speeds pass in one direction and slow ones in the other direction. Because transferring heat between systems that are mutually at thermal equilibrium without doing any work violates second law of thermodynamics [10], [8]. Szilard resolved this paradox by arguing based on the proposition that destruction of physical information creates entropy in the environment . For the demon to create such a temperature difference, without disturbing the system, it has to have an in nite memory at hand. Because having nite memory restricts the amount of information that can be stored at a given time and therefore excess information obtained by observing positions and velocities of several molecules would have to be destroyed continuously. This destruction of information would have dissipated energy back into the environment (container). This dissipated energy in turn would have increased the net disorder in the system contradicting Maxwell s prediction that the demon would actually decrease it [11], [12], [13]. An engine that Szilard used to illustrate the above idea, consists of a single molecule of an ideal gas in a cylindrical vessel with an adiabatic friction less piston locked in the middle separating it into two halves. The single molecule has two distinct physical states (left/right of the box) and therefore can represent one bit of information. To destroy this information, this system is brought in contact with a thermal reservoir at the same temperature as the molecule and the piston is unlocked. As a result the molecule jitters back and forth and repeatedly kicks the wall until the wall reached the other end of the container. Finally the molecule s position is totally randomized and the information about its location is Fig. 2. The Thermal Bit. destroyed with the help of heat drawn from the reservoir. And since the internal energy of the molecule has not changed, the excess work is dissipated into the environment. Heat dissipated in destroying a bit (Qdissip.) which is the work done by the molecule (Wmol.) to push the volume from V/2 to V in an isothermal limit, using the ideal gas law PV = kT is given by [14] Qdissip. = Wmol. = V Z V/2 P dV = V Z V/2 kT dV V = kT ln 2, (1) where k is the Boltzmann constant. It has to be noted that the time taken to push the piston ( ) at a given temperature depends on the size of the container V . Note that cannot be in nitely small unless V is in nitely small in which case quantum effects have to be taken into account [16]. We use a modi cation of Szilard engine as shown in Figure 2 in our model. There are two possible states for such a system. The Bernoulli random variable corresponding to each state is Pright := 1{Probability[X > L ] = 0}, where X is the x coordinate of the position of the molecule, L is the horizontal dimension of the box, is any arbitrarily small positive number. Clearly Pright {0, 1}. 1) State 0: The piston is pushed to the extreme end and the information about the location of the molecule is totally randomized. There is no mechanical energy that can be derived out of this system (Pright = 0). 2) State 1: The molecule is con ned in the left half and the piston is push to the middle from the right. A mechanical energy of at least kT ln 2 can be derived out of it (Pright = 1). We say that these systems come in state 0 by default and we spend energy kT ln 2 in creating state 1. The two states together represent one bit of information which we here on wards refer to as the Thermal-bit.1 A certain amount of raw information that is sampled and converted into necessary number of bits (0 s and 1 s) can be physically represented using a tape (an array) of Thermal-bits as shown in Figure 3. B. Transmission setup (T) Figure 4 depicts the communication device that we intend to study in the subsequent sections. Part T of the system is 1Similar Thermal-bits can be prepared with systems with any number of molecules and not necessarily just one. But we deliberately choose single molecule systems as a limiting case. Fig. 3. Information as a tape of thermodynamic bits. Fig. 4. Communication device. the transmission setup and R is the reception setup. We intend to send n bits of information from T to R which a distance r apart in space. For a very large n it maybe assumed that the source generates as many bits in state 0 as in state 1. That implies that the probability of having either of them is 1/2. The Transmission Setup consists of an ideal AC power source (with no internal resistance) connected to a wire loop antenna of radius b. There is a switching mechanism S at the bottom. It works as follows: 1) A tape of Thermal-bits is fed into the switching mech- anism. Each time a bit enters in, it remains in S for seconds before the next bit enters. 2) If a bit enters the switch in state 1, mechanical energy is extracted out of it and is used to open the switch of the circuit and keeps it so for the time until the bit is replaced by the next one. The amount of mechanical energy extracted out of each Thermal-bit is given by eq. (1). Whereas, if it is a Thermal-bit in state 2 that enters in, the switch remains closed for seconds until the next bit enters. Each time the switch is closed, current from the AC source ows through the loop antenna and an electromagnetic eld is radiated (magnetic dipole radiation). Let us represent the kth bit to be sent by ak, a Bernoulli random variable of probability 1/2. Therefore, depending on ak, the switch remains either closed or open each for a period of time . The current signal through the loop can be written as I(t) = I0(t) cos( ct), where I0(t) = I0 P k akS(t k ) with I0 as the amplitude of the AC current, c is the carrier frequency and S represents a square wave of period . We assume that the switching time 2 / c. Information which has been stored in the form of Thermal- bits thus far is now converted into a series of electromagnetic pulses. These pulses travel at the speed of light and each pulse has a time length of . The phase difference between the pulses Fig. 5. Magnetic dipole[15]. Fig. 6. Information as a series of electromagnetic pulses. is what represents the information making it a BPSK (Binary Phase-Shift Keying) signal. C. Reception setup (R) Reception setup consists of a wire loop receiving antenna (radius b) attached in series to a resistor (Figure 4). The resistance of this resistor is adjusted/chosen such that the total impedance of the receiving antenna matches the free space impedance. By this, we can safely assume that all the power that reaches the antenna is absorbed in the form of induced EMF which in turn is ampli ed and then completely converted into heat at the resistor A switching mechanism S is located at the bottom. It works as follows: 1) A tape of thermal bits created in states 1 is sent in. 2) Each time the Thermal-bit is kept in contact with the resistor for a time allowing heat to transfer. 3) If the temperature of the resistor TR T, the piston of the Thermal-bit will be pushed out creating a bit in state 0 III. THE ENERGY EFFICIENCY LIMIT In this section, we derive the equations for the energy con- sumed by the communication system and the achievable rate of such a system. With these equations, we nally calculate the fundamental limit on energy ef ciency of a physical system that communicates with electromagnetic waves. A. The signaling system We know that the magnitude of the Poynting vector gener- ated by a magnetic dipole, as de ned in the previous section, at a distance r from the dipole and at an angle with vertical axis (Figure 5), making the assumptions b r, b c c and r c c , is given by | S| = 0 c m0(t) 2 c 4 c sin r cos( c(t r/c)) 2 (2) where c is velocity of light, m0(t) = b2I0(t) is the maximum dipole of the loop [15]. We nd the average of the power density over the time period of one complete wave cycle 0 = 2 c . S =  0b4 4 c sin2 16r2c3  I2 0 Eak, 0[( X k akS(t k ))2 cos2( c(t r/c))] =  0b4 4 c sin2 16r2c3  I2 0 E 0 h [ X k =l E[akal]S(t k )2 + X k E[a2 k]S(t k )2] cos2( c(t r/c)) i . But we know that ak {0, 1} with probability 1/2 each and that ak s are not correlated. Therefore, E[ak]E[al] = 1/4 and E[a2 k] = 1/2. Which gives, S =  0b4 4 c sin2 16r2c3  I2 0 3 4E 0 h X k S(t k )2 cos2( c(t r/c)) i . By using the assumptions that 0 and that S(t k ) is either 0 or 1, we get S =  0b4 4 c sin2 16r2c3  I2 0 3 4.1 2 = 3 0b4 4 c sin2 128r2c3  I2 0. (3) The total radiating power emitted by the antenna is obtained by integrating eq. (3) over the surface area of any sphere surrounding the loop. Therefore the average energy per bit emitted by the transmission setup during one operation for time (that is for bit in state 0) is given by Erad T = 3 0b4 4 cI2 0 128c3  Z 0 (sin )2 sin d 2 Z 0 d = 3 0b4 4 cI2 0 128c3  8 3 = 4 cI2 0, (4) where =  0 b4 16c3  . B. Energy considerations at T In the whole process of transmitting n bits of information, we like to evaluate the total amount of energy spent in the Transmission Setup. We have shown earlier that the energy required for an operation on state 1 to switch it to state 0 is kT ln 2 and an operation on state 0 costs zero energy. And by the assumption that the states are equally probable, we can say that an operation on a Thermal-bit on an average costs an energy of 1 2kT ln 2. Therefore, the average amount of energy required to read a total of n Thermal-bits would be Ebits T = n 2 kT ln 2 joules. To emit all the bits, the radiator must have been operated n/2 times and for time each time. Therefore the fundamental lower bound on the total energy spent is: Etot T (n) := n[ 4 cI2 0 + 1 2kT ln 2]. (5) C. Energy considerations at R Equation (3) gives the magnitude of the Poynting vector at a distance r from the transmitting antenna. We assume that both transmitting and receiving loops are in the same plane ( = 0). Assuming that all the power absorbed into the loop is equal to the product of the magnitude of the Poynting vector and the area b2. The received signal energy on average per bit is given by E0 R := 3 0b4 4 cI2 0 128r2c3 b2 = 4 cI2 0, (6) where = 3 0 b6 128r2c3 . If we assume that the distance is large, i.e. for large enough r, the sum of received energy per bit and the channel noise can be much less than the energy needed to write a bit at the reception end, i.e. E0 R 1 2kT ln 2. In this case, in order to write a bit into the tape at the receiver, the received non-zero signal will be ampli ed by an ampli er that has to supply an average total energy (for all n bits) Etot R (n) := n 2 kT ln 2. (7) Finally, we de ne the total energy cost of preparing a Thermal-bit transmitting it electromagnetically con- structing it back at the receiver as (from eq. (5) and eq. (7)) E0 tot = Etot T (n = 1) + Etot R (n = 1) =  4 cI2 0 + 1 2kT ln 2  + 1 2kT ln 2 = 4 cI2 0 + kT ln 2. (8) D. The energy ef ciency The energy per bit to noise energy ratio snrb 0 is given as snrb 0 = E0 R N0W = 4 c W 2 I2 0 N0 , (9) where, I2 0 which is proportional to the energy spent by the AC source at T per bit, N0 is the noise spectral density, and W := 1 is the bandwidth where is the time length of each pulse. We know that the mutual information of BPSK channel as a function of snr0 is given by [5] Ib(snrb 0) = 1 ln 2  snrb 0 1 2 Z e y2 2 log  cosh(snrb 0 y q snrb 0)  dy  . (10) Finally, we de ne energy ef ciency as the ratio b = WIb(snrb 0) E0 tot bits/sec/joules. By substituting snrb 0 from eq. (9), b( c) can be expressed as a function of c as b(W, c, I0, kT) = W( 4 cI2 0 W 2N0 1 2 R e y2 2 log  cosh( 4 c W 2 I2 0 N0 y q 4c W 2 I2 0 N0 )  dy) (ln 2)( 4cI2 0 W + kT ln 2) . (11) IV. ENERGY EFFICIENCY FOR HIGHER CONSTELLATIONS So far, we only considered the case where only one bit is encoded by one symbol. However, by making appropriate modi cations to the proposed setup and the scheme of phasing, one should in principle be able to encode any number of bits per symbol. Instead of caring for the details of the engineering, we focus on the energy considerations for the case of quadrature phase shift keying (QPSK). The main difference in the case of QPSK is that we have four symbols {11, 01, 10, 00} and the probability that the source produces a typical symbol ak is now assumed to be 1/4. This will result in the following changes: 1) The average energy per symbol emitted is 1 4(2Erad T + Erad T + Erad T + 0) = Erad T /2. 2) Similarly, the received signal energy on average per symbol E0 R is changed by a factor 1/2. 3) A thermal operation in this case is on two bits at once. The average energy spent on the a symbol is kT ln 2. Including the cost of operation at T and R makes the average energy spent per operation per symbol 2kT ln 2. Which is twice the case of BPSK. The total energy spent on a symbol in preparing, transmit- ting and writing (analogous to eq. (8)), will be E0 tot = 2 4 cI2 0 + 2kT ln 2 (12) And the energy per bit to noise energy ratio snrq 0 is given as snrq 0 = E0 R 2N0W = 4 c 2W 2 I2 0 N0 . (13) We know that the mutual information of QPSK channel as a function of snrq 0 is given by [5] Iq(snrq 0) = 1 ln 2  2snrq 0 r 2 Z e y2 2 log  cosh(snrq 0 y q snrq 0)  dy  . (14) Energy ef ciency in this case is given as q(W, c, I0, kT) = W( 4 cI2 0 2W 2N0 q 2 R e y2 2 log  cosh( 4 cI2 0 2W 2N0 y q 4cI2 0 2W 2N0 )  dy) (ln 2)( 4cI2 0 2W + 2kT ln 2) . (15) Energy ef ciency for any M-ary constellation can be theo- retically determined in the same lines. However, the engineer- ing of the setup and the scheme of phasing get much more complicated. V. NUMERICAL ANALYSIS Equations (11) and (15) give expressions for energy ef - ciency in the case of BPSK and QPSK, respectively. In this section, we numerically verify and compare the behavior of the functions b(W, c, I0, kT) and q(W, c, I0, kT). We use the values 0 = 4 10 7N A 2, c = 3 108ms 1, r = 1m and b = 1m to get the values of = 9.25926 10 34 and = 3.42695 10 33. Figure 7 is a plot of b and q against carrier frequency c for W = 1Hz, N0 = 1, kT = 1 and I0 = 1A. It can be seen that at lower frequencies BPSK is more ef cient that QPSK, but for higher frequencies QPSK is much more ef cient than BPSK. We numerically determine the optimal carrier frequencies from the plots as b = 1.57013 108Hz and q = 2.00214 108Hz. Figure 8 is a plot of b and q against bandwidth W for optimal frequencies b = 1.57013 108Hz, q = 2.00214 108Hz, N0 = 1, kT = 1 and I0 = 1A. The energy ef ciency approaches 0 when band width is in nitely large. Figure 9 is a plot of b and q against square of the ampli- tude square of current I0 for W = 1Hz, N0 = 1, b = q = 108Hz and kT = 1 For low values of current (amplitude), BPSK is seen to be more ef cient than QPSK, but for higher amplitudes QPSK is much more ef cient than BPSK. Figure 10 is a plot of optimal frequency c against tem- perature (kT) of the Thermal-bits in both cases of BPSK and QPSK for W = 1, N0 = 1 and I0 = 1A . Since temperatures cannot be arbitrarily small in classical conditions, this suggests that the optimal frequency cannot be arbitrarily small either. VI. CONCLUSION In this work, we devised a hypothetical communication sys- tem and calculated the upper bound on energy ef ciency using electromagnetic and thermodynamic theory. We have seen that, in the proposed model, for a given total amount of energy that is at disposal to prepare, transmit and rewrite information bits, BPSK QPSK 0 2 108 4 108 6 108 8 108 1 109 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 Carrier frequency cHHzL Energy Efficiency Hbits sec joulesL Fig. 7. Energy ef ciency vs. Frequency ( c). BPSK QPSK 0 5 10 15 20 0.0 0.2 0.4 0.6 0.8 Bandwidth W HHzL Energy Efficiency Hbits sec joulesL Fig. 8. Energy ef ciency vs. Bandwidth (W). BPSK QPSK 0 10 20 30 40 50 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 I0 2Hampere2L Energy Efficiency Hbits sec joulesL Fig. 9. Energy ef ciency vs. I2 0. BPSK QPSK 0 20 40 60 80 100 1.0 108 1.2 108 1.4 108 1.6 108 1.8 108 2.0 108 2.2 108 2.4 108 Temperature kT HJL Optimal frequency * HHzL Fig. 10. c vs. Temperature (T). there exists a unique transmitting antenna frequency that yields maximum energy ef ciency. We have also seen the dependence of energy ef ciency on the bandwidth and the amplitude of the signal, and that it has an optimum at suitable values for the two. We have made a comparison of these dependencies in the cases of binary phase key shifting model and quadrature phase key shifting model. Similar treatment can be performed on various choices of physical systems to store and transport information. Our choice of thermodynamic Szilard boxes and electromagnetic waves is in the interest of exploring the classical limits. However, when we consider very low energy systems, the quantum mechanical effects could be more pronounced and this requires further study. In our future work we are interested to explore further fundamental physical systems to represent bits. For example: quantum spin states of particles, quantum mechanically described thermodynamic systems [16]. REFERENCES [1] Jacob D. Bekenstein, Energy Cost of Information Transfer , Physical Review Letters, vol. 46 - 10, Mar. 1981 [2] Seth Lloyd, Physical Limits to Communication , Physical Review Letters, vol. 93 - 10, 2004 [3] Claude E. Shannon, A Mathematical Theory of Communication . Bell System Technical Journal 27 (3): 379423, 1948. [4] Leon Brillouin, Science and Information Theory , Courier Dover Publications, 2004 [5] Samah A. M. Ghanem Mutual Information for Generalized Arbitrary Binary Input Constellations , MAP-Tele Workshop, 2010. [6] Rolf Landauer, Information is a Physical Entity , Physica A 263 (1999) 63-67. [7] Rold Landauer, Irreversibility and Heat Generation in the Computing Process IBM Journal of Research and Development, vol. 44, num 1/2, page 261, 2000. [8] Charles H. Bennett, Notes on Landauer s principle, reversible com- putation, and Maxwells Demon , Studies in History and Philosophy of Modern Physics 34 (2003) 501510 [9] Sergio Verdu, On channel capacity per unit cost , IEEE Trans. on Inf. Theory, vol. 36, no. 5, pp. 1019-1030, Sep. 1990. [10] Charles H. Bennett, Demons, engines and the second law , Scienti c American 257 (1987), no. 5, 108116. [11] Leo Szilard, On the decrease of entropy in a thermodynamic system by the intervention of intelligent beings , Behavioral Science 9 (1964), no. 4, 301310. [12] Manoj Gopalkrishnan, The Hot Bit I: The Szilard-Landauer Corre- spondence , http://arxiv.org/abs/1311.3533v2 [13] Leon Brillouin, Maxwell s Demon Cannot operate:Information and Entropy. I , J. Appl. Phys. 22, 334 (1951) [14] Richard P. Feynman et al, Feynman Lectures On Computation , 2000. [15] David J. Grif ths, Introduction to electrodynamics , Prentice Hall, 1999 [16] Sang Wook Kim et al, Quantum Szilard Engine , Phys. Rev. Lett. 106, 070401, Feb 2011.