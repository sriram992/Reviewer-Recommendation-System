See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/277893178 Synchronization of Memristor-Based Coupling Recurrent Neural Networks With Time-Varying Delays and Impulses Article in IEEE Transactions on Neural Networks and Learning Systems June 2015 DOI: 10.1109/TNNLS.2015.2435794 Source: PubMed CITATIONS 107 READS 417 4 authors: Some of the authors of this publication are also working on these related projects: chiral interfaces and assembly View project SUPP smart grid View project Wei Zhang Fudan University 1,013 PUBLICATIONS 36,668 CITATIONS SEE PROFILE Chuandong Li Southwest University in Chongqing 381 PUBLICATIONS 9,907 CITATIONS SEE PROFILE Tingwen Huang Texas A&M University at Qatar 663 PUBLICATIONS 22,195 CITATIONS SEE PROFILE Xing He Southwest University in Chongqing 131 PUBLICATIONS 2,392 CITATIONS SEE PROFILE All content following this page was uploaded by Tingwen Huang on 15 June 2015. The user has requested enhancement of the downloaded file. This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination. IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 1 Synchronization of Memristor-Based Coupling Recurrent Neural Networks With Time-Varying Delays and Impulses Wei Zhang, Chuandong Li, Senior Member, IEEE, Tingwen Huang, and Xing He Abstract Synchronization of an array of linearly coupled memristor- based recurrent neural networks with impulses and time-varying delays is investigated in this brief. Based on the Lyapunov function method, an extended Halanay differential inequality and a new delay impulsive differential inequality, some suf cient conditions are derived, which depend on impulsive and coupling delays to guarantee the exponential synchronization of the memristor-based recurrent neural networks. Impulses with and without delay and time-varying delay are considered for modeling the coupled neural networks simultaneously, which renders more practical signi cance of our current research. Finally, numerical simulations are given to verify the effectiveness of the theoretical results. Index Terms Impulse, memristor, recurrent neural networks, synchronization, time-varying delay. I. INTRODUCTION In 1971, based on physical symmetry arguments, Chua [1] con- ceived and predicted that besides the resistor, capacitor, and inductor, there should be the fourth fundamental two-terminal circuit ele- ment called memristor, which is a contraction of memory resistor. Chua [1] also mathematically demonstrated that his hypothetical device would represent a relationship between ux and charge similar to what a nonlinear resistor provides between voltage and current. In 2008, Strukov et al. [2] proudly announced their realization of a memristor prototype. In their prototype, memristor is a two-terminal element with variable resistance called memristance, which depends on how much electric charge has been passed through in a particular direction. In other words, memristor has the distinctive ability to memorize the passed quantity of electric charge. Due to this feature, we can replace the resistor with memristor to build a new model of neural networks to emulate the human brain, we can also further apply memristor on the design of the next generation computer, such as the powerful brain-like neural computer [2] [5]. In recent years, dynamic analysis of memristor-based recur- rent neural networks has attracted increasing attention [6] [12]. Guo et al. [6] investigated globally exponential dissipation and stabilization of memristor-based recurrent neural networks with time-varying delays. In [11], global exponential stability of a class of memristor-based recurrent neural networks with time-varying delays was studied by constructing proper Lyapunov functions and using the differential inclusion theory. In [12], exponential synchronization Manuscript received February 13, 2014; revised October 26, 2014 and May 3, 2015; accepted May 16, 2015. This work was supported in part by the Qatar National Research Fund, a member of the Qatar Foundation, through the National Priorities Research Program under Grant NPRP 4-1162-1-181 and in part by the National Natural Science Foundation of China under Grant 61374078 and Grant 61403313. W. Zhang and C. Li are with the College of Computer Science, Chongqing University, Chongqing 400044, China (e-mail: 787885596@qq.com; licd@cqu.edu.cn). T. Huang is with Texas A&M University at Qatar, Doha 23874, Qatar (e-mail: tingwen.huang@qatar.tamu.edu). X. He is with the School of Electronics and Information Engineering, Southwest University, Chongqing 400715, China (e-mail: hexingdoc@hotmail.com). Color versions of one or more of the gures in this paper are available online at http://ieeexplore.ieee.org. Digital Object Identi er 10.1109/TNNLS.2015.2435794 was investigated for memristor-based recurrent neural networks with time delays. However, a few authors have investigated the exponen- tial synchronization of memristor-based coupling delayed recurrent neural networks with impulses. Impulsive effects exist in neural networks. For instance, in the implementation of electronic networks, the state of the network is subject to instantaneous perturbations and experiences abrupt changes at certain instances, which may be caused by switching phenomenon, frequency change, or sudden noise. Although there are many results concerning the stability of impulsive systems, the synchronization problem of dynamical networks with impulsive effects has received little attention. Impulsive control is effective in dealing with dynami- cal systems [13] [24]. However, impulsive controllers in [13] [24] did not consider time-delay effects. Abrupt changes of the state in one subsystem cannot be received by its neighbors simultaneously, which implies that it is necessary to consider impulsive effects with time delays. In [25], impulse-induced exponential stability was studied for recurrent delayed neural networks. In [26], synchroniza- tion of TS fuzzy complex dynamical networks with time-varying impulsive delays and stochastic effects were investigated. To the best of our knowledge, a few published papers have considered the synchronization of memristor-based coupling recurrent neural networks (MRNNs) with delayed impulses. Motivated by the afore- mentioned discussions, we investigate the synchronization of MRNN with time-varying delayed impulses. Notations: max( ) and min( ) are used to denote the maximum and minimum eigenvalues of a real matrix. Rn denotes the n-dimensional Euclidean space. is the Euclidean norm in Rn. A = (aij )n n is an n n matrix. Let N+ = {1, 2, . . .}. The superscript T denotes the matrix or vector transposition. En is the n n identity matrix and 1N denote the identity vector. II. PROBLEM FORMULATION AND PRELIMINARIES In this section, we establish the mathematical model of the memristor-based recurrent neural networks, followed with some assumptions, de nitions, and lemmas. According to [6] and [27], we provide a mathematical model of the memductance as follows: (v(t)) = , v(s) , s (t , t] , v(s) , s (t , t] lim s t (v(s)), v(s) , s (t , t] (1) where represents a decrease, represents an increase, rep- resents unchanges, and is a suf ciently small positive constant. lims t (v(s)) is either equal to or , which means that the memductance keeps the voltage value. Obviously, the memductance function may be discontinuous. Remark 1: Based on the circuit design of memristor-based neural networks [29] and value trends of the memristor [30], it is obvi- ous that the values of the connection weights of memristor-based neural networks can be described as the effect of the difference between the network output voltage and the voltage on the capacitor. As stated in [28], two memory states are required in digital computer applications, and here memristor also has two suf ciently distinct 2162-237X 2015 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information. This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination. 2 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS equilibrium states. Therefore, a more realistic mathematical descrip- tion of the connection weights of memristor-based neural networks is proposed in this brief. Consider the MRNN model with time-varying delays described as follows: duk(t) dt = dkuk(t) + n  l=1 akl(t) fl(ul(t)) + n  l=1 bkl(t) fl(ul(t kl(t))) + Ik (2) where akl(t) = a kl, kl(s) , s (t , t] a kl, kl(s) , s (t , t] lim s t akl( kl(s)), kl(s) , s (t , t] (3) bkl(t) = b kl, kl(s) , s (t , t] b kl, kl(s) , s (t , t] lim s t bkl( kl(s)), kl(s) , s (t , t] (4) where kl(t) = fl(ul(t)) uk(t), kl(t) = fl(ul(t kl(t))) uk(t), uk is the state of the kth neuron, and fl( ) denotes the activation function. Ik denotes the input of the kth neuron and kl(t), k, and l = 1, 2, . . . , n are the transmission delays, which are bounded. For convenience, the dynamical differential equations of MRNN matrix format are given by du(t) dt = Du(t) + A(u(t)) f (u(t)) + B(u(t)) f (u(t 1(t))) + I (5) where 1(t) = [ kl(t)]n n, 0 1(t) 1, u(t) = (u1(t), u2(t), . . . , un(t))T is the state vector, and D = diag(d1, d2, . . . , dn) is a real diagonal matrix, where di > 0, i = 1, 2, . . . , n are the neuron self-inhibitions; A(u(t)) = [akl(t)]n n and B(u(t)) = [bkl(t)]n n are the feedback and delayed feedback connection weight matrices, respectively and, f (u(t)) = ( f1(u(t)), . . . , fn(u(t)))T represents the neuron activation function. I = [I1, I2, . . . , In]T Rn is an input or a bias vector. For convenience, we denote t 1 = t 1(t) and t k 2 = t k 2(t k). According to [31] and [32], let cii =  j=1, j =i cij , an array of linearly coupled identical delayed MRNN with N identical networks can be described as duik(t) dt = dkuik(t) + n  l=1 akl(t) fl(uil(t)) + n  l=1 bkl(t) fl(uil(t kl(t))) + Ik + N  j=1, j =i cij ku jk(t). (6) This can be written in matrix form as dui(t) dt = Dui(t) + A(ui(t)) f (ui(t)) + B(ui(t)) f (ui(t 1)) + I + N  j=1, j =i cij u j(t) (7) where ui(t) = (ui1(t), ui2(t), . . . , uin(t))T , C = (cij )N N RN N denotes the coupling con guration of the coupled network with cij 0, i = j, cii =  j=1, j =i cij , i, j = 1, 2, . . . , N, and = diag( 1, 2, . . . , n), and each differential equation has a unique solution with initial value ui(s) = i(s) i = 1, 2, . . . , n, s [t0 , t0] (8) where i = ( i1, i2, . . . , in)T . For a constant vector u i = (u i1, u i2, . . . , u in)T , we have that fl(u l ) u k is a constant and its derivative is equal to 0. Then akl( fl(u l ) u k) = a0 kl and bkl( fl(u l ) u k) = b0 kl . Hence, we can present the following de nition of equilibrium of (7). De nition 1: A constant u i = (u i1, u i2, . . . , u in)T is called an equilibrium of (6), if dku ik + n  l=1 a0 kl f  u il + n  l=1 b0 kl f  u il + Ik = 0 (9) for k,l = 1, 2, . . . , n. By introducing the impulsive effects into system (7), one can obtain the following coupled MRNN with time-varying impulsive delay effects: dui(t) dt = Dui(t)+A(ui(t)) f (ui(t))+B(ui(t)) f (ui(t 1))+I + N j=1, j =i cij u j(t), t = t k ui(t k) = wui  t k + ui(t k 2), t = t k, k N+ (10) where w and are the impulsive strengths without and with delay, respectively. {t1, t2, . . .} is a sequence of strictly increasing impulsive instants satisfying limk t k = + , u(t k) = u(t+ k ) = limt t+ k u(t), u(t k ) = limt t k u(t), ui(t k) = ui(t k) ui(t k ), and 0 2(t) 2. For the activation function f ( ), we have the following assumptions. Assumption 1: The activation function f ( ) = ( f1( ), . . . , fn( ))T satis es the Lipschitz condition, i.e., there exist positive constants li, and x, y R, such that || fi(x) fi(y)|| li||x y||, i = 1, 2, . . . , n. Remark 2: Various kinds of frequently used activation functions satisfy Assumption 2. For example, the sigmoid activation functions fi(x) = tanh(x) used in the Hop eld neural networks, and the piecewise linear activation functions fi(x) = 0.5(|x + 1| |x|) in cellular neural networks. De nition 2: The coupled MRNN with impulsive effects is said to be exponential synchronized, if there exist > 0, t0 > 0, and M0 > 0 such that for any initial values i(s) ||xi (t) x j (t)|| M0e (t t0) (11) holds for all t t0, and for any i, j = 1, 2, . . . , N, where M0 and are called the decay coef cient and decay rate, respectively. III. MAIN RESULTS In the following, we shall discuss the globally exponential syn- chronization problem for MRNNs with impulsive delays. To present concisely, here we let u(t) = [u1(t), u2(t), . . . , uN (t)]T , AN (u(t)) = (EN A(u(t))), f (u(t)) = [ f T (x1(t)), . . . , f T (uN (t))]T , BN(u(t)) = (EN B(u(t))), DN = (EN D), C = (C ), A+ = [a+ kl]n n, B+ = [b+ kl]n n, a+ kl = max{a kl, a kl}, b+ kl = max{b kl , b kl}, AN+ = (IN A+), BN+ = (EN B+), and I = 1N I. Then coupled neural networks (10) can be rewritten as du(t) dt = DN u(t) + AN (u(t)) f (u(t)) + BN(u(t)) f (u(t 1)) + I + Cu(t), t = t k u  t+ k u  t k = wu  t k + u(t k 2), t = t k, k N+. (12) Theorem 1: Assume that Assumption 1 holds, and there exist a small enough number > 0, a positive de ne matrix P and diagonal This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination. IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 3 positive de nite matrices Q and R such for all k N+, the following conditions are satis ed:  =  P A(N 1)+ P B(N 1)+ 0 Q 0 0 R 0  < 0 (13) 0, 1 + 2e 1 (14)  + 1 + 2e   t k+1 t k < ln  1 + 2e (15) where  = P DN 1 (DN 1)T P + 2 P C + LT QL P,  = LT RL P; 1 = [(1 + w)2 + (1 + w) max(P)] and 2 = ( 2 + (1 + w) ) min(P)/ . Then the MRNN with delayed impulses (12) is exponentially synchronized. Proof: Let us construct a Lyapunov function of the form V (t) = uT (t)MPMu(t) (16) where M = M E M = 1 1 ... 1 1 (N 1) N . (17) For t = t k( k N+), by calculating the upper right-hand derivative of V (t), we can obtain D+V (t) = 2uT (t)MT PM  DN u(t) + AN(u(t)) f (x(t)) + BN(u(t)) f (u(t 1)) + C N u(t)  . (18) By [32, Lemma 1], we have following: MDN = DN 1M, MAN(u(t)) = AN 1(u(t))M MBN(u(t)) = BN 1(u(t))M, MC = CM (19) where C = C and C = MC J. Substituting (19) into (18), we have D+V (t) = 2uT (t)MT P DN 1Mu(t) + 2uT (t)MT P AN 1(u(t))M f (u(t)) + 2uT (t)MT P BN 1(u(t))M f (u(t 1)) + 2 uT (t)MT P CMu(t). (20) In view of the Lipschitz condition, we have 2uT(t)MT P AN 1(u(t))M f (u(t)) 2uT (t)MT P A(N 1)+M f (u(t)) uT(t)MT P A(N 1)+Q 1(A(N 1)+)T PMu(t) + uT(t)MT LT QLMu(t) (21) and 2uT (t)MT P BN 1(u)M f (u(t 1)) uT (t)MT P B(N 1)+R 1(B(N 1)+)T PMu(t) + uT (t 1)MT LT RLMu(t 1). (22) By (18) (22), we can obtain D+V (t) uT (t)MT  P DN 1 (DN 1)T P + 2 P C + P A(N 1)+Q 1(A(N 1)+)T P + LT QL + P B(N 1)+R 1(B(N 1)+)T P P  Mu(t)+uT (t 1)MT (LT RL P)Mu(t 1)+ V (t) + V (t 1) V (t) + V (t 1). (23) For any positive constant , one obtains from the second equation (12) that V (t k) = (1 + w)2uT  t k MT PMu  t k + (1 + w)  uT  t k MT PMu(t k 2) + uT (t k 2)MT PMu  t k  + 2uT (t k 2)MT PMu(t k 2) 1V  t k + 2V (t k 2). (24) Thus, in view of (23) and (24), all the conditions of [25, Lemma 1] are satis ed. This completes the proof of Theorem 1. Because the resistors are used in the no-delay-feedback self- connection, here we assume that the connections between coupled identical networks are realized by resistors. Thus, akk(t) = akk is a constant. We de ne the synchronization error system ei(t) = ui(t) y(t), where y(t) is an isolated delayed neural network, as dy(t) dt = Dy(t) + A(y(t)) f (y(t)) + B(y(t)) f (y(t 1) + I + i (25) where i = ( i1, i2, . . . , in)T denotes the control input and maybe there exist an equilibrium point, a periodic orbit, or a chaotic attractor for y(t). Let i = R(ei(t) sign(ei(t))), the error dynamical system is governed as follows: dei(t) dt = Dei(t) + A(ui(t))g(ei(t)) + B(ui(t))g(ei(t 1)) + N j=1, j =i cij e j (t) +  + i, t = t k ei  t+ k ei  t k = wei  t k + ei  t k 2 , t = t k (26) where k N+, g(ei(t)) = f (ei(t) + y(t)) f (y(t)), and  = (A(ui(t)) A(y(t))) f (y(t)) + (B(ui(t)) B(y(t))) f (y(t 1)). Assumption 2: The activation function f ( ) = ( f1( ), f2( ), . . . , fn( ))T satis es the Lipschitz condition and is bounded, i.e., x, y R, such that || fi(x) fi(y)|| li||x y||, | fi(x)| hi, and i = 1, 2, . . . , n. Theorem 2: Suppose that Assumption 2 holds and there exist positive numbers rk, k = 1, . . . , n, such that the following inequalities hold: d k = |w + 1| + | | < 1 (27) p + 1 d k q + lnd k t k+1 t k < 0 (28) rk n  l=1 kl (29) This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination. 4 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS where A+ = (a+ kl)n n, a+ kl = akk only if k = l, otherwise a+ kl = max{|a kl|, |a kl|}, B+ = [b+ kl]n n, b+ kl = max{|b kl|, |b kl|}, p = R D + A+L , q = B+L , and kl = sups (t ,t] |a kl(s) a kl(s)|hk + sups (t ,t] |b kl(s) b kl(s)|hk. Then the MRNN with time-varying impulsive delay (26) is globally exponentially stability. Proof: Construct a Lyapunov function V (t) = N  i=1 ei(t) (30) where ei(t) = n k=1 |eik(t)|. Differentiating V (t) along the solution of (26) t t k, k N+, one obtain that D+V (t) N  i=1 n  k=1 sign(eik(t)) dkeik(t) + rkeik(t) + n  l=1 bkl(t)gl(eil(t 1)) + N  j=1, j =i cij ke jk(t) rksign(eik(t)) + n  l=1 akl(t)gl(eil(t)) + N  i=1 [ (A(ui(t)) A(y(t))) f (y(t)) + (B(ui(t)) B(y(t))) f (y(t 1)) ] N  i=1 n  k=1 dk|eik(t)| + lk n  l=1 |akl(t)||eil(t)| +lk n  l=1 |bkl(t)||eil(t 1)| rk + rk|eik(t)| + N  j=1, j =i cij k|e jk(t)| + N  i=1 [ (A(ui(t)) A(y(t))) f (y(t)) + (B(ui(t)) B(y(t))) f (y(t 1)) ]. (31) From akl(t) and bkl(t) are de nition, we get n  l=1 |akl(t)||eil(t)| = n  l=1,k =l akl(t)|eil(t)| + n  l=k akk|eil(t)| n  l=1 a+ kl|eil(t)| (32) and n  l=1 |bkl(t)||eil(t 1)| n  l=1 b+ kl|eil(t 1)|. (33) From the diffusive property of symmetric matrix C, one observes that N  i=1 N  j=1 cij e j(t) = n  k=1 k N  i=1 N  j=1 cij |e jk(t)| = n  k=1 k N  i=1 N  j=1, j =i cij eT ik(t) eT jk(t)  0. (34) Because the activation function is bounded, we can obtain (A(ui(t)) A(y(t))) f (y(t)) n  k=1 n  l=1 sup s (t ,t] a kl(s) a kl(s) | fk(yk(t))| n  k=1 n  l=1 sup s (t ,t] a kl(s) a kl(s) hk (35) and (B(ui(t)) B(y(t))) f (y(t 1)) n  k=1 n  l=1 sup s (t ,t] b kl(s) b kl(s) hk. (36) Substituting (32) (36) into (31), we have D+V (t) N  i=1 n  k=1 dk|eik(t)| + lk n  l=1 a+ kl|eil(t)| +lk n  l=1,k =l b+ kl|eil(t 1)| + rk|eik(t)| rk + n  k=1 n  l=1 sup s (t ,t] a kl(s) a kl(s) hk + n  k=1 n  l=1 sup s (t ,t] b kl(s) b kl(s) hk N  i=1 n  k=1 [ dk + rk]|eik(t)| + lk n  l=1 a+ kl|eil(t)| + lk n  l=1 b+ kl|eil(t 1)|] pV (t) + qV (t 1). (37) On the other hand, from the construction of V (t), we have V (t) N  i=1 |w + 1| ei  t k  + | | ei  t k 2  = |w + 1|V  t k + | |V (t k 2). (38) By (37) and (38), it follows immediately that all the conditions of [26, Lemma 5] are satis ed. This completes the proof of Theorem 2. IV. NUMERICAL EXAMPLES In order to verify the effectiveness of the theoretical results, we give two numerical examples. In order to facilitate, we set I = 0. This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination. IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS 5 TABLE I EXAMPLE 1 PARAMETER SETUP Fig. 1. Synchronization errors of x11 xi1 and i = 2, . . . , 6, in Example 1. We will consider the following coupled neural network models: dui(t) dt = Dui(t) + A(ui(t)) f (ui(t)) + B(ui(t)) f (ui(t 1)) + N  j=1, j =i cij u j (t). (39) Example 1: Consider a two-neuron MRNN model with six subsystems. The parameters are given in Table I. Here, is a suf ciently small positive constant, D = diag(3, 3), = diag(1, 1), f (t) = (tanh(ui1(t)), tanh(ui2(t)))T , 1(t) = 0.25 sin(t)+0.25, and 2(t) = 0.2 cos(t)+0.2. The coupling matrix is given cij = 0.5, i = j. We use the MATLAB LMI Control Toolbox to solve the LMIs in (13), and obtain the following feasible matrices: P =  3.9536 0.1046 0.1046 3.8902  , Q =  13.5955 0 0 13.5955  R =  5.2354 0 0 5.2354  . Thus, condition (H1) of Theorem 1 is satis ed. Let w = 1, = 0.4, = 3, = 2, = 1, = 3, and = 0.001. By simple computation, we obtain 1 + 2e = 0.1601 < 1 and exp(( + /( 1 + 2e ))(t k+1 t k)) (1/( 1 + 2e )) = 3.2887 < 0. According to the condition of Theorem 1, it can be concluded that system (39) is exponential stability. Thus, MRNN with time-varying impulsive delay is globally exponential synchronization. Fig. 1 shows the synchronization errors of x11 xi1 and x12 xi2, respectively. Example 2: In this example, we consider three-neuron MRNN model with six subsystems. The parameters are given in Table II. Here, is a suf ciently small positive constant, D = diag(10.5, 10.5, 10.5), = diag(1, 1, 1), f (u) = (|u + 1| |u 1|)/2, TABLE II EXAMPLE 2 PARAMETER SETUP Fig. 2. Trajectories of system (39) with impulse. 1(t) = 0.25 sin(t)+0.25, and 2(t) = 0.3 cos(t)+0.3. The coupling matrix is given as cij = 1, i = j. Let w = 1.2 and = 0.5. By solving (36) and (37), we can obtain d k = 0.7 < 1 and p + (1/d k)q +(ln d k/t k+1 t k) = 0.2106 < 0. According to Theorem 2, it can be concluded that system (39) is exponential synchronization. We select coupled neural networks consisting of six linearly coupled identical nodes. Fig. 2 shows the synchronization errors of x11 xi1, x12 xi2, and x13 xi3, respectively. Figs. 1 and 2 indicate that synchronization can be achieved. REFERENCES [1] L. O. Chua, Memristor The missing circuit element, IEEE Trans. Circuit Theory, vol. 18, no. 5, pp. 507 519, Sep. 1971. [2] D. B. Strukov, G. S. Snider, D. R. Stewart, and R. S. Williams, The missing memristor found, Nature, vol. 453, no. 7191, pp. 80 83, May 2008. [3] H. Kim, M. P. Sah, C. Yang, T. Roska, and L. O. Chua, Memristor bridge synapses, Proc. IEEE, vol. 100, no. 6, pp. 2061 2070, Jun. 2012. [4] J. M. Tour and T. He, Electronics: The fourth element, Nature, vol. 453, no. 6, pp. 42 43, May 2008. [5] G. S. Snider, Self-organized computation with unreliable, memristive nanodevices, Nanotechnology, vol. 18, no. 36, pp. 365202-1 365202-13, Aug. 2007. [6] Z. Guo, J. Wang, and Z. Yan, Attractivity analysis of memristor-based cellular neural networks with time-varying delays, IEEE Trans. Neural Netw., vol. 25, no. 4, pp. 704 717, Apr. 2014. [7] A. Wu and Z. Zeng, Lagrange stability of memristive neural networks with discrete and distributed delays, IEEE Trans. Neural Netw., vol. 25, no. 4, pp. 690 703, Apr. 2014. [8] S. Wen, Z. Zeng, and T. Huang, Observer-based synchronization of memristive systems with multiple networked input and output delays, Nonlinear Dyn., vol. 78, no. 1, pp. 541 554, Oct. 2014. This article has been accepted for inclusion in a future issue of this journal. Content is final as presented, with the exception of pagination. 6 IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS [9] A. Wu, J. Zhang, and Z. Zeng, Dynamic behaviors of a class of memristor-based Hop eld networks, Phys. Lett. A, vol. 375, no. 15, pp. 1661 1665, Apr. 2011. [10] A. Wu and Z. Zeng, Exponential stabilization of memristive neural networks with time delays, IEEE Trans. Neural Netw., vol. 23, no. 12, pp. 1919 1929, Dec. 2012. [11] G. Zhang, Y. Shen, and J. Sun, Global exponential stability of a class of memristor-based recurrent neural networks with time-varying delays, Neurocomputing, vol. 97, no. 5, pp. 149 154, Nov. 2012. [12] A. Wu, Z. Zeng, X. Zhu, and J. Zhang, Exponential synchroniza- tion of memristor-based recurrent neural networks with time delays, Neurocomputing, vol. 74, no. 17, pp. 3043 3050, Oct. 2011. [13] W. Zhang, Y. Tang, Q. Miao, and W. Du, Exponential synchronization of coupled switched neural networks with mode-dependent impulsive effects, IEEE Trans. Neural Netw., vol. 24, no. 8, pp. 1316 1326, Aug. 2013. [14] X. He, C. Li, T. Huang, and C. Li, A recurrent neural network for solving bilevel linear programming problem, IEEE Trans. Neural Netw. Learn. Syst., vol. 25, no. 4, pp. 824 830, Apr. 2014. [15] X. Yang, J. Cao, and J. Lu, Stochastic synchronization of complex networks with nonidentical nodes via hybrid adaptive and impulsive control, IEEE Trans. Circuits Syst. I, Reg. Papers, vol. 59, no. 2, pp. 371 384, Feb. 2012. [16] J. Lu, D. W. C. Ho, J. Cao, and J. Kurths, Exponential synchronization of linearly coupled neural networks with impulsive disturbances, IEEE Trans. Neural Netw., vol. 22, no. 2, pp. 329 336, Feb. 2011. [17] A. F. Filippov, Differential Equations With Discontinuous Righthand Sides: Control Systems. Dordrecht, The Netherlands: Springer-Verlag, 1988. [18] A. N. Michel, L. Hou, and D. Liu, Stability of Dynamical Systems: Continuous, Discontinuous, and Discrete Systems. Boston, MA, USA: Birkh user, 2007. [19] A. Bacciotti and L. Rosier, Liapunov Functions and Stability in Control Theory (Lecture Notes in Control and Information Science), vol. 267. Berlin, Germany: Springer-Verlag, 2005. [20] S. Wen, Z. Zeng, T. Huang, Q. Meng, and W. Yao, Lag synchronization of switched neural networks via neural activation function and appli- cations in image encryption, IEEE Trans. Neural Netw. Learn. Syst., to be published. [21] G. Zhang, Z. Liu, and Z. Ma, Synchronization of complex dynamical networks via impulsive control, Chaos, vol. 17, no. 4, pp. 043126-1 043126-9, Dec. 2007. [22] Z.-H. Guan, Z.-W. Liu, G. Feng, and Y.-W. Wang, Synchronization of complex dynamical networks with time-varying delays via impulsive distributed control, IEEE Trans. Circuits Syst. I, Reg. Papers, vol. 57, no. 8, pp. 2182 2195, Aug. 2010. [23] X. He, C. Li, T. Huang, and C. Li, Neural network for solving convex quadratic bilevel programming problems, Neural Netw., vol. 51, no. 3, pp. 17 25, Mar. 2014. [24] B. Liu and D. J. Hill, Robust stability of complex impulsive dynamical systems, in Proc. 46th IEEE Conf. Decision Control, New Orleans, LA, USA, Dec. 2007, pp. 103 108. [25] Q. Wu, J. Zhou, and L. Xiang, Impulses-induced exponential stability in recurrent delayed neural networks, Neurocomputing, vol. 74, no. 17, pp. 3204 3211, Oct. 2011. [26] X. Yang and Z. Yang, Synchronization of TS fuzzy complex dynamical networks with time-varying impulsive delays and stochastic effects, Fuzzy Sets Syst., vol. 235, no. 1, pp. 25 43, Jan. 2013. [27] Z. Guo, J. Wang, and Z. Yan, Global exponential dissipativity and stabilization of memristor-based recurrent neural networks with time-varying delays, Neural Netw., vol. 48, no. 12, pp. 158 172, Dec. 2013. [28] L. O. Chua, Resistance switching memories are memristor, Appl. Phys. A, vol. 102, no. 4, pp. 765 783, Mar. 2011. [29] S. Wen, Z. Zeng, and T. Huang, Exponential stability analysis of memristor-based recurrent neural networks with time-varying delays, Neurocomputing, vol. 97, no. 17, pp. 233 240, Nov. 2012. [30] S. Wen, Z. Zeng, T. Huang, Y. Chen, and P. Li, Circuit design and exponential stabilization of memristive neural networks, Neural Netw., vol. 63, no. 3, pp. 48 56, Mar. 2015. [31] W. Lu and T. Chen, Synchronization of coupled connected neural networks with delays, IEEE Trans. Circuits Syst. I, Reg. Papers, vol. 51, no. 12, pp. 2491 2503, Dec. 2004. [32] C. W. Wu, Synchronization in an array of linearly coupled dynamical systems, IEEE Trans. Circuits Syst. I, Fundam. Theory Appl., vol. 42, no. 8, pp. 430 447, Aug. 1995. View publication stats